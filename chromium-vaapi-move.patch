From 42e955c9b3030121dd945e103a39381a92221bdb Mon Sep 17 00:00:00 2001
From: Miguel Casas <mcasas@chromium.org>
Date: Mon, 04 Dec 2017 14:18:12 +0000
Subject: [PATCH] vaapi: move vaapi* files to //media/gpu/vaapi/ folder

This CL moves the (remaining) vaapi related files from
//media/gpu to the existing//media/gpu/vaapi.

Fully automatic:

$ git mv media/gpu/vaapi_* media/gpu/vaapi/
$ git mv media/gpu/va_s*   media/gpu/vaapi/
$ tools/git/mass-rename.p

TBR= sadrul@chromium.org, avi@chromium.org for
the two first files that just get an include path udpate.

Bug: none
Cq-Include-Trybots: master.tryserver.chromium.android:android_optional_gpu_tests_rel;master.tryserver.chromium.linux:linux_optional_gpu_tests_rel;master.tryserver.chromium.mac:mac_optional_gpu_tests_rel;master.tryserver.chromium.win:win_optional_gpu_tests_rel
Change-Id: Ia1dcbdef3695bae5879d0951fc78cf6dcef3325f
Reviewed-on: https://chromium-review.googlesource.com/801636
Commit-Queue: Miguel Casas <mcasas@chromium.org>
Reviewed-by: Pawel Osciak <posciak@chromium.org>
Reviewed-by: Dale Curtis <dalecurtis@chromium.org>
Cr-Commit-Position: refs/heads/master@{#521330}
---

--- a/components/viz/service/main/viz_main_impl.cc
+++ b/components/viz/service/main/viz_main_impl.cc
@@ -29,7 +29,7 @@
 #include "services/service_manager/public/cpp/connector.h"
 
 #if defined(OS_CHROMEOS) && BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #endif
 
 namespace {
--- a/content/gpu/gpu_main.cc
+++ b/content/gpu/gpu_main.cc
@@ -95,7 +95,7 @@
 #endif
 
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #endif
 
 namespace content {
--- a/media/gpu/BUILD.gn
+++ b/media/gpu/BUILD.gn
@@ -310,26 +310,26 @@ component("gpu") {
 
   if (use_vaapi) {
     sources += [
-                 "va_surface.cc",
-                 "va_surface.h",
-                 "vaapi/vaapi_picture_factory.cc",
-                 "vaapi/vaapi_picture_factory.h",
+                 "vaapi/va_surface.cc",
+                 "vaapi/va_surface.h",
+                 "vaapi/vaapi_jpeg_decode_accelerator.cc",
+                 "vaapi/vaapi_jpeg_decode_accelerator.h",
+                 "vaapi/vaapi_jpeg_decoder.cc",
+                 "vaapi/vaapi_jpeg_decoder.h",
+                 "vaapi/vaapi_jpeg_encode_accelerator.cc",
+                 "vaapi/vaapi_jpeg_encode_accelerator.h",
+                 "vaapi/vaapi_jpeg_encoder.cc",
+                 "vaapi/vaapi_jpeg_encoder.h",
                  "vaapi/vaapi_picture.cc",
                  "vaapi/vaapi_picture.h",
-                 "vaapi_jpeg_decode_accelerator.cc",
-                 "vaapi_jpeg_decode_accelerator.h",
-                 "vaapi_jpeg_decoder.cc",
-                 "vaapi_jpeg_decoder.h",
-                 "vaapi_jpeg_encode_accelerator.cc",
-                 "vaapi_jpeg_encode_accelerator.h",
-                 "vaapi_jpeg_encoder.cc",
-                 "vaapi_jpeg_encoder.h",
-                 "vaapi_video_decode_accelerator.cc",
-                 "vaapi_video_decode_accelerator.h",
-                 "vaapi_video_encode_accelerator.cc",
-                 "vaapi_video_encode_accelerator.h",
-                 "vaapi_wrapper.cc",
-                 "vaapi_wrapper.h",
+                 "vaapi/vaapi_picture_factory.cc",
+                 "vaapi/vaapi_picture_factory.h",
+                 "vaapi/vaapi_video_decode_accelerator.cc",
+                 "vaapi/vaapi_video_decode_accelerator.h",
+                 "vaapi/vaapi_video_encode_accelerator.cc",
+                 "vaapi/vaapi_video_encode_accelerator.h",
+                 "vaapi/vaapi_wrapper.cc",
+                 "vaapi/vaapi_wrapper.h",
                ] + get_target_outputs(":libva_generate_stubs")
     configs += [ "//third_party/libyuv:libyuv_config" ]
     deps += [
@@ -596,7 +596,7 @@ source_set("unit_tests") {
   ]
 
   if (use_vaapi) {
-    sources += [ "vaapi_video_decode_accelerator_unittest.cc" ]
+    sources += [ "vaapi/vaapi_video_decode_accelerator_unittest.cc" ]
     deps += [
       ":gpu",
       "//base/test:test_support",
--- a/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
@@ -17,7 +17,7 @@
 #endif
 
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_jpeg_decode_accelerator.h"
+#include "media/gpu/vaapi/vaapi_jpeg_decode_accelerator.h"
 #endif
 
 #if defined(USE_V4L2_JDA)
--- a/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -34,7 +34,7 @@
 #include "media/gpu/android/device_info.h"
 #endif
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_video_decode_accelerator.h"
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
 #include "ui/gl/gl_implementation.h"
 #endif
 
--- a/media/gpu/gpu_video_encode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_encode_accelerator_factory.cc
@@ -24,7 +24,7 @@
 #include "media/gpu/media_foundation_video_encode_accelerator_win.h"
 #endif
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_video_encode_accelerator.h"
+#include "media/gpu/vaapi/vaapi_video_encode_accelerator.h"
 #endif
 
 namespace media {
--- a/media/gpu/jpeg_decode_accelerator_unittest.cc
+++ b/media/gpu/jpeg_decode_accelerator_unittest.cc
@@ -35,7 +35,7 @@
 #include "ui/gfx/codec/jpeg_codec.h"
 
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #endif
 
 namespace media {
--- a/media/gpu/va_surface.cc
+++ /dev/null
@@ -1,24 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/va_surface.h"
-
-namespace media {
-
-VASurface::VASurface(VASurfaceID va_surface_id,
-                     const gfx::Size& size,
-                     unsigned int format,
-                     const ReleaseCB& release_cb)
-    : va_surface_id_(va_surface_id),
-      size_(size),
-      format_(format),
-      release_cb_(release_cb) {
-  DCHECK(!release_cb_.is_null());
-}
-
-VASurface::~VASurface() {
-  release_cb_.Run(va_surface_id_);
-}
-
-}  // namespace media
--- a/media/gpu/va_surface.h
+++ /dev/null
@@ -1,117 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// This file contains the definition of VASurface class, used for decoding by
-// VaapiVideoDecodeAccelerator and VaapiH264Decoder.
-
-#ifndef MEDIA_GPU_VA_SURFACE_H_
-#define MEDIA_GPU_VA_SURFACE_H_
-
-#include <va/va.h>
-
-#include "base/callback.h"
-#include "base/macros.h"
-#include "base/memory/ref_counted.h"
-#include "media/gpu/media_gpu_export.h"
-#include "ui/gfx/geometry/size.h"
-
-namespace media {
-
-// A VA-API-specific decode surface used by VaapiH264Decoder to decode into
-// and use as reference for decoding other surfaces. It is also handed by the
-// decoder to VaapiVideoDecodeAccelerator when the contents of the surface are
-// ready and should be displayed. VAVDA converts the surface contents into an
-// X/Drm Pixmap bound to a texture for display and releases its reference to it.
-// Decoder releases its references to the surface when it's done decoding and
-// using it as reference. Note that a surface may still be used for reference
-// after it's been sent to output and also after it is no longer used by VAVDA.
-// Thus, the surface can be in use by both VAVDA and the Decoder at the same
-// time, or by either of them, with the restriction that VAVDA will never get
-// the surface until the contents are ready, and it is guaranteed that the
-// contents will not change after that.
-// When both the decoder and VAVDA release their references to the surface,
-// it is freed and the release callback is executed to put the surface back
-// into available surfaces pool, which is managed externally.
-//
-//   VASurfaceID is allocated in VaapiWrapper.
-//        |
-// +----->|
-// |      v
-// | VASurfaceID is put onto VaapiVideoDecodeAccelerator::available_va_surfaces_
-// |      |      list.
-// |      v
-// | VASurfaceID is taken off of the VVDA:available_va_surfaces_ when
-// |      |      VaapiH264Decoder requests more output surfaces, is wrapped into
-// |      |      a VASurface and passed to VaapiH264Decoder.
-// |      v
-// | VASurface is put onto VaapiH264Decoder::available_va_surfaces_, keeping
-// |      |      the only reference to it until it's needed for decoding.
-// |      v
-// | VaapiH264Decoder starts decoding a new frame. It takes a VASurface off of
-// |      |      VHD::available_va_surfaces_ and assigns it to a DecodeSurface,
-// |      |      which now keeps the only reference.
-// |      v
-// | DecodeSurface is used for decoding, putting data into associated VASurface.
-// |      |
-// |      |--------------------------------------------------+
-// |      |                                                  |
-// |      v                                                  v
-// | DecodeSurface is to be output.              VaapiH264Decoder uses the
-// | VaapiH264Decoder passes the associated      DecodeSurface and associated
-// | VASurface to VaapiVideoDecodeAccelerator,   VASurface as reference for
-// | which stores it (taking a ref) on           decoding more frames.
-// | pending_output_cbs_ queue until an output               |
-// | VaapiPicture becomes available.                         v
-// |                 |                           Once the DecodeSurface is not
-// |                 |                           needed as reference anymore,
-// |                 v                           it is released, releasing the
-// | A VaapiPicture becomes available after      associated VASurface reference.
-// | the client of VVDA returns                              |
-// | a PictureBuffer associated with it. VVDA                |
-// | puts the contents of the VASurface into                 |
-// | it and releases the reference to VASurface.             |
-// |                 |                                       |
-// |                 '---------------------------------------'
-// |                                     |
-// |                                     v
-// | Neither VVDA nor VHD hold a reference to VASurface. VASurface is released,
-// | ReleaseCB gets called in its destructor, which puts the associated
-// | VASurfaceID back onto VVDA::available_va_surfaces_.
-// |                                     |
-// '-------------------------------------|
-//                                       |
-//                                       v
-//                       VaapiWrapper frees VASurfaceID.
-//
-class MEDIA_GPU_EXPORT VASurface
-    : public base::RefCountedThreadSafe<VASurface> {
- public:
-  // Provided by user, will be called when all references to the surface
-  // are released.
-  using ReleaseCB = base::Callback<void(VASurfaceID)>;
-
-  VASurface(VASurfaceID va_surface_id,
-            const gfx::Size& size,
-            unsigned int format,
-            const ReleaseCB& release_cb);
-
-  VASurfaceID id() const { return va_surface_id_; }
-  const gfx::Size& size() const { return size_; }
-  unsigned int format() const { return format_; }
-
- private:
-  friend class base::RefCountedThreadSafe<VASurface>;
-  ~VASurface();
-
-  const VASurfaceID va_surface_id_;
-  const gfx::Size size_;
-  const unsigned int format_;
-  const ReleaseCB release_cb_;
-
-  DISALLOW_COPY_AND_ASSIGN(VASurface);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VA_SURFACE_H_
--- /dev/null
+++ b/media/gpu/vaapi/va_surface.cc
@@ -0,0 +1,24 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/va_surface.h"
+
+namespace media {
+
+VASurface::VASurface(VASurfaceID va_surface_id,
+                     const gfx::Size& size,
+                     unsigned int format,
+                     const ReleaseCB& release_cb)
+    : va_surface_id_(va_surface_id),
+      size_(size),
+      format_(format),
+      release_cb_(release_cb) {
+  DCHECK(!release_cb_.is_null());
+}
+
+VASurface::~VASurface() {
+  release_cb_.Run(va_surface_id_);
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/va_surface.h
@@ -0,0 +1,117 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+//
+// This file contains the definition of VASurface class, used for decoding by
+// VaapiVideoDecodeAccelerator and VaapiH264Decoder.
+
+#ifndef MEDIA_GPU_VAAPI_VA_SURFACE_H_
+#define MEDIA_GPU_VAAPI_VA_SURFACE_H_
+
+#include <va/va.h>
+
+#include "base/callback.h"
+#include "base/macros.h"
+#include "base/memory/ref_counted.h"
+#include "media/gpu/media_gpu_export.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace media {
+
+// A VA-API-specific decode surface used by VaapiH264Decoder to decode into
+// and use as reference for decoding other surfaces. It is also handed by the
+// decoder to VaapiVideoDecodeAccelerator when the contents of the surface are
+// ready and should be displayed. VAVDA converts the surface contents into an
+// X/Drm Pixmap bound to a texture for display and releases its reference to it.
+// Decoder releases its references to the surface when it's done decoding and
+// using it as reference. Note that a surface may still be used for reference
+// after it's been sent to output and also after it is no longer used by VAVDA.
+// Thus, the surface can be in use by both VAVDA and the Decoder at the same
+// time, or by either of them, with the restriction that VAVDA will never get
+// the surface until the contents are ready, and it is guaranteed that the
+// contents will not change after that.
+// When both the decoder and VAVDA release their references to the surface,
+// it is freed and the release callback is executed to put the surface back
+// into available surfaces pool, which is managed externally.
+//
+//   VASurfaceID is allocated in VaapiWrapper.
+//        |
+// +----->|
+// |      v
+// | VASurfaceID is put onto VaapiVideoDecodeAccelerator::available_va_surfaces_
+// |      |      list.
+// |      v
+// | VASurfaceID is taken off of the VVDA:available_va_surfaces_ when
+// |      |      VaapiH264Decoder requests more output surfaces, is wrapped into
+// |      |      a VASurface and passed to VaapiH264Decoder.
+// |      v
+// | VASurface is put onto VaapiH264Decoder::available_va_surfaces_, keeping
+// |      |      the only reference to it until it's needed for decoding.
+// |      v
+// | VaapiH264Decoder starts decoding a new frame. It takes a VASurface off of
+// |      |      VHD::available_va_surfaces_ and assigns it to a DecodeSurface,
+// |      |      which now keeps the only reference.
+// |      v
+// | DecodeSurface is used for decoding, putting data into associated VASurface.
+// |      |
+// |      |--------------------------------------------------+
+// |      |                                                  |
+// |      v                                                  v
+// | DecodeSurface is to be output.              VaapiH264Decoder uses the
+// | VaapiH264Decoder passes the associated      DecodeSurface and associated
+// | VASurface to VaapiVideoDecodeAccelerator,   VASurface as reference for
+// | which stores it (taking a ref) on           decoding more frames.
+// | pending_output_cbs_ queue until an output               |
+// | VaapiPicture becomes available.                         v
+// |                 |                           Once the DecodeSurface is not
+// |                 |                           needed as reference anymore,
+// |                 v                           it is released, releasing the
+// | A VaapiPicture becomes available after      associated VASurface reference.
+// | the client of VVDA returns                              |
+// | a PictureBuffer associated with it. VVDA                |
+// | puts the contents of the VASurface into                 |
+// | it and releases the reference to VASurface.             |
+// |                 |                                       |
+// |                 '---------------------------------------'
+// |                                     |
+// |                                     v
+// | Neither VVDA nor VHD hold a reference to VASurface. VASurface is released,
+// | ReleaseCB gets called in its destructor, which puts the associated
+// | VASurfaceID back onto VVDA::available_va_surfaces_.
+// |                                     |
+// '-------------------------------------|
+//                                       |
+//                                       v
+//                       VaapiWrapper frees VASurfaceID.
+//
+class MEDIA_GPU_EXPORT VASurface
+    : public base::RefCountedThreadSafe<VASurface> {
+ public:
+  // Provided by user, will be called when all references to the surface
+  // are released.
+  using ReleaseCB = base::Callback<void(VASurfaceID)>;
+
+  VASurface(VASurfaceID va_surface_id,
+            const gfx::Size& size,
+            unsigned int format,
+            const ReleaseCB& release_cb);
+
+  VASurfaceID id() const { return va_surface_id_; }
+  const gfx::Size& size() const { return size_; }
+  unsigned int format() const { return format_; }
+
+ private:
+  friend class base::RefCountedThreadSafe<VASurface>;
+  ~VASurface();
+
+  const VASurfaceID va_surface_id_;
+  const gfx::Size size_;
+  const unsigned int format_;
+  const ReleaseCB release_cb_;
+
+  DISALLOW_COPY_AND_ASSIGN(VASurface);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VA_SURFACE_H_
--- a/media/gpu/vaapi/vaapi_drm_picture.cc
+++ b/media/gpu/vaapi/vaapi_drm_picture.cc
@@ -5,8 +5,8 @@
 #include "media/gpu/vaapi/vaapi_drm_picture.h"
 
 #include "base/file_descriptor_posix.h"
-#include "media/gpu/va_surface.h"
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #include "ui/gfx/gpu_memory_buffer.h"
 #include "ui/gfx/native_pixmap.h"
 #include "ui/gl/gl_bindings.h"
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_decode_accelerator.cc
@@ -0,0 +1,325 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_jpeg_decode_accelerator.h"
+
+#include <stddef.h>
+#include <string.h>
+
+#include <memory>
+#include <utility>
+
+#include "base/bind.h"
+#include "base/logging.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "base/trace_event/trace_event.h"
+#include "gpu/ipc/service/gpu_channel.h"
+#include "media/base/video_frame.h"
+#include "media/filters/jpeg_parser.h"
+#include "media/gpu/shared_memory_region.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "third_party/libyuv/include/libyuv.h"
+
+#define VLOGF(level) VLOG(level) << __func__ << "(): "
+#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
+
+namespace media {
+
+namespace {
+// UMA errors that the VaapiJpegDecodeAccelerator class reports.
+enum VAJDADecoderFailure {
+  VAAPI_ERROR = 0,
+  VAJDA_DECODER_FAILURES_MAX,
+};
+
+static void ReportToUMA(VAJDADecoderFailure failure) {
+  UMA_HISTOGRAM_ENUMERATION("Media.VAJDA.DecoderFailure", failure,
+                            VAJDA_DECODER_FAILURES_MAX + 1);
+}
+
+static unsigned int VaSurfaceFormatForJpeg(
+    const JpegFrameHeader& frame_header) {
+  // The range of sampling factor is [1, 4]. Pack them into integer to make the
+  // matching code simpler. For example, 0x211 means the sampling factor are 2,
+  // 1, 1 for 3 components.
+  unsigned int h = 0, v = 0;
+  for (int i = 0; i < frame_header.num_components; i++) {
+    DCHECK_LE(frame_header.components[i].horizontal_sampling_factor, 4);
+    DCHECK_LE(frame_header.components[i].vertical_sampling_factor, 4);
+    h = h << 4 | frame_header.components[i].horizontal_sampling_factor;
+    v = v << 4 | frame_header.components[i].vertical_sampling_factor;
+  }
+
+  switch (frame_header.num_components) {
+    case 1:  // Grey image
+      return VA_RT_FORMAT_YUV400;
+
+    case 3:  // Y Cb Cr color image
+      // See https://en.wikipedia.org/wiki/Chroma_subsampling for the
+      // definition of these numbers.
+      if (h == 0x211 && v == 0x211)
+        return VA_RT_FORMAT_YUV420;
+
+      if (h == 0x211 && v == 0x111)
+        return VA_RT_FORMAT_YUV422;
+
+      if (h == 0x111 && v == 0x111)
+        return VA_RT_FORMAT_YUV444;
+
+      if (h == 0x411 && v == 0x111)
+        return VA_RT_FORMAT_YUV411;
+  }
+  VLOGF(1) << "Unsupported sampling factor: num_components="
+           << frame_header.num_components << ", h=" << std::hex << h
+           << ", v=" << v;
+
+  return 0;
+}
+
+}  // namespace
+
+VaapiJpegDecodeAccelerator::DecodeRequest::DecodeRequest(
+    int32_t bitstream_buffer_id,
+    std::unique_ptr<SharedMemoryRegion> shm,
+    const scoped_refptr<VideoFrame>& video_frame)
+    : bitstream_buffer_id(bitstream_buffer_id),
+      shm(std::move(shm)),
+      video_frame(video_frame) {}
+
+VaapiJpegDecodeAccelerator::DecodeRequest::~DecodeRequest() {}
+
+void VaapiJpegDecodeAccelerator::NotifyError(int32_t bitstream_buffer_id,
+                                             Error error) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  VLOGF(1) << "Notifying of error " << error;
+  DCHECK(client_);
+  client_->NotifyError(bitstream_buffer_id, error);
+}
+
+void VaapiJpegDecodeAccelerator::NotifyErrorFromDecoderThread(
+    int32_t bitstream_buffer_id,
+    Error error) {
+  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
+  task_runner_->PostTask(FROM_HERE,
+                         base::Bind(&VaapiJpegDecodeAccelerator::NotifyError,
+                                    weak_this_, bitstream_buffer_id, error));
+}
+
+void VaapiJpegDecodeAccelerator::VideoFrameReady(int32_t bitstream_buffer_id) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  client_->VideoFrameReady(bitstream_buffer_id);
+}
+
+VaapiJpegDecodeAccelerator::VaapiJpegDecodeAccelerator(
+    const scoped_refptr<base::SingleThreadTaskRunner>& io_task_runner)
+    : task_runner_(base::ThreadTaskRunnerHandle::Get()),
+      io_task_runner_(io_task_runner),
+      decoder_thread_("VaapiJpegDecoderThread"),
+      va_surface_id_(VA_INVALID_SURFACE),
+      weak_this_factory_(this) {
+  weak_this_ = weak_this_factory_.GetWeakPtr();
+}
+
+VaapiJpegDecodeAccelerator::~VaapiJpegDecodeAccelerator() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  VLOGF(2) << "Destroying VaapiJpegDecodeAccelerator";
+
+  weak_this_factory_.InvalidateWeakPtrs();
+  decoder_thread_.Stop();
+}
+
+bool VaapiJpegDecodeAccelerator::Initialize(Client* client) {
+  VLOGF(2);
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  client_ = client;
+
+  vaapi_wrapper_ =
+      VaapiWrapper::Create(VaapiWrapper::kDecode, VAProfileJPEGBaseline,
+                           base::Bind(&ReportToUMA, VAAPI_ERROR));
+
+  if (!vaapi_wrapper_.get()) {
+    VLOGF(1) << "Failed initializing VAAPI";
+    return false;
+  }
+
+  if (!decoder_thread_.Start()) {
+    VLOGF(1) << "Failed to start decoding thread.";
+    return false;
+  }
+  decoder_task_runner_ = decoder_thread_.task_runner();
+
+  return true;
+}
+
+bool VaapiJpegDecodeAccelerator::OutputPicture(
+    VASurfaceID va_surface_id,
+    int32_t input_buffer_id,
+    const scoped_refptr<VideoFrame>& video_frame) {
+  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
+
+  TRACE_EVENT1("jpeg", "VaapiJpegDecodeAccelerator::OutputPicture",
+               "input_buffer_id", input_buffer_id);
+
+  DVLOGF(4) << "Outputting VASurface " << va_surface_id
+            << " into video_frame associated with input buffer id "
+            << input_buffer_id;
+
+  VAImage image;
+  VAImageFormat format;
+  const uint32_t kI420Fourcc = VA_FOURCC('I', '4', '2', '0');
+  memset(&image, 0, sizeof(image));
+  memset(&format, 0, sizeof(format));
+  format.fourcc = kI420Fourcc;
+  format.byte_order = VA_LSB_FIRST;
+  format.bits_per_pixel = 12;  // 12 for I420
+
+  uint8_t* mem = nullptr;
+  gfx::Size coded_size = video_frame->coded_size();
+  if (!vaapi_wrapper_->GetVaImage(va_surface_id, &format, coded_size, &image,
+                                  reinterpret_cast<void**>(&mem))) {
+    VLOGF(1) << "Cannot get VAImage";
+    return false;
+  }
+
+  // Copy image content from VAImage to VideoFrame.
+  // The component order of VAImage I420 are Y, U, and V.
+  DCHECK_EQ(image.num_planes, 3u);
+  DCHECK_GE(image.width, coded_size.width());
+  DCHECK_GE(image.height, coded_size.height());
+  const uint8_t* src_y = mem + image.offsets[0];
+  const uint8_t* src_u = mem + image.offsets[1];
+  const uint8_t* src_v = mem + image.offsets[2];
+  size_t src_y_stride = image.pitches[0];
+  size_t src_u_stride = image.pitches[1];
+  size_t src_v_stride = image.pitches[2];
+  uint8_t* dst_y = video_frame->data(VideoFrame::kYPlane);
+  uint8_t* dst_u = video_frame->data(VideoFrame::kUPlane);
+  uint8_t* dst_v = video_frame->data(VideoFrame::kVPlane);
+  size_t dst_y_stride = video_frame->stride(VideoFrame::kYPlane);
+  size_t dst_u_stride = video_frame->stride(VideoFrame::kUPlane);
+  size_t dst_v_stride = video_frame->stride(VideoFrame::kVPlane);
+
+  if (libyuv::I420Copy(src_y, src_y_stride,  // Y
+                       src_u, src_u_stride,  // U
+                       src_v, src_v_stride,  // V
+                       dst_y, dst_y_stride,  // Y
+                       dst_u, dst_u_stride,  // U
+                       dst_v, dst_v_stride,  // V
+                       coded_size.width(), coded_size.height())) {
+    VLOGF(1) << "I420Copy failed";
+    return false;
+  }
+
+  vaapi_wrapper_->ReturnVaImage(&image);
+
+  task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiJpegDecodeAccelerator::VideoFrameReady,
+                            weak_this_, input_buffer_id));
+
+  return true;
+}
+
+void VaapiJpegDecodeAccelerator::DecodeTask(
+    const std::unique_ptr<DecodeRequest>& request) {
+  DVLOGF(4);
+  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT0("jpeg", "DecodeTask");
+
+  JpegParseResult parse_result;
+  if (!ParseJpegPicture(
+          reinterpret_cast<const uint8_t*>(request->shm->memory()),
+          request->shm->size(), &parse_result)) {
+    VLOGF(1) << "ParseJpegPicture failed";
+    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
+                                 PARSE_JPEG_FAILED);
+    return;
+  }
+
+  unsigned int new_va_rt_format =
+      VaSurfaceFormatForJpeg(parse_result.frame_header);
+  if (!new_va_rt_format) {
+    VLOGF(1) << "Unsupported subsampling";
+    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
+                                 UNSUPPORTED_JPEG);
+    return;
+  }
+
+  // Reuse VASurface if size doesn't change.
+  gfx::Size new_coded_size(parse_result.frame_header.coded_width,
+                           parse_result.frame_header.coded_height);
+  if (new_coded_size != coded_size_ || va_surface_id_ == VA_INVALID_SURFACE ||
+      new_va_rt_format != va_rt_format_) {
+    vaapi_wrapper_->DestroySurfaces();
+    va_surface_id_ = VA_INVALID_SURFACE;
+    va_rt_format_ = new_va_rt_format;
+
+    std::vector<VASurfaceID> va_surfaces;
+    if (!vaapi_wrapper_->CreateSurfaces(va_rt_format_, new_coded_size, 1,
+                                        &va_surfaces)) {
+      VLOGF(1) << "Create VA surface failed";
+      NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
+                                   PLATFORM_FAILURE);
+      return;
+    }
+    va_surface_id_ = va_surfaces[0];
+    coded_size_ = new_coded_size;
+  }
+
+  if (!VaapiJpegDecoder::Decode(vaapi_wrapper_.get(), parse_result,
+                                va_surface_id_)) {
+    VLOGF(1) << "Decode JPEG failed";
+    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
+                                 PLATFORM_FAILURE);
+    return;
+  }
+
+  if (!OutputPicture(va_surface_id_, request->bitstream_buffer_id,
+                     request->video_frame)) {
+    VLOGF(1) << "Output picture failed";
+    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
+                                 PLATFORM_FAILURE);
+    return;
+  }
+}
+
+void VaapiJpegDecodeAccelerator::Decode(
+    const BitstreamBuffer& bitstream_buffer,
+    const scoped_refptr<VideoFrame>& video_frame) {
+  DCHECK(io_task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("jpeg", "Decode", "input_id", bitstream_buffer.id());
+
+  DVLOGF(4) << "Mapping new input buffer id: " << bitstream_buffer.id()
+            << " size: " << bitstream_buffer.size();
+
+  // SharedMemoryRegion will take over the |bitstream_buffer.handle()|.
+  std::unique_ptr<SharedMemoryRegion> shm(
+      new SharedMemoryRegion(bitstream_buffer, true));
+
+  if (bitstream_buffer.id() < 0) {
+    VLOGF(1) << "Invalid bitstream_buffer, id: " << bitstream_buffer.id();
+    NotifyErrorFromDecoderThread(bitstream_buffer.id(), INVALID_ARGUMENT);
+    return;
+  }
+
+  if (!shm->Map()) {
+    VLOGF(1) << "Failed to map input buffer";
+    NotifyErrorFromDecoderThread(bitstream_buffer.id(), UNREADABLE_INPUT);
+    return;
+  }
+
+  std::unique_ptr<DecodeRequest> request(
+      new DecodeRequest(bitstream_buffer.id(), std::move(shm), video_frame));
+
+  decoder_task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiJpegDecodeAccelerator::DecodeTask,
+                            base::Unretained(this), base::Passed(&request)));
+}
+
+bool VaapiJpegDecodeAccelerator::IsSupported() {
+  return VaapiWrapper::IsJpegDecodeSupported();
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_decode_accelerator.h
@@ -0,0 +1,121 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODE_ACCELERATOR_H_
+#define MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODE_ACCELERATOR_H_
+
+#include <stdint.h>
+
+#include <memory>
+
+#include "base/macros.h"
+#include "base/memory/linked_ptr.h"
+#include "base/memory/weak_ptr.h"
+#include "base/single_thread_task_runner.h"
+#include "base/synchronization/lock.h"
+#include "base/threading/thread.h"
+#include "media/base/bitstream_buffer.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/shared_memory_region.h"
+#include "media/gpu/vaapi/vaapi_jpeg_decoder.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/jpeg_decode_accelerator.h"
+
+namespace media {
+
+// Class to provide JPEG decode acceleration for Intel systems with hardware
+// support for it, and on which libva is available.
+// Decoding tasks are performed in a separate decoding thread.
+//
+// Threading/life-cycle: this object is created & destroyed on the GPU
+// ChildThread.  A few methods on it are called on the decoder thread which is
+// stopped during |this->Destroy()|, so any tasks posted to the decoder thread
+// can assume |*this| is still alive.  See |weak_this_| below for more details.
+class MEDIA_GPU_EXPORT VaapiJpegDecodeAccelerator
+    : public JpegDecodeAccelerator {
+ public:
+  VaapiJpegDecodeAccelerator(
+      const scoped_refptr<base::SingleThreadTaskRunner>& io_task_runner);
+  ~VaapiJpegDecodeAccelerator() override;
+
+  // JpegDecodeAccelerator implementation.
+  bool Initialize(JpegDecodeAccelerator::Client* client) override;
+  void Decode(const BitstreamBuffer& bitstream_buffer,
+              const scoped_refptr<VideoFrame>& video_frame) override;
+  bool IsSupported() override;
+
+ private:
+  // An input buffer and the corresponding output video frame awaiting
+  // consumption, provided by the client.
+  struct DecodeRequest {
+    DecodeRequest(int32_t bitstream_buffer_id,
+                  std::unique_ptr<SharedMemoryRegion> shm,
+                  const scoped_refptr<VideoFrame>& video_frame);
+    ~DecodeRequest();
+
+    int32_t bitstream_buffer_id;
+    std::unique_ptr<SharedMemoryRegion> shm;
+    scoped_refptr<VideoFrame> video_frame;
+  };
+
+  // Notifies the client that an error has occurred and decoding cannot
+  // continue.
+  void NotifyError(int32_t bitstream_buffer_id, Error error);
+  void NotifyErrorFromDecoderThread(int32_t bitstream_buffer_id, Error error);
+  void VideoFrameReady(int32_t bitstream_buffer_id);
+
+  // Processes one decode |request|.
+  void DecodeTask(const std::unique_ptr<DecodeRequest>& request);
+
+  // Puts contents of |va_surface| into given |video_frame|, releases the
+  // surface and passes the |input_buffer_id| of the resulting picture to
+  // client for output.
+  bool OutputPicture(VASurfaceID va_surface_id,
+                     int32_t input_buffer_id,
+                     const scoped_refptr<VideoFrame>& video_frame);
+
+  // ChildThread's task runner.
+  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
+
+  // GPU IO task runner.
+  scoped_refptr<base::SingleThreadTaskRunner> io_task_runner_;
+
+  // The client of this class.
+  Client* client_;
+
+  // WeakPtr<> pointing to |this| for use in posting tasks from the decoder
+  // thread back to the ChildThread.  Because the decoder thread is a member of
+  // this class, any task running on the decoder thread is guaranteed that this
+  // object is still alive.  As a result, tasks posted from ChildThread to
+  // decoder thread should use base::Unretained(this), and tasks posted from the
+  // decoder thread to the ChildThread should use |weak_this_|.
+  base::WeakPtr<VaapiJpegDecodeAccelerator> weak_this_;
+
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  // Comes after vaapi_wrapper_ to ensure its destructor is executed before
+  // |vaapi_wrapper_| is destroyed.
+  std::unique_ptr<VaapiJpegDecoder> decoder_;
+  base::Thread decoder_thread_;
+  // Use this to post tasks to |decoder_thread_| instead of
+  // |decoder_thread_.task_runner()| because the latter will be NULL once
+  // |decoder_thread_.Stop()| returns.
+  scoped_refptr<base::SingleThreadTaskRunner> decoder_task_runner_;
+
+  // The current VA surface for decoding.
+  VASurfaceID va_surface_id_;
+  // The coded size associated with |va_surface_id_|.
+  gfx::Size coded_size_;
+  // The VA RT format associated with |va_surface_id_|.
+  unsigned int va_rt_format_;
+
+  // The WeakPtrFactory for |weak_this_|.
+  base::WeakPtrFactory<VaapiJpegDecodeAccelerator> weak_this_factory_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiJpegDecodeAccelerator);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODE_ACCELERATOR_H_
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_decoder.cc
@@ -0,0 +1,229 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_jpeg_decoder.h"
+
+#include <stddef.h>
+#include <string.h>
+
+#include "base/logging.h"
+#include "base/macros.h"
+#include "media/filters/jpeg_parser.h"
+
+namespace media {
+
+// VAAPI only support subset of JPEG profiles. This function determines a given
+// parsed JPEG result is supported or not.
+static bool IsVaapiSupportedJpeg(const JpegParseResult& jpeg) {
+  if (jpeg.frame_header.visible_width < 1 ||
+      jpeg.frame_header.visible_height < 1) {
+    DLOG(ERROR) << "width(" << jpeg.frame_header.visible_width
+                << ") and height(" << jpeg.frame_header.visible_height
+                << ") should be at least 1";
+    return false;
+  }
+
+  // Size 64k*64k is the maximum in the JPEG standard. VAAPI doesn't support
+  // resolutions larger than 16k*16k.
+  const int kMaxDimension = 16384;
+  if (jpeg.frame_header.coded_width > kMaxDimension ||
+      jpeg.frame_header.coded_height > kMaxDimension) {
+    DLOG(ERROR) << "VAAPI doesn't support size("
+                << jpeg.frame_header.coded_width << "*"
+                << jpeg.frame_header.coded_height << ") larger than "
+                << kMaxDimension << "*" << kMaxDimension;
+    return false;
+  }
+
+  if (jpeg.frame_header.num_components != 3) {
+    DLOG(ERROR) << "VAAPI doesn't support num_components("
+                << static_cast<int>(jpeg.frame_header.num_components)
+                << ") != 3";
+    return false;
+  }
+
+  if (jpeg.frame_header.components[0].horizontal_sampling_factor <
+          jpeg.frame_header.components[1].horizontal_sampling_factor ||
+      jpeg.frame_header.components[0].horizontal_sampling_factor <
+          jpeg.frame_header.components[2].horizontal_sampling_factor) {
+    DLOG(ERROR) << "VAAPI doesn't supports horizontal sampling factor of Y"
+                << " smaller than Cb and Cr";
+    return false;
+  }
+
+  if (jpeg.frame_header.components[0].vertical_sampling_factor <
+          jpeg.frame_header.components[1].vertical_sampling_factor ||
+      jpeg.frame_header.components[0].vertical_sampling_factor <
+          jpeg.frame_header.components[2].vertical_sampling_factor) {
+    DLOG(ERROR) << "VAAPI doesn't supports vertical sampling factor of Y"
+                << " smaller than Cb and Cr";
+    return false;
+  }
+
+  return true;
+}
+
+static void FillPictureParameters(
+    const JpegFrameHeader& frame_header,
+    VAPictureParameterBufferJPEGBaseline* pic_param) {
+  memset(pic_param, 0, sizeof(*pic_param));
+  pic_param->picture_width = frame_header.coded_width;
+  pic_param->picture_height = frame_header.coded_height;
+  pic_param->num_components = frame_header.num_components;
+
+  for (int i = 0; i < pic_param->num_components; i++) {
+    pic_param->components[i].component_id = frame_header.components[i].id;
+    pic_param->components[i].h_sampling_factor =
+        frame_header.components[i].horizontal_sampling_factor;
+    pic_param->components[i].v_sampling_factor =
+        frame_header.components[i].vertical_sampling_factor;
+    pic_param->components[i].quantiser_table_selector =
+        frame_header.components[i].quantization_table_selector;
+  }
+}
+
+static void FillIQMatrix(const JpegQuantizationTable* q_table,
+                         VAIQMatrixBufferJPEGBaseline* iq_matrix) {
+  memset(iq_matrix, 0, sizeof(*iq_matrix));
+  static_assert(kJpegMaxQuantizationTableNum ==
+                    arraysize(iq_matrix->load_quantiser_table),
+                "max number of quantization table mismatched");
+  for (size_t i = 0; i < kJpegMaxQuantizationTableNum; i++) {
+    if (!q_table[i].valid)
+      continue;
+    iq_matrix->load_quantiser_table[i] = 1;
+    static_assert(
+        arraysize(iq_matrix->quantiser_table[i]) == arraysize(q_table[i].value),
+        "number of quantization entries mismatched");
+    for (size_t j = 0; j < arraysize(q_table[i].value); j++)
+      iq_matrix->quantiser_table[i][j] = q_table[i].value[j];
+  }
+}
+
+static void FillHuffmanTable(const JpegHuffmanTable* dc_table,
+                             const JpegHuffmanTable* ac_table,
+                             VAHuffmanTableBufferJPEGBaseline* huffman_table) {
+  memset(huffman_table, 0, sizeof(*huffman_table));
+  // Use default huffman tables if not specified in header.
+  bool has_huffman_table = false;
+  for (size_t i = 0; i < kJpegMaxHuffmanTableNumBaseline; i++) {
+    if (dc_table[i].valid || ac_table[i].valid) {
+      has_huffman_table = true;
+      break;
+    }
+  }
+  if (!has_huffman_table) {
+    dc_table = kDefaultDcTable;
+    ac_table = kDefaultAcTable;
+  }
+
+  static_assert(kJpegMaxHuffmanTableNumBaseline ==
+                    arraysize(huffman_table->load_huffman_table),
+                "max number of huffman table mismatched");
+  static_assert(sizeof(huffman_table->huffman_table[0].num_dc_codes) ==
+                    sizeof(dc_table[0].code_length),
+                "size of huffman table code length mismatch");
+  static_assert(sizeof(huffman_table->huffman_table[0].dc_values[0]) ==
+                    sizeof(dc_table[0].code_value[0]),
+                "size of huffman table code value mismatch");
+  for (size_t i = 0; i < kJpegMaxHuffmanTableNumBaseline; i++) {
+    if (!dc_table[i].valid || !ac_table[i].valid)
+      continue;
+    huffman_table->load_huffman_table[i] = 1;
+
+    memcpy(huffman_table->huffman_table[i].num_dc_codes,
+           dc_table[i].code_length,
+           sizeof(huffman_table->huffman_table[i].num_dc_codes));
+    memcpy(huffman_table->huffman_table[i].dc_values, dc_table[i].code_value,
+           sizeof(huffman_table->huffman_table[i].dc_values));
+    memcpy(huffman_table->huffman_table[i].num_ac_codes,
+           ac_table[i].code_length,
+           sizeof(huffman_table->huffman_table[i].num_ac_codes));
+    memcpy(huffman_table->huffman_table[i].ac_values, ac_table[i].code_value,
+           sizeof(huffman_table->huffman_table[i].ac_values));
+  }
+}
+
+static void FillSliceParameters(
+    const JpegParseResult& parse_result,
+    VASliceParameterBufferJPEGBaseline* slice_param) {
+  memset(slice_param, 0, sizeof(*slice_param));
+  slice_param->slice_data_size = parse_result.data_size;
+  slice_param->slice_data_offset = 0;
+  slice_param->slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
+  slice_param->slice_horizontal_position = 0;
+  slice_param->slice_vertical_position = 0;
+  slice_param->num_components = parse_result.scan.num_components;
+  for (int i = 0; i < slice_param->num_components; i++) {
+    slice_param->components[i].component_selector =
+        parse_result.scan.components[i].component_selector;
+    slice_param->components[i].dc_table_selector =
+        parse_result.scan.components[i].dc_selector;
+    slice_param->components[i].ac_table_selector =
+        parse_result.scan.components[i].ac_selector;
+  }
+  slice_param->restart_interval = parse_result.restart_interval;
+
+  // Cast to int to prevent overflow.
+  int max_h_factor =
+      parse_result.frame_header.components[0].horizontal_sampling_factor;
+  int max_v_factor =
+      parse_result.frame_header.components[0].vertical_sampling_factor;
+  int mcu_cols = parse_result.frame_header.coded_width / (max_h_factor * 8);
+  DCHECK_GT(mcu_cols, 0);
+  int mcu_rows = parse_result.frame_header.coded_height / (max_v_factor * 8);
+  DCHECK_GT(mcu_rows, 0);
+  slice_param->num_mcus = mcu_rows * mcu_cols;
+}
+
+// static
+bool VaapiJpegDecoder::Decode(VaapiWrapper* vaapi_wrapper,
+                              const JpegParseResult& parse_result,
+                              VASurfaceID va_surface) {
+  DCHECK_NE(va_surface, VA_INVALID_SURFACE);
+  if (!IsVaapiSupportedJpeg(parse_result))
+    return false;
+
+  // Set picture parameters.
+  VAPictureParameterBufferJPEGBaseline pic_param;
+  FillPictureParameters(parse_result.frame_header, &pic_param);
+  if (!vaapi_wrapper->SubmitBuffer(VAPictureParameterBufferType,
+                                   sizeof(pic_param), &pic_param))
+    return false;
+
+  // Set quantization table.
+  VAIQMatrixBufferJPEGBaseline iq_matrix;
+  FillIQMatrix(parse_result.q_table, &iq_matrix);
+  if (!vaapi_wrapper->SubmitBuffer(VAIQMatrixBufferType, sizeof(iq_matrix),
+                                   &iq_matrix))
+    return false;
+
+  // Set huffman table.
+  VAHuffmanTableBufferJPEGBaseline huffman_table;
+  FillHuffmanTable(parse_result.dc_table, parse_result.ac_table,
+                   &huffman_table);
+  if (!vaapi_wrapper->SubmitBuffer(VAHuffmanTableBufferType,
+                                   sizeof(huffman_table), &huffman_table))
+    return false;
+
+  // Set slice parameters.
+  VASliceParameterBufferJPEGBaseline slice_param;
+  FillSliceParameters(parse_result, &slice_param);
+  if (!vaapi_wrapper->SubmitBuffer(VASliceParameterBufferType,
+                                   sizeof(slice_param), &slice_param))
+    return false;
+
+  // Set scan data.
+  if (!vaapi_wrapper->SubmitBuffer(VASliceDataBufferType,
+                                   parse_result.data_size,
+                                   const_cast<char*>(parse_result.data)))
+    return false;
+
+  if (!vaapi_wrapper->ExecuteAndDestroyPendingBuffers(va_surface))
+    return false;
+
+  return true;
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_decoder.h
@@ -0,0 +1,43 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODER_H_
+#define MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODER_H_
+
+#include "base/macros.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+
+namespace media {
+
+struct JpegParseResult;
+
+// A JPEG decoder that utilizes VA-API hardware video decode acceleration on
+// Intel systems. Provides functionality to allow plugging VAAPI HW
+// acceleration into the JpegDecodeAccelerator framework.
+//
+// Clients of this class are expected to manage VA surfaces created via
+// VaapiWrapper, parse JPEG picture via ParseJpegPicture, and then pass
+// them to this class.
+class MEDIA_GPU_EXPORT VaapiJpegDecoder {
+ public:
+  // Decode a JPEG picture. It will fill VA-API parameters and call
+  // corresponding VA-API methods according to parsed JPEG result
+  // |parse_result|. Decoded data will be outputted to the given |va_surface|.
+  // Return false on failure.
+  // |vaapi_wrapper| should be initialized in kDecode mode with
+  // VAProfileJPEGBaseline profile.
+  // |va_surface| should be created with size at least as large as the picture
+  // size.
+  static bool Decode(VaapiWrapper* vaapi_wrapper,
+                     const JpegParseResult& parse_result,
+                     VASurfaceID va_surface);
+
+ private:
+  DISALLOW_IMPLICIT_CONSTRUCTORS(VaapiJpegDecoder);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_JPEG_DECODER_H_
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_decoder_unittest.cc
@@ -0,0 +1,139 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include <stdint.h>
+#include <string.h>
+
+#include <string>
+
+// This has to be included first.
+// See http://code.google.com/p/googletest/issues/detail?id=371
+#include "testing/gtest/include/gtest/gtest.h"
+
+#include "base/at_exit.h"
+#include "base/bind.h"
+#include "base/files/file_util.h"
+#include "base/logging.h"
+#include "base/md5.h"
+#include "base/path_service.h"
+#include "base/strings/string_piece.h"
+#include "media/base/test_data_util.h"
+#include "media/base/video_frame.h"
+#include "media/filters/jpeg_parser.h"
+#include "media/gpu/vaapi/vaapi_jpeg_decoder.h"
+
+namespace media {
+namespace {
+
+const char* kTestFilename = "pixel-1280x720.jpg";
+const char* kExpectedMd5Sum = "6e9e1716073c9a9a1282e3f0e0dab743";
+
+void LogOnError() {
+  LOG(FATAL) << "Oh noes! Decoder failed";
+}
+
+class VaapiJpegDecoderTest : public ::testing::Test {
+ protected:
+  VaapiJpegDecoderTest() {}
+
+  void SetUp() override {
+    base::Closure report_error_cb = base::Bind(&LogOnError);
+    wrapper_ = VaapiWrapper::Create(VaapiWrapper::kDecode,
+                                    VAProfileJPEGBaseline, report_error_cb);
+    ASSERT_TRUE(wrapper_);
+
+    base::FilePath input_file = GetTestDataFilePath(kTestFilename);
+
+    ASSERT_TRUE(base::ReadFileToString(input_file, &jpeg_data_))
+        << "failed to read input data from " << input_file.value();
+  }
+
+  void TearDown() override { wrapper_ = nullptr; }
+
+  bool VerifyDecode(const JpegParseResult& parse_result,
+                    const std::string& md5sum);
+
+ protected:
+  scoped_refptr<VaapiWrapper> wrapper_;
+  std::string jpeg_data_;
+};
+
+bool VaapiJpegDecoderTest::VerifyDecode(const JpegParseResult& parse_result,
+                                        const std::string& expected_md5sum) {
+  gfx::Size size(parse_result.frame_header.coded_width,
+                 parse_result.frame_header.coded_height);
+
+  std::vector<VASurfaceID> va_surfaces;
+  if (!wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, size, 1, &va_surfaces))
+    return false;
+
+  if (!VaapiJpegDecoder::Decode(wrapper_.get(), parse_result, va_surfaces[0])) {
+    LOG(ERROR) << "Decode failed";
+    return false;
+  }
+
+  VAImage image;
+  VAImageFormat format;
+  const uint32_t kI420Fourcc = VA_FOURCC('I', '4', '2', '0');
+  memset(&image, 0, sizeof(image));
+  memset(&format, 0, sizeof(format));
+  format.fourcc = kI420Fourcc;
+  format.byte_order = VA_LSB_FIRST;
+  format.bits_per_pixel = 12;  // 12 for I420
+
+  void* mem;
+  if (!wrapper_->GetVaImage(va_surfaces[0], &format, size, &image, &mem)) {
+    LOG(ERROR) << "Cannot get VAImage";
+    return false;
+  }
+  EXPECT_EQ(kI420Fourcc, image.format.fourcc);
+
+  base::StringPiece result(reinterpret_cast<const char*>(mem),
+                           VideoFrame::AllocationSize(PIXEL_FORMAT_I420, size));
+  EXPECT_EQ(expected_md5sum, base::MD5String(result));
+
+  wrapper_->ReturnVaImage(&image);
+
+  return true;
+}
+
+TEST_F(VaapiJpegDecoderTest, DecodeSuccess) {
+  JpegParseResult parse_result;
+  ASSERT_TRUE(
+      ParseJpegPicture(reinterpret_cast<const uint8_t*>(jpeg_data_.data()),
+                       jpeg_data_.size(), &parse_result));
+
+  EXPECT_TRUE(VerifyDecode(parse_result, kExpectedMd5Sum));
+}
+
+TEST_F(VaapiJpegDecoderTest, DecodeFail) {
+  JpegParseResult parse_result;
+  ASSERT_TRUE(
+      ParseJpegPicture(reinterpret_cast<const uint8_t*>(jpeg_data_.data()),
+                       jpeg_data_.size(), &parse_result));
+
+  // Not supported by VAAPI.
+  parse_result.frame_header.num_components = 1;
+  parse_result.scan.num_components = 1;
+
+  gfx::Size size(parse_result.frame_header.coded_width,
+                 parse_result.frame_header.coded_height);
+
+  std::vector<VASurfaceID> va_surfaces;
+  ASSERT_TRUE(
+      wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, size, 1, &va_surfaces));
+
+  EXPECT_FALSE(
+      VaapiJpegDecoder::Decode(wrapper_.get(), parse_result, va_surfaces[0]));
+}
+
+}  // namespace
+}  // namespace media
+
+int main(int argc, char** argv) {
+  testing::InitGoogleTest(&argc, argv);
+  base::AtExitManager exit_manager;
+  media::VaapiWrapper::PreSandboxInitialization();
+  return RUN_ALL_TESTS();
+}
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_encode_accelerator.cc
@@ -0,0 +1,268 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_jpeg_encode_accelerator.h"
+
+#include <stddef.h>
+
+#include <memory>
+#include <utility>
+
+#include "base/bind.h"
+#include "base/logging.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/sequence_checker.h"
+#include "base/task_scheduler/post_task.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "base/trace_event/trace_event.h"
+#include "media/base/bind_to_current_loop.h"
+#include "media/base/video_frame.h"
+#include "media/gpu/vaapi/vaapi_jpeg_encoder.h"
+
+namespace media {
+
+namespace {
+
+// UMA results that the VaapiJpegEncodeAccelerator class reports.
+// These values are persisted to logs, and should therefore never be renumbered
+// nor reused.
+enum VAJEAEncoderResult {
+  VAAPI_SUCCESS = 0,
+  VAAPI_ERROR,
+  VAJEA_ENCODER_RESULT_MAX = VAAPI_ERROR,
+};
+
+static void ReportToUMA(VAJEAEncoderResult result) {
+  UMA_HISTOGRAM_ENUMERATION("Media.VAJEA.EncoderResult", result,
+                            VAJEAEncoderResult::VAJEA_ENCODER_RESULT_MAX + 1);
+}
+}  // namespace
+
+VaapiJpegEncodeAccelerator::EncodeRequest::EncodeRequest(
+    scoped_refptr<media::VideoFrame> video_frame,
+    std::unique_ptr<SharedMemoryRegion> shm,
+    int quality)
+    : video_frame(std::move(video_frame)),
+      shm(std::move(shm)),
+      quality(quality) {}
+
+VaapiJpegEncodeAccelerator::EncodeRequest::~EncodeRequest() {}
+
+class VaapiJpegEncodeAccelerator::Encoder {
+ public:
+  Encoder(scoped_refptr<VaapiWrapper> vaapi_wrapper,
+          base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb,
+          base::RepeatingCallback<void(int, Status)> notify_error_cb);
+  ~Encoder();
+
+  // Processes one encode |request|.
+  void EncodeTask(std::unique_ptr<EncodeRequest> request);
+
+ private:
+  // |cached_output_buffer_id_| is the last allocated VABuffer during
+  // EncodeTask() and |cached_output_buffer_size_| is the size of it.
+  // If the next call to EncodeTask() does not require a buffer bigger than
+  // |cached_output_buffer_size_|, |cached_output_buffer_id_| will be reused.
+  size_t cached_output_buffer_size_;
+  VABufferID cached_output_buffer_id_;
+
+  std::unique_ptr<VaapiJpegEncoder> jpeg_encoder_;
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb_;
+  base::RepeatingCallback<void(int, Status)> notify_error_cb_;
+
+  SEQUENCE_CHECKER(sequence_checker_);
+
+  DISALLOW_COPY_AND_ASSIGN(Encoder);
+};
+
+VaapiJpegEncodeAccelerator::Encoder::Encoder(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb,
+    base::RepeatingCallback<void(int, Status)> notify_error_cb)
+    : cached_output_buffer_size_(0),
+      jpeg_encoder_(new VaapiJpegEncoder(vaapi_wrapper)),
+      vaapi_wrapper_(std::move(vaapi_wrapper)),
+      video_frame_ready_cb_(std::move(video_frame_ready_cb)),
+      notify_error_cb_(std::move(notify_error_cb)) {
+  DETACH_FROM_SEQUENCE(sequence_checker_);
+}
+
+VaapiJpegEncodeAccelerator::Encoder::~Encoder() {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+}
+
+void VaapiJpegEncodeAccelerator::Encoder::EncodeTask(
+    std::unique_ptr<EncodeRequest> request) {
+  TRACE_EVENT0("jpeg", "EncodeTask");
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  const int video_frame_id = request->video_frame->unique_id();
+  gfx::Size input_size = request->video_frame->coded_size();
+  std::vector<VASurfaceID> va_surfaces;
+  if (!vaapi_wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, input_size, 1,
+                                      &va_surfaces)) {
+    VLOG(1) << "Failed to create VA surface";
+    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
+    return;
+  }
+  VASurfaceID va_surface_id = va_surfaces[0];
+
+  if (!vaapi_wrapper_->UploadVideoFrameToSurface(request->video_frame,
+                                                 va_surface_id)) {
+    VLOG(1) << "Failed to upload video frame to VA surface";
+    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
+    return;
+  }
+
+  // Create output buffer for encoding result.
+  size_t max_coded_buffer_size =
+      VaapiJpegEncoder::GetMaxCodedBufferSize(input_size);
+  if (max_coded_buffer_size > cached_output_buffer_size_) {
+    vaapi_wrapper_->DestroyCodedBuffers();
+    cached_output_buffer_size_ = 0;
+
+    VABufferID output_buffer_id;
+    if (!vaapi_wrapper_->CreateCodedBuffer(max_coded_buffer_size,
+                                           &output_buffer_id)) {
+      VLOG(1) << "Failed to create VA buffer for encoding output";
+      notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
+      return;
+    }
+    cached_output_buffer_size_ = max_coded_buffer_size;
+    cached_output_buffer_id_ = output_buffer_id;
+  }
+
+  if (!jpeg_encoder_->Encode(input_size, request->quality, va_surface_id,
+                             cached_output_buffer_id_)) {
+    VLOG(1) << "Encode JPEG failed";
+    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
+    return;
+  }
+
+  // Get the encoded output. DownloadFromCodedBuffer() is a blocking call. It
+  // would wait until encoding is finished.
+  size_t encoded_size = 0;
+  if (!vaapi_wrapper_->DownloadFromCodedBuffer(
+          cached_output_buffer_id_, va_surface_id,
+          static_cast<uint8_t*>(request->shm->memory()), request->shm->size(),
+          &encoded_size)) {
+    VLOG(1) << "Failed to retrieve output image from VA coded buffer";
+    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
+  }
+
+  video_frame_ready_cb_.Run(request->video_frame->unique_id(), encoded_size);
+}
+
+VaapiJpegEncodeAccelerator::VaapiJpegEncodeAccelerator(
+    scoped_refptr<base::SingleThreadTaskRunner> io_task_runner)
+    : task_runner_(base::ThreadTaskRunnerHandle::Get()),
+      io_task_runner_(std::move(io_task_runner)),
+      weak_this_factory_(this) {
+  weak_this_ = weak_this_factory_.GetWeakPtr();
+}
+
+VaapiJpegEncodeAccelerator::~VaapiJpegEncodeAccelerator() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  DVLOG(1) << "Destroying VaapiJpegEncodeAccelerator";
+
+  weak_this_factory_.InvalidateWeakPtrs();
+  encoder_task_runner_->DeleteSoon(FROM_HERE, std::move(encoder_));
+}
+
+void VaapiJpegEncodeAccelerator::NotifyError(int video_frame_id,
+                                             Status status) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  DLOG(ERROR) << "Notifying error: " << status;
+  DCHECK(client_);
+  client_->NotifyError(video_frame_id, status);
+}
+
+void VaapiJpegEncodeAccelerator::VideoFrameReady(int video_frame_id,
+                                                 size_t encoded_picture_size) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  ReportToUMA(VAJEAEncoderResult::VAAPI_SUCCESS);
+
+  client_->VideoFrameReady(video_frame_id, encoded_picture_size);
+}
+
+JpegEncodeAccelerator::Status VaapiJpegEncodeAccelerator::Initialize(
+    JpegEncodeAccelerator::Client* client) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (!VaapiWrapper::IsJpegEncodeSupported()) {
+    return HW_JPEG_ENCODE_NOT_SUPPORTED;
+  }
+
+  client_ = client;
+  scoped_refptr<VaapiWrapper> vaapi_wrapper = VaapiWrapper::Create(
+      VaapiWrapper::kEncode, VAProfileJPEGBaseline,
+      base::Bind(&ReportToUMA, VAJEAEncoderResult::VAAPI_ERROR));
+
+  if (!vaapi_wrapper) {
+    VLOG(1) << "Failed initializing VAAPI";
+    return PLATFORM_FAILURE;
+  }
+
+  encoder_task_runner_ = base::CreateSingleThreadTaskRunnerWithTraits(
+      {base::MayBlock(), base::TaskPriority::USER_BLOCKING});
+  if (!encoder_task_runner_) {
+    VLOG(1) << "Failed to create encoder task runner.";
+    return THREAD_CREATION_FAILED;
+  }
+
+  encoder_ = std::make_unique<Encoder>(
+      std::move(vaapi_wrapper),
+      BindToCurrentLoop(base::BindRepeating(
+          &VaapiJpegEncodeAccelerator::VideoFrameReady, weak_this_)),
+      BindToCurrentLoop(base::BindRepeating(
+          &VaapiJpegEncodeAccelerator::NotifyError, weak_this_)));
+
+  return ENCODE_OK;
+}
+
+size_t VaapiJpegEncodeAccelerator::GetMaxCodedBufferSize(
+    const gfx::Size& picture_size) {
+  return VaapiJpegEncoder::GetMaxCodedBufferSize(picture_size);
+}
+
+void VaapiJpegEncodeAccelerator::Encode(
+    scoped_refptr<media::VideoFrame> video_frame,
+    int quality,
+    const BitstreamBuffer& bitstream_buffer) {
+  DCHECK(io_task_runner_->BelongsToCurrentThread());
+
+  int video_frame_id = video_frame->unique_id();
+  TRACE_EVENT1("jpeg", "Encode", "input_id", video_frame_id);
+
+  // TODO(shenghao): support other YUV formats.
+  if (video_frame->format() != VideoPixelFormat::PIXEL_FORMAT_I420) {
+    VLOG(1) << "Unsupported input format: " << video_frame->format();
+    task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiJpegEncodeAccelerator::NotifyError,
+                              weak_this_, video_frame_id, INVALID_ARGUMENT));
+    return;
+  }
+
+  // SharedMemoryRegion will take ownership of the |bitstream_buffer.handle()|.
+  auto shm = std::make_unique<SharedMemoryRegion>(bitstream_buffer, false);
+  if (!shm->Map()) {
+    VLOG(1) << "Failed to map output buffer";
+    task_runner_->PostTask(
+        FROM_HERE,
+        base::Bind(&VaapiJpegEncodeAccelerator::NotifyError, weak_this_,
+                   video_frame_id, INACCESSIBLE_OUTPUT_BUFFER));
+    return;
+  }
+
+  auto request = std::make_unique<EncodeRequest>(std::move(video_frame),
+                                                 std::move(shm), quality);
+  encoder_task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(&VaapiJpegEncodeAccelerator::Encoder::EncodeTask,
+                 base::Unretained(encoder_.get()), base::Passed(&request)));
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_encode_accelerator.h
@@ -0,0 +1,96 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
+#define MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
+
+#include <memory>
+
+#include "base/macros.h"
+#include "base/memory/weak_ptr.h"
+#include "base/single_thread_task_runner.h"
+#include "media/base/bitstream_buffer.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/shared_memory_region.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/jpeg_encode_accelerator.h"
+
+namespace media {
+
+// Class to provide JPEG encode acceleration for Intel systems with hardware
+// support for it, and on which libva is available.
+// Encoding tasks are performed in a separate encoding thread.
+//
+// Threading/life-cycle: this object is created & destroyed on the GPU
+// ChildThread.  Methods in nested class Encoder are called on the encoder
+// thread which is stopped during destructor, so the callbacks bound with
+// a weak this can be run on the encoder thread because it can assume
+// VaapiJpegEncodeAccelerator is still alive.
+class MEDIA_GPU_EXPORT VaapiJpegEncodeAccelerator
+    : public JpegEncodeAccelerator {
+ public:
+  explicit VaapiJpegEncodeAccelerator(
+      scoped_refptr<base::SingleThreadTaskRunner> io_task_runner);
+  ~VaapiJpegEncodeAccelerator() override;
+
+  // JpegEncodeAccelerator implementation.
+  Status Initialize(JpegEncodeAccelerator::Client* client) override;
+  size_t GetMaxCodedBufferSize(const gfx::Size& picture_size) override;
+
+  // Currently only I420 format is supported for |video_frame|.
+  void Encode(scoped_refptr<media::VideoFrame> video_frame,
+              int quality,
+              const BitstreamBuffer& bitstream_buffer) override;
+
+ private:
+  // An input video frame and the corresponding output buffer awaiting
+  // consumption, provided by the client.
+  struct EncodeRequest {
+    EncodeRequest(scoped_refptr<media::VideoFrame> video_frame,
+                  std::unique_ptr<SharedMemoryRegion> shm,
+                  int quality);
+    ~EncodeRequest();
+
+    scoped_refptr<media::VideoFrame> video_frame;
+    std::unique_ptr<SharedMemoryRegion> shm;
+    int quality;
+
+    DISALLOW_COPY_AND_ASSIGN(EncodeRequest);
+  };
+
+  // The Encoder class is a collection of methods that run on
+  // |encoder_task_runner_|.
+  class Encoder;
+
+  // Notifies the client that an error has occurred and encoding cannot
+  // continue.
+  void NotifyError(int video_frame_id, Status status);
+
+  void VideoFrameReady(int video_frame_id, size_t encoded_picture_size);
+
+  // ChildThread's task runner.
+  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
+
+  // GPU IO task runner.
+  scoped_refptr<base::SingleThreadTaskRunner> io_task_runner_;
+
+  // The client of this class.
+  Client* client_;
+
+  // Use this to post tasks to encoder thread.
+  scoped_refptr<base::SingleThreadTaskRunner> encoder_task_runner_;
+
+  std::unique_ptr<Encoder> encoder_;
+
+  // |weak_this_| is used to post tasks from |encoder_task_runner_| to
+  // |task_runner_|.
+  base::WeakPtr<VaapiJpegEncodeAccelerator> weak_this_;
+  base::WeakPtrFactory<VaapiJpegEncodeAccelerator> weak_this_factory_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiJpegEncodeAccelerator);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_encoder.cc
@@ -0,0 +1,427 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_jpeg_encoder.h"
+
+#include <stddef.h>
+#include <string.h>
+#include <array>
+
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/numerics/safe_conversions.h"
+#include "media/filters/jpeg_parser.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+
+#define ARRAY_MEMCPY_CHECKED(to, from)                               \
+  do {                                                               \
+    static_assert(sizeof(to) == sizeof(from),                        \
+                  #from " and " #to " arrays must be of same size"); \
+    memcpy(to, from, sizeof(to));                                    \
+  } while (0)
+
+namespace media {
+
+namespace {
+
+// JPEG header only uses 2 bytes to represent width and height.
+const int kMaxDimension = 65535;
+const size_t kDctSize2 = 64;
+const size_t kNumDcRunSizeBits = 16;
+const size_t kNumAcRunSizeBits = 16;
+const size_t kNumDcCodeWordsHuffVal = 12;
+const size_t kNumAcCodeWordsHuffVal = 162;
+const size_t kJpegHeaderSize = 83 + (kDctSize2 * 2) + (kNumDcRunSizeBits * 2) +
+                               (kNumDcCodeWordsHuffVal * 2) +
+                               (kNumAcRunSizeBits * 2) +
+                               (kNumAcCodeWordsHuffVal * 2);
+
+const uint8_t kZigZag8x8[64] = {
+    0,  1,  8,  16, 9,  2,  3,  10, 17, 24, 32, 25, 18, 11, 4,  5,
+    12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6,  7,  14, 21, 28,
+    35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,
+    58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63};
+
+const JpegQuantizationTable kDefaultQuantTable[2] = {
+    // Table K.1 Luminance quantization table values.
+    {
+        true,
+        {16, 11, 10, 16, 24,  40,  51,  61,  12, 12, 14, 19, 26,  58,  60,  55,
+         14, 13, 16, 24, 40,  57,  69,  56,  14, 17, 22, 29, 51,  87,  80,  62,
+         18, 22, 37, 56, 68,  109, 103, 77,  24, 35, 55, 64, 81,  104, 113, 92,
+         49, 64, 78, 87, 103, 121, 120, 101, 72, 92, 95, 98, 112, 100, 103, 99},
+    },
+    // Table K.2 Chrominance quantization table values.
+    {
+        true,
+        {17, 18, 24, 47, 99, 99, 99, 99, 18, 21, 26, 66, 99, 99, 99, 99,
+         24, 26, 56, 99, 99, 99, 99, 99, 47, 66, 99, 99, 99, 99, 99, 99,
+         99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99,
+         99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99},
+    },
+};
+
+using JPEGHeader = uint8_t[kJpegHeaderSize];
+
+void FillPictureParameters(const gfx::Size& input_size,
+                           int quality,
+                           VABufferID output_buffer_id,
+                           VAEncPictureParameterBufferJPEG* pic_param) {
+  pic_param->picture_width = input_size.width();
+  pic_param->picture_height = input_size.height();
+  pic_param->num_components = 3;
+
+  // Output buffer.
+  pic_param->coded_buf = output_buffer_id;
+  pic_param->quality = quality;
+  // Profile = Baseline.
+  pic_param->pic_flags.bits.profile = 0;
+  // Sequential encoding.
+  pic_param->pic_flags.bits.progressive = 0;
+  // Uses Huffman coding.
+  pic_param->pic_flags.bits.huffman = 1;
+  // Input format is interleaved (YUV).
+  pic_param->pic_flags.bits.interleaved = 0;
+  // Non-differential Encoding.
+  pic_param->pic_flags.bits.differential = 0;
+  // Only 8 bit sample depth is currently supported.
+  pic_param->sample_bit_depth = 8;
+  pic_param->num_scan = 1;
+}
+
+void FillQMatrix(VAQMatrixBufferJPEG* q_matrix) {
+  // Fill the raw, unscaled quantization tables for libva. The VAAPI driver is
+  // responsible for scaling the quantization tables based on picture
+  // parameter quality.
+  const JpegQuantizationTable& luminance = kDefaultQuantTable[0];
+  static_assert(
+      arraysize(luminance.value) == arraysize(q_matrix->lum_quantiser_matrix),
+      "Luminance quantization table size mismatch.");
+  static_assert(arraysize(kZigZag8x8) == arraysize(luminance.value),
+                "Luminance quantization table size mismatch.");
+  q_matrix->load_lum_quantiser_matrix = 1;
+  for (size_t i = 0; i < arraysize(kZigZag8x8); i++) {
+    q_matrix->lum_quantiser_matrix[i] = luminance.value[kZigZag8x8[i]];
+  }
+
+  const JpegQuantizationTable& chrominance = kDefaultQuantTable[1];
+  static_assert(arraysize(chrominance.value) ==
+                    arraysize(q_matrix->chroma_quantiser_matrix),
+                "Chrominance quantization table size mismatch.");
+  static_assert(arraysize(kZigZag8x8) == arraysize(chrominance.value),
+                "Chrominance quantization table size mismatch.");
+  q_matrix->load_chroma_quantiser_matrix = 1;
+  for (size_t i = 0; i < arraysize(kZigZag8x8); i++) {
+    q_matrix->chroma_quantiser_matrix[i] = chrominance.value[kZigZag8x8[i]];
+  }
+}
+
+void FillHuffmanTableParameters(
+    VAHuffmanTableBufferJPEGBaseline* huff_table_param) {
+  static_assert(arraysize(kDefaultDcTable) == arraysize(kDefaultAcTable),
+                "DC table and AC table size mismatch.");
+  static_assert(
+      arraysize(kDefaultDcTable) == arraysize(huff_table_param->huffman_table),
+      "DC table and destination table size mismatch.");
+
+  for (size_t i = 0; i < arraysize(kDefaultDcTable); ++i) {
+    const JpegHuffmanTable& dcTable = kDefaultDcTable[i];
+    const JpegHuffmanTable& acTable = kDefaultAcTable[i];
+    huff_table_param->load_huffman_table[i] = true;
+
+    // Load DC Table.
+    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].num_dc_codes,
+                         dcTable.code_length);
+    // |code_values| of JpegHuffmanTable needs to hold DC and AC code values
+    // so it has different size than
+    // |huff_table_param->huffman_table[i].dc_values|. Therefore we can't use
+    // ARRAY_MEMCPY_CHECKED() here.
+    static_assert(arraysize(huff_table_param->huffman_table[i].dc_values) <=
+                      arraysize(dcTable.code_value),
+                  "DC table code value array too small.");
+    memcpy(huff_table_param->huffman_table[i].dc_values, &dcTable.code_value[0],
+           sizeof(huff_table_param->huffman_table[i].dc_values));
+
+    // Load AC Table.
+    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].num_ac_codes,
+                         acTable.code_length);
+    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].ac_values,
+                         acTable.code_value);
+
+    memset(huff_table_param->huffman_table[i].pad, 0,
+           sizeof(huff_table_param->huffman_table[i].pad));
+  }
+}
+
+void FillSliceParameters(VAEncSliceParameterBufferJPEG* slice_param) {
+  slice_param->restart_interval = 0;
+  slice_param->num_components = 3;
+
+  slice_param->components[0].component_selector = 1;
+  slice_param->components[0].dc_table_selector = 0;
+  slice_param->components[0].ac_table_selector = 0;
+
+  slice_param->components[1].component_selector = 2;
+  slice_param->components[1].dc_table_selector = 1;
+  slice_param->components[1].ac_table_selector = 1;
+
+  slice_param->components[2].component_selector = 3;
+  slice_param->components[2].dc_table_selector = 1;
+  slice_param->components[2].ac_table_selector = 1;
+}
+
+size_t FillJpegHeader(const gfx::Size& input_size,
+                      int quality,
+                      JPEGHeader& header) {
+  unsigned int width = input_size.width();
+  unsigned int height = input_size.height();
+
+  size_t idx = 0;
+
+  // Start Of Input.
+  static const uint8_t kSOI[] = {0xFF, JPEG_SOI};
+  memcpy(header, kSOI, sizeof(kSOI));
+  idx += sizeof(kSOI);
+
+  // Application Segment - JFIF standard 1.01.
+  // TODO(shenghao): Use Exif (JPEG_APP1) instead.
+  static const uint8_t kAppSegment[] = {
+      0xFF, JPEG_APP0, 0x00,
+      0x10,  // Segment length:16 (2-byte).
+      0x4A,  // J
+      0x46,  // F
+      0x49,  // I
+      0x46,  // F
+      0x00,  // 0
+      0x01,  // Major version.
+      0x01,  // Minor version.
+      0x01,  // Density units 0:no units, 1:pixels per inch,
+             // 2: pixels per cm.
+      0x00,
+      0x48,  // X density (2-byte).
+      0x00,
+      0x48,  // Y density (2-byte).
+      0x00,  // Thumbnail width.
+      0x00   // Thumbnail height.
+  };
+  memcpy(header + idx, kAppSegment, sizeof(kAppSegment));
+  idx += sizeof(kAppSegment);
+
+  if (quality <= 0) {
+    quality = 1;
+  }
+
+  // Normalize quality factor.
+  // Unlike VAQMatrixBufferJPEG, we have to scale quantization table in JPEG
+  // header by ourselves.
+  uint32_t quality_normalized = base::saturated_cast<uint32_t>(
+      (quality < 50) ? (5000 / quality) : (200 - (quality * 2)));
+
+  // Quantization Tables.
+  for (size_t i = 0; i < 2; ++i) {
+    const uint8_t kQuantSegment[] = {
+        0xFF, JPEG_DQT, 0x00,
+        0x03 + kDctSize2,        // Segment length:67 (2-byte).
+        static_cast<uint8_t>(i)  // Precision (4-bit high) = 0,
+                                 // Index (4-bit low) = i.
+    };
+    memcpy(header + idx, kQuantSegment, sizeof(kQuantSegment));
+    idx += sizeof(kQuantSegment);
+
+    const JpegQuantizationTable& quant_table = kDefaultQuantTable[i];
+    for (size_t j = 0; j < kDctSize2; ++j) {
+      uint32_t scaled_quant_value =
+          (quant_table.value[kZigZag8x8[j]] * quality_normalized) / 100;
+      scaled_quant_value = std::min(255u, std::max(1u, scaled_quant_value));
+      header[idx++] = static_cast<uint8_t>(scaled_quant_value);
+    }
+  }
+
+  // Start of Frame - Baseline.
+  const uint8_t kStartOfFrame[] = {
+      0xFF,
+      JPEG_SOF0,  // Baseline.
+      0x00,
+      0x11,  // Segment length:17 (2-byte).
+      8,     // Data precision.
+      static_cast<uint8_t>((height >> 8) & 0xFF),
+      static_cast<uint8_t>(height & 0xFF),
+      static_cast<uint8_t>((width >> 8) & 0xFF),
+      static_cast<uint8_t>(width & 0xFF),
+      0x03,  // Number of Components.
+  };
+  memcpy(header + idx, kStartOfFrame, sizeof(kStartOfFrame));
+  idx += sizeof(kStartOfFrame);
+  for (uint8_t i = 0; i < 3; ++i) {
+    // These are the values for U and V planes.
+    uint8_t h_sample_factor = 1;
+    uint8_t v_sample_factor = 1;
+    uint8_t quant_table_number = 1;
+    if (!i) {
+      // These are the values for Y plane.
+      h_sample_factor = 2;
+      v_sample_factor = 2;
+      quant_table_number = 0;
+    }
+
+    header[idx++] = i + 1;
+    // Horizontal Sample Factor (4-bit high),
+    // Vertical Sample Factor (4-bit low).
+    header[idx++] = (h_sample_factor << 4) | v_sample_factor;
+    header[idx++] = quant_table_number;
+  }
+
+  static const uint8_t kDcSegment[] = {
+      0xFF, JPEG_DHT, 0x00,
+      0x1F,  // Segment length:31 (2-byte).
+  };
+  static const uint8_t kAcSegment[] = {
+      0xFF, JPEG_DHT, 0x00,
+      0xB5,  // Segment length:181 (2-byte).
+  };
+
+  // Huffman Tables.
+  for (size_t i = 0; i < 2; ++i) {
+    // DC Table.
+    memcpy(header + idx, kDcSegment, sizeof(kDcSegment));
+    idx += sizeof(kDcSegment);
+
+    // Type (4-bit high) = 0:DC, Index (4-bit low).
+    header[idx++] = static_cast<uint8_t>(i);
+
+    const JpegHuffmanTable& dcTable = kDefaultDcTable[i];
+    for (size_t j = 0; j < kNumDcRunSizeBits; ++j)
+      header[idx++] = dcTable.code_length[j];
+    for (size_t j = 0; j < kNumDcCodeWordsHuffVal; ++j)
+      header[idx++] = dcTable.code_value[j];
+
+    // AC Table.
+    memcpy(header + idx, kAcSegment, sizeof(kAcSegment));
+    idx += sizeof(kAcSegment);
+
+    // Type (4-bit high) = 1:AC, Index (4-bit low).
+    header[idx++] = 0x10 | static_cast<uint8_t>(i);
+
+    const JpegHuffmanTable& acTable = kDefaultAcTable[i];
+    for (size_t j = 0; j < kNumAcRunSizeBits; ++j)
+      header[idx++] = acTable.code_length[j];
+    for (size_t j = 0; j < kNumAcCodeWordsHuffVal; ++j)
+      header[idx++] = acTable.code_value[j];
+  }
+
+  // Start of Scan.
+  static const uint8_t kStartOfScan[] = {
+      0xFF, JPEG_SOS, 0x00,
+      0x0C,  // Segment Length:12 (2-byte).
+      0x03   // Number of components in scan.
+  };
+  memcpy(header + idx, kStartOfScan, sizeof(kStartOfScan));
+  idx += sizeof(kStartOfScan);
+
+  for (uint8_t i = 0; i < 3; ++i) {
+    uint8_t dc_table_number = 1;
+    uint8_t ac_table_number = 1;
+    if (!i) {
+      dc_table_number = 0;
+      ac_table_number = 0;
+    }
+
+    header[idx++] = i + 1;
+    // DC Table Selector (4-bit high), AC Table Selector (4-bit low).
+    header[idx++] = (dc_table_number << 4) | ac_table_number;
+  }
+  header[idx++] = 0x00;  // 0 for Baseline.
+  header[idx++] = 0x3F;  // 63 for Baseline.
+  header[idx++] = 0x00;  // 0 for Baseline.
+
+  return idx << 3;
+}
+
+}  // namespace
+
+VaapiJpegEncoder::VaapiJpegEncoder(scoped_refptr<VaapiWrapper> vaapi_wrapper)
+    : vaapi_wrapper_(vaapi_wrapper),
+      q_matrix_cached_(nullptr),
+      huff_table_param_cached_(nullptr),
+      slice_param_cached_(nullptr) {}
+
+VaapiJpegEncoder::~VaapiJpegEncoder() {}
+
+size_t VaapiJpegEncoder::GetMaxCodedBufferSize(const gfx::Size& size) {
+  return size.GetArea() * 3 / 2 + kJpegHeaderSize;
+}
+
+bool VaapiJpegEncoder::Encode(const gfx::Size& input_size,
+                              int quality,
+                              VASurfaceID surface_id,
+                              VABufferID output_buffer_id) {
+  DCHECK_NE(surface_id, VA_INVALID_SURFACE);
+
+  if (input_size.width() > kMaxDimension ||
+      input_size.height() > kMaxDimension) {
+    return false;
+  }
+
+  // Set picture parameters.
+  VAEncPictureParameterBufferJPEG pic_param;
+  FillPictureParameters(input_size, quality, output_buffer_id, &pic_param);
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPictureParameterBufferType,
+                                    sizeof(pic_param), &pic_param)) {
+    return false;
+  }
+
+  if (!q_matrix_cached_) {
+    q_matrix_cached_.reset(new VAQMatrixBufferJPEG());
+    FillQMatrix(q_matrix_cached_.get());
+  }
+  if (!vaapi_wrapper_->SubmitBuffer(VAQMatrixBufferType,
+                                    sizeof(*q_matrix_cached_),
+                                    q_matrix_cached_.get())) {
+    return false;
+  }
+
+  if (!huff_table_param_cached_) {
+    huff_table_param_cached_.reset(new VAHuffmanTableBufferJPEGBaseline());
+    FillHuffmanTableParameters(huff_table_param_cached_.get());
+  }
+  if (!vaapi_wrapper_->SubmitBuffer(VAHuffmanTableBufferType,
+                                    sizeof(*huff_table_param_cached_),
+                                    huff_table_param_cached_.get())) {
+    return false;
+  }
+
+  // Set slice parameters.
+  if (!slice_param_cached_) {
+    slice_param_cached_.reset(new VAEncSliceParameterBufferJPEG());
+    FillSliceParameters(slice_param_cached_.get());
+  }
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncSliceParameterBufferType,
+                                    sizeof(*slice_param_cached_),
+                                    slice_param_cached_.get())) {
+    return false;
+  }
+
+  JPEGHeader header_data;
+  size_t length_in_bits = FillJpegHeader(input_size, quality, header_data);
+
+  VAEncPackedHeaderParameterBuffer header_param;
+  memset(&header_param, 0, sizeof(header_param));
+  header_param.type = VAEncPackedHeaderRawData;
+  header_param.bit_length = length_in_bits;
+  header_param.has_emulation_bytes = 0;
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
+                                    sizeof(header_param), &header_param)) {
+    return false;
+  }
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
+                                    (length_in_bits + 7) / 8, header_data)) {
+    return false;
+  }
+
+  // Submit the |surface_id| which contains input YUV frame and begin encoding.
+  return vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(surface_id);
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_jpeg_encoder.h
@@ -0,0 +1,65 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODER_H_
+#define MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODER_H_
+
+#include <va/va.h>
+#include <memory>
+
+#include "base/macros.h"
+#include "base/memory/scoped_refptr.h"
+#include "media/gpu/media_gpu_export.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace media {
+
+class VaapiWrapper;
+
+// A collection of methods that utilize VA-API hardware video encode
+// acceleration on Intel systems. Provides functionality to allow plugging VAAPI
+// HW acceleration into the JpegEncodeAccelerator framework.
+//
+// Clients are expected to manage VA surfaces and VA buffers created via
+// VaapiWrapper, and pass them to this class.
+class MEDIA_GPU_EXPORT VaapiJpegEncoder {
+ public:
+  // |vaapi_wrapper| should be initialized in VaapiWrapper::kEncode
+  // mode with VAProfileJPEGBaseline profile.
+  explicit VaapiJpegEncoder(scoped_refptr<VaapiWrapper> vaapi_wrapper);
+  ~VaapiJpegEncoder();
+
+  // Encode a JPEG picture. It will fill VA-API parameters and call
+  // corresponding VA-API methods according to |input_size|.
+  // |quality| is the JPEG image quality
+  // |surface_id| is the VA surface that contains input image.
+  // |output_buffer_id| is the ID of VA buffer that encoded image will be
+  // stored. The size of it should be at least as large as
+  // GetMaxCodedBufferSize().
+  // Return false on failure.
+  bool Encode(const gfx::Size& input_size,
+              int quality,
+              VASurfaceID surface_id,
+              VABufferID output_buffer_id);
+
+  // Gets the maximum possible encoded result size.
+  // |size| is the dimension of the YUV image to be encoded.
+  static size_t GetMaxCodedBufferSize(const gfx::Size& size);
+
+ private:
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  // |q_matrix_cached_|, |huff_table_param_cached_| and |slice_param_cached_|
+  // are created when Encode() is called the first time. After that, they will
+  // directly be used for all the subsequent Encode() calls.
+  std::unique_ptr<VAQMatrixBufferJPEG> q_matrix_cached_;
+  std::unique_ptr<VAHuffmanTableBufferJPEGBaseline> huff_table_param_cached_;
+  std::unique_ptr<VAEncSliceParameterBufferJPEG> slice_param_cached_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiJpegEncoder);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_JPEG_ENCODER_H_
--- a/media/gpu/vaapi/vaapi_picture.cc
+++ b/media/gpu/vaapi/vaapi_picture.cc
@@ -4,7 +4,7 @@
 
 #include "media/gpu/vaapi/vaapi_picture.h"
 
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #include "ui/gl/gl_bindings.h"
 #include "ui/gl/gl_implementation.h"
 
--- a/media/gpu/vaapi/vaapi_picture_factory.cc
+++ b/media/gpu/vaapi/vaapi_picture_factory.cc
@@ -4,7 +4,7 @@
 
 #include "media/gpu/vaapi/vaapi_picture_factory.h"
 
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #include "ui/gl/gl_bindings.h"
 
 #include "media/gpu/vaapi/vaapi_drm_picture.h"
--- a/media/gpu/vaapi/vaapi_tfp_picture.cc
+++ b/media/gpu/vaapi/vaapi_tfp_picture.cc
@@ -4,8 +4,8 @@
 
 #include "media/gpu/vaapi/vaapi_tfp_picture.h"
 
-#include "media/gpu/va_surface.h"
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #include "ui/gfx/x/x11_types.h"
 #include "ui/gl/gl_bindings.h"
 #include "ui/gl/gl_image_glx.h"
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator.cc
@@ -0,0 +1,1871 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
+
+#include <string.h>
+
+#include <memory>
+
+#include <va/va.h>
+
+#include "base/bind.h"
+#include "base/files/scoped_file.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/stl_util.h"
+#include "base/strings/string_util.h"
+#include "base/synchronization/waitable_event.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "base/trace_event/trace_event.h"
+#include "gpu/ipc/service/gpu_channel.h"
+#include "media/base/bind_to_current_loop.h"
+#include "media/gpu/accelerated_video_decoder.h"
+#include "media/gpu/format_utils.h"
+#include "media/gpu/h264_decoder.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "media/gpu/vp8_decoder.h"
+#include "media/gpu/vp9_decoder.h"
+#include "media/video/picture.h"
+#include "ui/gl/gl_image.h"
+
+#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
+#define VLOGF(level) VLOG(level) << __func__ << "(): "
+
+namespace media {
+
+namespace {
+// UMA errors that the VaapiVideoDecodeAccelerator class reports.
+enum VAVDADecoderFailure {
+  VAAPI_ERROR = 0,
+  VAVDA_DECODER_FAILURES_MAX,
+};
+// from ITU-T REC H.264 spec
+// section 8.5.6
+// "Inverse scanning process for 4x4 transform coefficients and scaling lists"
+static const int kZigzagScan4x4[16] = {0, 1,  4,  8,  5, 2,  3,  6,
+                                       9, 12, 13, 10, 7, 11, 14, 15};
+
+// section 8.5.7
+// "Inverse scanning process for 8x8 transform coefficients and scaling lists"
+static const uint8_t kZigzagScan8x8[64] = {
+    0,  1,  8,  16, 9,  2,  3,  10, 17, 24, 32, 25, 18, 11, 4,  5,
+    12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6,  7,  14, 21, 28,
+    35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,
+    58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63};
+
+// Returns the preferred VA_RT_FORMAT for the given |profile|.
+unsigned int GetVaFormatForVideoCodecProfile(VideoCodecProfile profile) {
+  if (profile == VP9PROFILE_PROFILE2 || profile == VP9PROFILE_PROFILE3)
+    return VA_RT_FORMAT_YUV420_10BPP;
+  return VA_RT_FORMAT_YUV420;
+}
+
+}  // namespace
+
+static void ReportToUMA(VAVDADecoderFailure failure) {
+  UMA_HISTOGRAM_ENUMERATION("Media.VAVDA.DecoderFailure", failure,
+                            VAVDA_DECODER_FAILURES_MAX + 1);
+}
+
+#define RETURN_AND_NOTIFY_ON_FAILURE(result, log, error_code, ret) \
+  do {                                                             \
+    if (!(result)) {                                               \
+      VLOGF(1) << log;                                             \
+      NotifyError(error_code);                                     \
+      return ret;                                                  \
+    }                                                              \
+  } while (0)
+
+class VaapiVideoDecodeAccelerator::VaapiDecodeSurface
+    : public base::RefCountedThreadSafe<VaapiDecodeSurface> {
+ public:
+  VaapiDecodeSurface(int32_t bitstream_id,
+                     const scoped_refptr<VASurface>& va_surface);
+
+  int32_t bitstream_id() const { return bitstream_id_; }
+  scoped_refptr<VASurface> va_surface() { return va_surface_; }
+  gfx::Rect visible_rect() const { return visible_rect_; }
+
+  void set_visible_rect(const gfx::Rect& visible_rect) {
+    visible_rect_ = visible_rect;
+  }
+
+ private:
+  friend class base::RefCountedThreadSafe<VaapiDecodeSurface>;
+  ~VaapiDecodeSurface();
+
+  const int32_t bitstream_id_;
+  const scoped_refptr<VASurface> va_surface_;
+  gfx::Rect visible_rect_;
+};
+
+VaapiVideoDecodeAccelerator::VaapiDecodeSurface::VaapiDecodeSurface(
+    int32_t bitstream_id,
+    const scoped_refptr<VASurface>& va_surface)
+    : bitstream_id_(bitstream_id), va_surface_(va_surface) {}
+
+VaapiVideoDecodeAccelerator::VaapiDecodeSurface::~VaapiDecodeSurface() {}
+
+class VaapiH264Picture : public H264Picture {
+ public:
+  explicit VaapiH264Picture(
+      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
+      : dec_surface_(surface) {}
+
+  VaapiH264Picture* AsVaapiH264Picture() override { return this; }
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
+    return dec_surface_;
+  }
+
+ private:
+  ~VaapiH264Picture() override {}
+
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiH264Picture);
+};
+
+class VaapiVideoDecodeAccelerator::VaapiH264Accelerator
+    : public H264Decoder::H264Accelerator {
+ public:
+  VaapiH264Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
+                       VaapiWrapper* vaapi_wrapper);
+  ~VaapiH264Accelerator() override;
+
+  // H264Decoder::H264Accelerator implementation.
+  scoped_refptr<H264Picture> CreateH264Picture() override;
+
+  bool SubmitFrameMetadata(const H264SPS* sps,
+                           const H264PPS* pps,
+                           const H264DPB& dpb,
+                           const H264Picture::Vector& ref_pic_listp0,
+                           const H264Picture::Vector& ref_pic_listb0,
+                           const H264Picture::Vector& ref_pic_listb1,
+                           const scoped_refptr<H264Picture>& pic) override;
+
+  bool SubmitSlice(const H264PPS* pps,
+                   const H264SliceHeader* slice_hdr,
+                   const H264Picture::Vector& ref_pic_list0,
+                   const H264Picture::Vector& ref_pic_list1,
+                   const scoped_refptr<H264Picture>& pic,
+                   const uint8_t* data,
+                   size_t size) override;
+
+  bool SubmitDecode(const scoped_refptr<H264Picture>& pic) override;
+  bool OutputPicture(const scoped_refptr<H264Picture>& pic) override;
+
+  void Reset() override;
+
+ private:
+  scoped_refptr<VaapiDecodeSurface> H264PictureToVaapiDecodeSurface(
+      const scoped_refptr<H264Picture>& pic);
+
+  void FillVAPicture(VAPictureH264* va_pic, scoped_refptr<H264Picture> pic);
+  int FillVARefFramesFromDPB(const H264DPB& dpb,
+                             VAPictureH264* va_pics,
+                             int num_pics);
+
+  VaapiWrapper* vaapi_wrapper_;
+  VaapiVideoDecodeAccelerator* vaapi_dec_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiH264Accelerator);
+};
+
+class VaapiVP8Picture : public VP8Picture {
+ public:
+  explicit VaapiVP8Picture(
+      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
+      : dec_surface_(surface) {}
+
+  VaapiVP8Picture* AsVaapiVP8Picture() override { return this; }
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
+    return dec_surface_;
+  }
+
+ private:
+  ~VaapiVP8Picture() override {}
+
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVP8Picture);
+};
+
+class VaapiVideoDecodeAccelerator::VaapiVP8Accelerator
+    : public VP8Decoder::VP8Accelerator {
+ public:
+  VaapiVP8Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
+                      VaapiWrapper* vaapi_wrapper);
+  ~VaapiVP8Accelerator() override;
+
+  // VP8Decoder::VP8Accelerator implementation.
+  scoped_refptr<VP8Picture> CreateVP8Picture() override;
+
+  bool SubmitDecode(const scoped_refptr<VP8Picture>& pic,
+                    const Vp8FrameHeader* frame_hdr,
+                    const scoped_refptr<VP8Picture>& last_frame,
+                    const scoped_refptr<VP8Picture>& golden_frame,
+                    const scoped_refptr<VP8Picture>& alt_frame) override;
+
+  bool OutputPicture(const scoped_refptr<VP8Picture>& pic) override;
+
+ private:
+  scoped_refptr<VaapiDecodeSurface> VP8PictureToVaapiDecodeSurface(
+      const scoped_refptr<VP8Picture>& pic);
+
+  VaapiWrapper* vaapi_wrapper_;
+  VaapiVideoDecodeAccelerator* vaapi_dec_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVP8Accelerator);
+};
+
+class VaapiVP9Picture : public VP9Picture {
+ public:
+  explicit VaapiVP9Picture(
+      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
+      : dec_surface_(surface) {}
+
+  VaapiVP9Picture* AsVaapiVP9Picture() override { return this; }
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
+    return dec_surface_;
+  }
+
+ private:
+  ~VaapiVP9Picture() override {}
+
+  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVP9Picture);
+};
+
+class VaapiVideoDecodeAccelerator::VaapiVP9Accelerator
+    : public VP9Decoder::VP9Accelerator {
+ public:
+  VaapiVP9Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
+                      VaapiWrapper* vaapi_wrapper);
+  ~VaapiVP9Accelerator() override;
+
+  // VP9Decoder::VP9Accelerator implementation.
+  scoped_refptr<VP9Picture> CreateVP9Picture() override;
+
+  bool SubmitDecode(const scoped_refptr<VP9Picture>& pic,
+                    const Vp9SegmentationParams& seg,
+                    const Vp9LoopFilterParams& lf,
+                    const std::vector<scoped_refptr<VP9Picture>>& ref_pictures,
+                    const base::Closure& done_cb) override;
+
+  bool OutputPicture(const scoped_refptr<VP9Picture>& pic) override;
+
+  bool IsFrameContextRequired() const override { return false; }
+
+  bool GetFrameContext(const scoped_refptr<VP9Picture>& pic,
+                       Vp9FrameContext* frame_ctx) override;
+
+ private:
+  scoped_refptr<VaapiDecodeSurface> VP9PictureToVaapiDecodeSurface(
+      const scoped_refptr<VP9Picture>& pic);
+
+  VaapiWrapper* vaapi_wrapper_;
+  VaapiVideoDecodeAccelerator* vaapi_dec_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVP9Accelerator);
+};
+
+class VaapiVideoDecodeAccelerator::InputBuffer {
+ public:
+  InputBuffer() = default;
+  InputBuffer(uint32_t id,
+              std::unique_ptr<SharedMemoryRegion> shm,
+              base::OnceCallback<void(int32_t id)> release_cb)
+      : id_(id), shm_(std::move(shm)), release_cb_(std::move(release_cb)) {}
+  ~InputBuffer() {
+    VLOGF(4) << "id = " << id_;
+    if (release_cb_)
+      std::move(release_cb_).Run(id_);
+  }
+
+  // Indicates this is a dummy buffer for flush request.
+  bool IsFlushRequest() const { return shm_ == nullptr; }
+  int32_t id() const { return id_; }
+  SharedMemoryRegion* shm() const { return shm_.get(); }
+
+ private:
+  const int32_t id_ = -1;
+  const std::unique_ptr<SharedMemoryRegion> shm_;
+  base::OnceCallback<void(int32_t id)> release_cb_;
+
+  DISALLOW_COPY_AND_ASSIGN(InputBuffer);
+};
+
+void VaapiVideoDecodeAccelerator::NotifyError(Error error) {
+  if (!task_runner_->BelongsToCurrentThread()) {
+    DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+    task_runner_->PostTask(FROM_HERE,
+                           base::Bind(&VaapiVideoDecodeAccelerator::NotifyError,
+                                      weak_this_, error));
+    return;
+  }
+
+  // Post Cleanup() as a task so we don't recursively acquire lock_.
+  task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::Cleanup, weak_this_));
+
+  VLOGF(1) << "Notifying of error " << error;
+  if (client_) {
+    client_->NotifyError(error);
+    client_ptr_factory_.reset();
+  }
+}
+
+VaapiPicture* VaapiVideoDecodeAccelerator::PictureById(
+    int32_t picture_buffer_id) {
+  Pictures::iterator it = pictures_.find(picture_buffer_id);
+  if (it == pictures_.end()) {
+    VLOGF(4) << "Picture id " << picture_buffer_id << " does not exist";
+    return NULL;
+  }
+
+  return it->second.get();
+}
+
+VaapiVideoDecodeAccelerator::VaapiVideoDecodeAccelerator(
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb)
+    : state_(kUninitialized),
+      input_ready_(&lock_),
+      vaapi_picture_factory_(new VaapiPictureFactory()),
+      surfaces_available_(&lock_),
+      task_runner_(base::ThreadTaskRunnerHandle::Get()),
+      decoder_thread_("VaapiDecoderThread"),
+      num_frames_at_client_(0),
+      finish_flush_pending_(false),
+      awaiting_va_surfaces_recycle_(false),
+      requested_num_pics_(0),
+      output_format_(gfx::BufferFormat::BGRX_8888),
+      profile_(VIDEO_CODEC_PROFILE_UNKNOWN),
+      make_context_current_cb_(make_context_current_cb),
+      bind_image_cb_(bind_image_cb),
+      weak_this_factory_(this) {
+  weak_this_ = weak_this_factory_.GetWeakPtr();
+  va_surface_release_cb_ = BindToCurrentLoop(
+      base::Bind(&VaapiVideoDecodeAccelerator::RecycleVASurfaceID, weak_this_));
+}
+
+VaapiVideoDecodeAccelerator::~VaapiVideoDecodeAccelerator() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+}
+
+bool VaapiVideoDecodeAccelerator::Initialize(const Config& config,
+                                             Client* client) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (config.is_encrypted()) {
+    NOTREACHED() << "Encrypted streams are not supported for this VDA";
+    return false;
+  }
+
+  switch (config.output_mode) {
+    case Config::OutputMode::ALLOCATE:
+      output_format_ = vaapi_picture_factory_->GetBufferFormatForAllocateMode();
+      break;
+
+    case Config::OutputMode::IMPORT:
+      output_format_ = vaapi_picture_factory_->GetBufferFormatForImportMode();
+      break;
+
+    default:
+      NOTREACHED() << "Only ALLOCATE and IMPORT OutputModes are supported";
+      return false;
+  }
+
+  client_ptr_factory_.reset(new base::WeakPtrFactory<Client>(client));
+  client_ = client_ptr_factory_->GetWeakPtr();
+
+  VideoCodecProfile profile = config.profile;
+
+  base::AutoLock auto_lock(lock_);
+  DCHECK_EQ(state_, kUninitialized);
+  VLOGF(2) << "Initializing VAVDA, profile: " << GetProfileName(profile);
+
+  vaapi_wrapper_ = VaapiWrapper::CreateForVideoCodec(
+      VaapiWrapper::kDecode, profile, base::Bind(&ReportToUMA, VAAPI_ERROR));
+
+  if (!vaapi_wrapper_.get()) {
+    VLOGF(1) << "Failed initializing VAAPI for profile "
+             << GetProfileName(profile);
+    return false;
+  }
+
+  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+    h264_accelerator_.reset(
+        new VaapiH264Accelerator(this, vaapi_wrapper_.get()));
+    decoder_.reset(new H264Decoder(h264_accelerator_.get()));
+  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+    vp8_accelerator_.reset(new VaapiVP8Accelerator(this, vaapi_wrapper_.get()));
+    decoder_.reset(new VP8Decoder(vp8_accelerator_.get()));
+  } else if (profile >= VP9PROFILE_MIN && profile <= VP9PROFILE_MAX) {
+    vp9_accelerator_.reset(new VaapiVP9Accelerator(this, vaapi_wrapper_.get()));
+    decoder_.reset(new VP9Decoder(vp9_accelerator_.get()));
+  } else {
+    VLOGF(1) << "Unsupported profile " << GetProfileName(profile);
+    return false;
+  }
+  profile_ = profile;
+
+  CHECK(decoder_thread_.Start());
+  decoder_thread_task_runner_ = decoder_thread_.task_runner();
+
+  state_ = kIdle;
+  output_mode_ = config.output_mode;
+  return true;
+}
+
+void VaapiVideoDecodeAccelerator::OutputPicture(
+    const scoped_refptr<VASurface>& va_surface,
+    int32_t input_id,
+    gfx::Rect visible_rect,
+    VaapiPicture* picture) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  int32_t output_id = picture->picture_buffer_id();
+
+  VLOGF(4) << "Outputting VASurface " << va_surface->id()
+           << " into pixmap bound to picture buffer id " << output_id;
+  {
+    TRACE_EVENT2("Video Decoder", "VAVDA::DownloadFromSurface", "input_id",
+                 input_id, "output_id", output_id);
+    RETURN_AND_NOTIFY_ON_FAILURE(picture->DownloadFromSurface(va_surface),
+                                 "Failed putting surface into pixmap",
+                                 PLATFORM_FAILURE, );
+  }
+  // Notify the client a picture is ready to be displayed.
+  ++num_frames_at_client_;
+  TRACE_COUNTER1("Video Decoder", "Textures at client", num_frames_at_client_);
+  VLOGF(4) << "Notifying output picture id " << output_id << " for input "
+           << input_id
+           << " is ready. visible rect: " << visible_rect.ToString();
+  if (client_) {
+    // TODO(hubbe): Use the correct color space.  http://crbug.com/647725
+    client_->PictureReady(Picture(output_id, input_id, visible_rect,
+                                  gfx::ColorSpace(), picture->AllowOverlay()));
+  }
+}
+
+void VaapiVideoDecodeAccelerator::TryOutputSurface() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  // Handle Destroy() arriving while pictures are queued for output.
+  if (!client_)
+    return;
+
+  if (pending_output_cbs_.empty() || output_buffers_.empty())
+    return;
+
+  OutputCB output_cb = pending_output_cbs_.front();
+  pending_output_cbs_.pop();
+
+  VaapiPicture* picture = PictureById(output_buffers_.front());
+  DCHECK(picture);
+  output_buffers_.pop();
+
+  output_cb.Run(picture);
+
+  if (finish_flush_pending_ && pending_output_cbs_.empty())
+    FinishFlush();
+}
+
+void VaapiVideoDecodeAccelerator::QueueInputBuffer(
+    const BitstreamBuffer& bitstream_buffer) {
+  VLOGF(4) << "Queueing new input buffer id: " << bitstream_buffer.id()
+           << " size: " << (int)bitstream_buffer.size();
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("Video Decoder", "QueueInputBuffer", "input_id",
+               bitstream_buffer.id());
+
+  base::AutoLock auto_lock(lock_);
+  if (bitstream_buffer.size() == 0) {
+    DCHECK(!base::SharedMemory::IsHandleValid(bitstream_buffer.handle()));
+    // Dummy buffer for flush.
+    auto flush_buffer = base::MakeUnique<InputBuffer>();
+    DCHECK(flush_buffer->IsFlushRequest());
+    input_buffers_.push(std::move(flush_buffer));
+  } else {
+    std::unique_ptr<SharedMemoryRegion> shm(
+        new SharedMemoryRegion(bitstream_buffer, true));
+    RETURN_AND_NOTIFY_ON_FAILURE(shm->Map(), "Failed to map input buffer",
+                                 UNREADABLE_INPUT, );
+
+    auto input_buffer = base::MakeUnique<InputBuffer>(
+        bitstream_buffer.id(), std::move(shm),
+        BindToCurrentLoop(
+            base::Bind(&Client::NotifyEndOfBitstreamBuffer, client_)));
+    input_buffers_.push(std::move(input_buffer));
+
+    TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
+  }
+
+  input_ready_.Signal();
+
+  switch (state_) {
+    case kIdle:
+      state_ = kDecoding;
+      decoder_thread_task_runner_->PostTask(
+          FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
+                                base::Unretained(this)));
+      break;
+
+    case kDecoding:
+      // Decoder already running.
+      break;
+
+    case kResetting:
+      // When resetting, allow accumulating bitstream buffers, so that
+      // the client can queue after-seek-buffers while we are finishing with
+      // the before-seek one.
+      break;
+
+    default:
+      VLOGF(1) << "Decode/Flush request from client in invalid state: "
+               << state_;
+      NotifyError(PLATFORM_FAILURE);
+      break;
+  }
+}
+
+bool VaapiVideoDecodeAccelerator::GetInputBuffer_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+
+  if (curr_input_buffer_.get())
+    return true;
+
+  // Will only wait if it is expected that in current state new buffers will
+  // be queued from the client via Decode(). The state can change during wait.
+  while (input_buffers_.empty() && (state_ == kDecoding || state_ == kIdle)) {
+    input_ready_.Wait();
+  }
+
+  // We could have got woken up in a different state or never got to sleep
+  // due to current state.
+  if (state_ != kDecoding && state_ != kIdle)
+    return false;
+
+  DCHECK(!input_buffers_.empty());
+  curr_input_buffer_ = std::move(input_buffers_.front());
+  input_buffers_.pop();
+
+  if (curr_input_buffer_->IsFlushRequest()) {
+    VLOGF(4) << "New flush buffer";
+    return true;
+  }
+
+  VLOGF(4) << "New current input buffer, id: " << curr_input_buffer_->id()
+           << " size: " << curr_input_buffer_->shm()->size() << "B";
+  decoder_->SetStream(
+      static_cast<uint8_t*>(curr_input_buffer_->shm()->memory()),
+      curr_input_buffer_->shm()->size());
+
+  return true;
+}
+
+void VaapiVideoDecodeAccelerator::ReturnCurrInputBuffer_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+  DCHECK(curr_input_buffer_.get());
+  curr_input_buffer_.reset();
+
+  TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
+}
+
+// TODO(posciak): refactor the whole class to remove sleeping in wait for
+// surfaces, and reschedule DecodeTask instead.
+bool VaapiVideoDecodeAccelerator::WaitForSurfaces_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+
+  while (available_va_surfaces_.empty() &&
+         (state_ == kDecoding || state_ == kIdle)) {
+    surfaces_available_.Wait();
+  }
+
+  return state_ == kDecoding || state_ == kIdle;
+}
+
+void VaapiVideoDecodeAccelerator::DecodeTask() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (state_ != kDecoding)
+    return;
+
+  // Main decode task.
+  VLOGF(4) << "Decode task";
+
+  // Try to decode what stream data is (still) in the decoder until we run out
+  // of it.
+  while (GetInputBuffer_Locked()) {
+    DCHECK(curr_input_buffer_.get());
+
+    if (curr_input_buffer_->IsFlushRequest()) {
+      FlushTask();
+      break;
+    }
+
+    AcceleratedVideoDecoder::DecodeResult res;
+    {
+      // We are OK releasing the lock here, as decoder never calls our methods
+      // directly and we will reacquire the lock before looking at state again.
+      // This is the main decode function of the decoder and while keeping
+      // the lock for its duration would be fine, it would defeat the purpose
+      // of having a separate decoder thread.
+      base::AutoUnlock auto_unlock(lock_);
+      TRACE_EVENT0("Video Decoder", "VAVDA::Decode");
+      res = decoder_->Decode();
+    }
+
+    switch (res) {
+      case AcceleratedVideoDecoder::kAllocateNewSurfaces:
+        VLOGF(2) << "Decoder requesting a new set of surfaces";
+        task_runner_->PostTask(
+            FROM_HERE,
+            base::Bind(&VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange,
+                       weak_this_, decoder_->GetRequiredNumOfPictures(),
+                       decoder_->GetPicSize()));
+        // We'll get rescheduled once ProvidePictureBuffers() finishes.
+        return;
+
+      case AcceleratedVideoDecoder::kRanOutOfStreamData:
+        ReturnCurrInputBuffer_Locked();
+        break;
+
+      case AcceleratedVideoDecoder::kRanOutOfSurfaces:
+        // No more output buffers in the decoder, try getting more or go to
+        // sleep waiting for them.
+        if (!WaitForSurfaces_Locked())
+          return;
+
+        break;
+
+      case AcceleratedVideoDecoder::kNeedContextUpdate:
+        // This should not happen as we return false from
+        // IsFrameContextRequired().
+        NOTREACHED() << "Context updates not supported";
+        return;
+
+      case AcceleratedVideoDecoder::kDecodeError:
+        RETURN_AND_NOTIFY_ON_FAILURE(false, "Error decoding stream",
+                                     PLATFORM_FAILURE, );
+        return;
+    }
+  }
+}
+
+void VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange(size_t num_pics,
+                                                           gfx::Size size) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  DCHECK(!awaiting_va_surfaces_recycle_);
+
+  // At this point decoder has stopped running and has already posted onto our
+  // loop any remaining output request callbacks, which executed before we got
+  // here. Some of them might have been pended though, because we might not
+  // have had enough TFPictures to output surfaces to. Initiate a wait cycle,
+  // which will wait for client to return enough PictureBuffers to us, so that
+  // we can finish all pending output callbacks, releasing associated surfaces.
+  VLOGF(2) << "Initiating surface set change";
+  awaiting_va_surfaces_recycle_ = true;
+
+  requested_num_pics_ = num_pics;
+  requested_pic_size_ = size;
+
+  TryFinishSurfaceSetChange();
+}
+
+void VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (!awaiting_va_surfaces_recycle_)
+    return;
+
+  if (!pending_output_cbs_.empty() ||
+      pictures_.size() != available_va_surfaces_.size()) {
+    // Either:
+    // 1. Not all pending pending output callbacks have been executed yet.
+    // Wait for the client to return enough pictures and retry later.
+    // 2. The above happened and all surface release callbacks have been posted
+    // as the result, but not all have executed yet. Post ourselves after them
+    // to let them release surfaces.
+    DVLOGF(2) << "Awaiting pending output/surface release callbacks to finish";
+    task_runner_->PostTask(
+        FROM_HERE,
+        base::Bind(&VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange,
+                   weak_this_));
+    return;
+  }
+
+  // All surfaces released, destroy them and dismiss all PictureBuffers.
+  awaiting_va_surfaces_recycle_ = false;
+  available_va_surfaces_.clear();
+  vaapi_wrapper_->DestroySurfaces();
+
+  for (Pictures::iterator iter = pictures_.begin(); iter != pictures_.end();
+       ++iter) {
+    VLOGF(2) << "Dismissing picture id: " << iter->first;
+    if (client_)
+      client_->DismissPictureBuffer(iter->first);
+  }
+  pictures_.clear();
+
+  // And ask for a new set as requested.
+  VLOGF(2) << "Requesting " << requested_num_pics_
+           << " pictures of size: " << requested_pic_size_.ToString();
+
+  VideoPixelFormat format = GfxBufferFormatToVideoPixelFormat(output_format_);
+  task_runner_->PostTask(
+      FROM_HERE, base::Bind(&Client::ProvidePictureBuffers, client_,
+                            requested_num_pics_, format, 1, requested_pic_size_,
+                            vaapi_picture_factory_->GetGLTextureTarget()));
+}
+
+void VaapiVideoDecodeAccelerator::Decode(
+    const BitstreamBuffer& bitstream_buffer) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("Video Decoder", "VAVDA::Decode", "Buffer id",
+               bitstream_buffer.id());
+
+  if (bitstream_buffer.id() < 0) {
+    if (base::SharedMemory::IsHandleValid(bitstream_buffer.handle()))
+      base::SharedMemory::CloseHandle(bitstream_buffer.handle());
+    VLOGF(1) << "Invalid bitstream_buffer, id: " << bitstream_buffer.id();
+    NotifyError(INVALID_ARGUMENT);
+    return;
+  }
+
+  // Skip empty buffers. VaapiVDA uses empty buffer as dummy buffer for flush
+  // internally.
+  if (bitstream_buffer.size() == 0) {
+    if (base::SharedMemory::IsHandleValid(bitstream_buffer.handle()))
+      base::SharedMemory::CloseHandle(bitstream_buffer.handle());
+    if (client_)
+      client_->NotifyEndOfBitstreamBuffer(bitstream_buffer.id());
+    return;
+  }
+
+  QueueInputBuffer(bitstream_buffer);
+}
+
+void VaapiVideoDecodeAccelerator::RecycleVASurfaceID(
+    VASurfaceID va_surface_id) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  available_va_surfaces_.push_back(va_surface_id);
+  surfaces_available_.Signal();
+}
+
+void VaapiVideoDecodeAccelerator::AssignPictureBuffers(
+    const std::vector<PictureBuffer>& buffers) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+  DCHECK(pictures_.empty());
+
+  while (!output_buffers_.empty())
+    output_buffers_.pop();
+
+  RETURN_AND_NOTIFY_ON_FAILURE(
+      buffers.size() >= requested_num_pics_,
+      "Got an invalid number of picture buffers. (Got " << buffers.size()
+      << ", requested " << requested_num_pics_ << ")", INVALID_ARGUMENT, );
+  DCHECK(requested_pic_size_ == buffers[0].size());
+
+  const unsigned int va_format = GetVaFormatForVideoCodecProfile(profile_);
+  std::vector<VASurfaceID> va_surface_ids;
+  RETURN_AND_NOTIFY_ON_FAILURE(
+      vaapi_wrapper_->CreateSurfaces(va_format, requested_pic_size_,
+                                     buffers.size(), &va_surface_ids),
+      "Failed creating VA Surfaces", PLATFORM_FAILURE, );
+  DCHECK_EQ(va_surface_ids.size(), buffers.size());
+
+  for (size_t i = 0; i < buffers.size(); ++i) {
+    uint32_t client_id = !buffers[i].client_texture_ids().empty()
+                             ? buffers[i].client_texture_ids()[0]
+                             : 0;
+    uint32_t service_id = !buffers[i].service_texture_ids().empty()
+                              ? buffers[i].service_texture_ids()[0]
+                              : 0;
+
+    std::unique_ptr<VaapiPicture> picture(vaapi_picture_factory_->Create(
+        vaapi_wrapper_, make_context_current_cb_, bind_image_cb_,
+        buffers[i].id(), requested_pic_size_, service_id, client_id));
+    RETURN_AND_NOTIFY_ON_FAILURE(
+        picture.get(), "Failed creating a VaapiPicture", PLATFORM_FAILURE, );
+
+    if (output_mode_ == Config::OutputMode::ALLOCATE) {
+      RETURN_AND_NOTIFY_ON_FAILURE(
+          picture->Allocate(output_format_),
+          "Failed to allocate memory for a VaapiPicture", PLATFORM_FAILURE, );
+      output_buffers_.push(buffers[i].id());
+    }
+    bool inserted =
+        pictures_.insert(std::make_pair(buffers[i].id(), std::move(picture)))
+            .second;
+    DCHECK(inserted);
+
+    available_va_surfaces_.push_back(va_surface_ids[i]);
+    surfaces_available_.Signal();
+  }
+
+  // Resume DecodeTask if it is still in decoding state.
+  if (state_ == kDecoding) {
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
+                              base::Unretained(this)));
+  }
+}
+
+#if defined(USE_OZONE)
+static void CloseGpuMemoryBufferHandle(
+    const gfx::GpuMemoryBufferHandle& handle) {
+  for (const auto& fd : handle.native_pixmap_handle.fds) {
+    // Close the fd by wrapping it in a ScopedFD and letting
+    // it fall out of scope.
+    base::ScopedFD scoped_fd(fd.fd);
+  }
+}
+
+void VaapiVideoDecodeAccelerator::ImportBufferForPicture(
+    int32_t picture_buffer_id,
+    const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) {
+  VLOGF(2) << "Importing picture id: " << picture_buffer_id;
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (output_mode_ != Config::OutputMode::IMPORT) {
+    CloseGpuMemoryBufferHandle(gpu_memory_buffer_handle);
+    VLOGF(1) << "Cannot import in non-import mode";
+    NotifyError(INVALID_ARGUMENT);
+    return;
+  }
+
+  VaapiPicture* picture = PictureById(picture_buffer_id);
+  if (!picture) {
+    CloseGpuMemoryBufferHandle(gpu_memory_buffer_handle);
+
+    // It's possible that we've already posted a DismissPictureBuffer for this
+    // picture, but it has not yet executed when this ImportBufferForPicture
+    // was posted to us by the client. In that case just ignore this (we've
+    // already dismissed it and accounted for that).
+    VLOGF(3) << "got picture id=" << picture_buffer_id
+             << " not in use (anymore?).";
+    return;
+  }
+
+  if (!picture->ImportGpuMemoryBufferHandle(output_format_,
+                                            gpu_memory_buffer_handle)) {
+    // ImportGpuMemoryBufferHandle will close the handles even on failure, so
+    // we don't need to do this ourselves.
+    VLOGF(1) << "Failed to import GpuMemoryBufferHandle";
+    NotifyError(PLATFORM_FAILURE);
+    return;
+  }
+
+  ReusePictureBuffer(picture_buffer_id);
+}
+#endif
+
+void VaapiVideoDecodeAccelerator::ReusePictureBuffer(
+    int32_t picture_buffer_id) {
+  VLOGF(4) << "picture id=" << picture_buffer_id;
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("Video Decoder", "VAVDA::ReusePictureBuffer", "Picture id",
+               picture_buffer_id);
+
+  if (!PictureById(picture_buffer_id)) {
+    // It's possible that we've already posted a DismissPictureBuffer for this
+    // picture, but it has not yet executed when this ReusePictureBuffer
+    // was posted to us by the client. In that case just ignore this (we've
+    // already dismissed it and accounted for that).
+    VLOGF(3) << "got picture id=" << picture_buffer_id
+             << " not in use (anymore?).";
+    return;
+  }
+
+  --num_frames_at_client_;
+  TRACE_COUNTER1("Video Decoder", "Textures at client", num_frames_at_client_);
+
+  output_buffers_.push(picture_buffer_id);
+  TryOutputSurface();
+}
+
+void VaapiVideoDecodeAccelerator::FlushTask() {
+  VLOGF(2);
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK(curr_input_buffer_.get() && curr_input_buffer_->IsFlushRequest());
+
+  curr_input_buffer_.reset();
+
+  // First flush all the pictures that haven't been outputted, notifying the
+  // client to output them.
+  bool res = decoder_->Flush();
+  RETURN_AND_NOTIFY_ON_FAILURE(res, "Failed flushing the decoder.",
+                               PLATFORM_FAILURE, );
+
+  // Put the decoder in idle state, ready to resume.
+  decoder_->Reset();
+
+  task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(&VaapiVideoDecodeAccelerator::FinishFlush, weak_this_));
+}
+
+void VaapiVideoDecodeAccelerator::Flush() {
+  VLOGF(2) << "Got flush request";
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  // Queue a dummy buffer, which means flush.
+  QueueInputBuffer(media::BitstreamBuffer());
+}
+
+void VaapiVideoDecodeAccelerator::FinishFlush() {
+  VLOGF(2);
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  finish_flush_pending_ = false;
+
+  base::AutoLock auto_lock(lock_);
+  if (state_ != kDecoding) {
+    DCHECK(state_ == kDestroying || state_ == kResetting) << state_;
+    return;
+  }
+
+  // Still waiting for textures from client to finish outputting all pending
+  // frames. Try again later.
+  if (!pending_output_cbs_.empty()) {
+    finish_flush_pending_ = true;
+    return;
+  }
+
+  // Resume decoding if necessary.
+  if (input_buffers_.empty()) {
+    state_ = kIdle;
+  } else {
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
+                              base::Unretained(this)));
+  }
+
+  task_runner_->PostTask(FROM_HERE,
+                         base::Bind(&Client::NotifyFlushDone, client_));
+}
+
+void VaapiVideoDecodeAccelerator::ResetTask() {
+  VLOGF(2);
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+
+  // All the decoding tasks from before the reset request from client are done
+  // by now, as this task was scheduled after them and client is expected not
+  // to call Decode() after Reset() and before NotifyResetDone.
+  decoder_->Reset();
+
+  base::AutoLock auto_lock(lock_);
+
+  // Return current input buffer, if present.
+  if (curr_input_buffer_.get())
+    ReturnCurrInputBuffer_Locked();
+
+  // And let client know that we are done with reset.
+  task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
+}
+
+void VaapiVideoDecodeAccelerator::Reset() {
+  VLOGF(2) << "Got reset request";
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  // This will make any new decode tasks exit early.
+  base::AutoLock auto_lock(lock_);
+  state_ = kResetting;
+  finish_flush_pending_ = false;
+
+  // Drop all remaining input buffers, if present.
+  while (!input_buffers_.empty())
+    input_buffers_.pop();
+  TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
+
+  decoder_thread_task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::ResetTask,
+                            base::Unretained(this)));
+
+  input_ready_.Signal();
+  surfaces_available_.Signal();
+}
+
+void VaapiVideoDecodeAccelerator::FinishReset() {
+  VLOGF(2);
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (state_ != kResetting) {
+    DCHECK(state_ == kDestroying || state_ == kUninitialized) << state_;
+    return;  // We could've gotten destroyed already.
+  }
+
+  // Drop pending outputs.
+  while (!pending_output_cbs_.empty())
+    pending_output_cbs_.pop();
+
+  if (awaiting_va_surfaces_recycle_) {
+    // Decoder requested a new surface set while we were waiting for it to
+    // finish the last DecodeTask, running at the time of Reset().
+    // Let the surface set change finish first before resetting.
+    task_runner_->PostTask(
+        FROM_HERE,
+        base::Bind(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
+    return;
+  }
+
+  state_ = kIdle;
+
+  task_runner_->PostTask(FROM_HERE,
+                         base::Bind(&Client::NotifyResetDone, client_));
+
+  // The client might have given us new buffers via Decode() while we were
+  // resetting and might be waiting for our move, and not call Decode() anymore
+  // until we return something. Post a DecodeTask() so that we won't
+  // sleep forever waiting for Decode() in that case. Having two of them
+  // in the pipe is harmless, the additional one will return as soon as it sees
+  // that we are back in kDecoding state.
+  if (!input_buffers_.empty()) {
+    state_ = kDecoding;
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
+                              base::Unretained(this)));
+  }
+}
+
+void VaapiVideoDecodeAccelerator::Cleanup() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  base::AutoLock auto_lock(lock_);
+  if (state_ == kUninitialized || state_ == kDestroying)
+    return;
+
+  VLOGF(2) << "Destroying VAVDA";
+  state_ = kDestroying;
+
+  client_ptr_factory_.reset();
+  weak_this_factory_.InvalidateWeakPtrs();
+
+  // Signal all potential waiters on the decoder_thread_, let them early-exit,
+  // as we've just moved to the kDestroying state, and wait for all tasks
+  // to finish.
+  input_ready_.Signal();
+  surfaces_available_.Signal();
+  {
+    base::AutoUnlock auto_unlock(lock_);
+    decoder_thread_.Stop();
+  }
+
+  state_ = kUninitialized;
+}
+
+void VaapiVideoDecodeAccelerator::Destroy() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  Cleanup();
+  delete this;
+}
+
+bool VaapiVideoDecodeAccelerator::TryToSetupDecodeOnSeparateThread(
+    const base::WeakPtr<Client>& decode_client,
+    const scoped_refptr<base::SingleThreadTaskRunner>& decode_task_runner) {
+  return false;
+}
+
+bool VaapiVideoDecodeAccelerator::DecodeSurface(
+    const scoped_refptr<VaapiDecodeSurface>& dec_surface) {
+  const bool result = vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(
+      dec_surface->va_surface()->id());
+  if (!result)
+    VLOGF(1) << "Failed decoding picture";
+  return result;
+}
+
+void VaapiVideoDecodeAccelerator::SurfaceReady(
+    const scoped_refptr<VaapiDecodeSurface>& dec_surface) {
+  if (!task_runner_->BelongsToCurrentThread()) {
+    task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::SurfaceReady,
+                              weak_this_, dec_surface));
+    return;
+  }
+
+  DCHECK(!awaiting_va_surfaces_recycle_);
+
+  {
+    base::AutoLock auto_lock(lock_);
+    // Drop any requests to output if we are resetting or being destroyed.
+    if (state_ == kResetting || state_ == kDestroying)
+      return;
+  }
+
+  pending_output_cbs_.push(
+      base::Bind(&VaapiVideoDecodeAccelerator::OutputPicture, weak_this_,
+                 dec_surface->va_surface(), dec_surface->bitstream_id(),
+                 dec_surface->visible_rect()));
+
+  TryOutputSurface();
+}
+
+scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
+VaapiVideoDecodeAccelerator::CreateSurface() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (available_va_surfaces_.empty())
+    return nullptr;
+
+  DCHECK(!awaiting_va_surfaces_recycle_);
+  scoped_refptr<VASurface> va_surface(new VASurface(
+      available_va_surfaces_.front(), requested_pic_size_,
+      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_));
+  available_va_surfaces_.pop_front();
+
+  return new VaapiDecodeSurface(curr_input_buffer_->id(), va_surface);
+}
+
+VaapiVideoDecodeAccelerator::VaapiH264Accelerator::VaapiH264Accelerator(
+    VaapiVideoDecodeAccelerator* vaapi_dec,
+    VaapiWrapper* vaapi_wrapper)
+    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
+  DCHECK(vaapi_wrapper_);
+  DCHECK(vaapi_dec_);
+}
+
+VaapiVideoDecodeAccelerator::VaapiH264Accelerator::~VaapiH264Accelerator() {}
+
+scoped_refptr<H264Picture>
+VaapiVideoDecodeAccelerator::VaapiH264Accelerator::CreateH264Picture() {
+  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
+  if (!va_surface)
+    return nullptr;
+
+  return new VaapiH264Picture(std::move(va_surface));
+}
+
+// Fill |va_pic| with default/neutral values.
+static void InitVAPicture(VAPictureH264* va_pic) {
+  memset(va_pic, 0, sizeof(*va_pic));
+  va_pic->picture_id = VA_INVALID_ID;
+  va_pic->flags = VA_PICTURE_H264_INVALID;
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitFrameMetadata(
+    const H264SPS* sps,
+    const H264PPS* pps,
+    const H264DPB& dpb,
+    const H264Picture::Vector& ref_pic_listp0,
+    const H264Picture::Vector& ref_pic_listb0,
+    const H264Picture::Vector& ref_pic_listb1,
+    const scoped_refptr<H264Picture>& pic) {
+  VAPictureParameterBufferH264 pic_param;
+  memset(&pic_param, 0, sizeof(pic_param));
+
+#define FROM_SPS_TO_PP(a) pic_param.a = sps->a
+#define FROM_SPS_TO_PP2(a, b) pic_param.b = sps->a
+  FROM_SPS_TO_PP2(pic_width_in_mbs_minus1, picture_width_in_mbs_minus1);
+  // This assumes non-interlaced video
+  FROM_SPS_TO_PP2(pic_height_in_map_units_minus1, picture_height_in_mbs_minus1);
+  FROM_SPS_TO_PP(bit_depth_luma_minus8);
+  FROM_SPS_TO_PP(bit_depth_chroma_minus8);
+#undef FROM_SPS_TO_PP
+#undef FROM_SPS_TO_PP2
+
+#define FROM_SPS_TO_PP_SF(a) pic_param.seq_fields.bits.a = sps->a
+#define FROM_SPS_TO_PP_SF2(a, b) pic_param.seq_fields.bits.b = sps->a
+  FROM_SPS_TO_PP_SF(chroma_format_idc);
+  FROM_SPS_TO_PP_SF2(separate_colour_plane_flag,
+                     residual_colour_transform_flag);
+  FROM_SPS_TO_PP_SF(gaps_in_frame_num_value_allowed_flag);
+  FROM_SPS_TO_PP_SF(frame_mbs_only_flag);
+  FROM_SPS_TO_PP_SF(mb_adaptive_frame_field_flag);
+  FROM_SPS_TO_PP_SF(direct_8x8_inference_flag);
+  pic_param.seq_fields.bits.MinLumaBiPredSize8x8 = (sps->level_idc >= 31);
+  FROM_SPS_TO_PP_SF(log2_max_frame_num_minus4);
+  FROM_SPS_TO_PP_SF(pic_order_cnt_type);
+  FROM_SPS_TO_PP_SF(log2_max_pic_order_cnt_lsb_minus4);
+  FROM_SPS_TO_PP_SF(delta_pic_order_always_zero_flag);
+#undef FROM_SPS_TO_PP_SF
+#undef FROM_SPS_TO_PP_SF2
+
+#define FROM_PPS_TO_PP(a) pic_param.a = pps->a
+  FROM_PPS_TO_PP(pic_init_qp_minus26);
+  FROM_PPS_TO_PP(pic_init_qs_minus26);
+  FROM_PPS_TO_PP(chroma_qp_index_offset);
+  FROM_PPS_TO_PP(second_chroma_qp_index_offset);
+#undef FROM_PPS_TO_PP
+
+#define FROM_PPS_TO_PP_PF(a) pic_param.pic_fields.bits.a = pps->a
+#define FROM_PPS_TO_PP_PF2(a, b) pic_param.pic_fields.bits.b = pps->a
+  FROM_PPS_TO_PP_PF(entropy_coding_mode_flag);
+  FROM_PPS_TO_PP_PF(weighted_pred_flag);
+  FROM_PPS_TO_PP_PF(weighted_bipred_idc);
+  FROM_PPS_TO_PP_PF(transform_8x8_mode_flag);
+
+  pic_param.pic_fields.bits.field_pic_flag = 0;
+  FROM_PPS_TO_PP_PF(constrained_intra_pred_flag);
+  FROM_PPS_TO_PP_PF2(bottom_field_pic_order_in_frame_present_flag,
+                     pic_order_present_flag);
+  FROM_PPS_TO_PP_PF(deblocking_filter_control_present_flag);
+  FROM_PPS_TO_PP_PF(redundant_pic_cnt_present_flag);
+  pic_param.pic_fields.bits.reference_pic_flag = pic->ref;
+#undef FROM_PPS_TO_PP_PF
+#undef FROM_PPS_TO_PP_PF2
+
+  pic_param.frame_num = pic->frame_num;
+
+  InitVAPicture(&pic_param.CurrPic);
+  FillVAPicture(&pic_param.CurrPic, pic);
+
+  // Init reference pictures' array.
+  for (int i = 0; i < 16; ++i)
+    InitVAPicture(&pic_param.ReferenceFrames[i]);
+
+  // And fill it with picture info from DPB.
+  FillVARefFramesFromDPB(dpb, pic_param.ReferenceFrames,
+                         arraysize(pic_param.ReferenceFrames));
+
+  pic_param.num_ref_frames = sps->max_num_ref_frames;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
+                                    sizeof(pic_param), &pic_param))
+    return false;
+
+  VAIQMatrixBufferH264 iq_matrix_buf;
+  memset(&iq_matrix_buf, 0, sizeof(iq_matrix_buf));
+
+  if (pps->pic_scaling_matrix_present_flag) {
+    for (int i = 0; i < 6; ++i) {
+      for (int j = 0; j < 16; ++j)
+        iq_matrix_buf.ScalingList4x4[i][kZigzagScan4x4[j]] =
+            pps->scaling_list4x4[i][j];
+    }
+
+    for (int i = 0; i < 2; ++i) {
+      for (int j = 0; j < 64; ++j)
+        iq_matrix_buf.ScalingList8x8[i][kZigzagScan8x8[j]] =
+            pps->scaling_list8x8[i][j];
+    }
+  } else {
+    for (int i = 0; i < 6; ++i) {
+      for (int j = 0; j < 16; ++j)
+        iq_matrix_buf.ScalingList4x4[i][kZigzagScan4x4[j]] =
+            sps->scaling_list4x4[i][j];
+    }
+
+    for (int i = 0; i < 2; ++i) {
+      for (int j = 0; j < 64; ++j)
+        iq_matrix_buf.ScalingList8x8[i][kZigzagScan8x8[j]] =
+            sps->scaling_list8x8[i][j];
+    }
+  }
+
+  return vaapi_wrapper_->SubmitBuffer(VAIQMatrixBufferType,
+                                      sizeof(iq_matrix_buf), &iq_matrix_buf);
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitSlice(
+    const H264PPS* pps,
+    const H264SliceHeader* slice_hdr,
+    const H264Picture::Vector& ref_pic_list0,
+    const H264Picture::Vector& ref_pic_list1,
+    const scoped_refptr<H264Picture>& pic,
+    const uint8_t* data,
+    size_t size) {
+  VASliceParameterBufferH264 slice_param;
+  memset(&slice_param, 0, sizeof(slice_param));
+
+  slice_param.slice_data_size = slice_hdr->nalu_size;
+  slice_param.slice_data_offset = 0;
+  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
+  slice_param.slice_data_bit_offset = slice_hdr->header_bit_size;
+
+#define SHDRToSP(a) slice_param.a = slice_hdr->a
+  SHDRToSP(first_mb_in_slice);
+  slice_param.slice_type = slice_hdr->slice_type % 5;
+  SHDRToSP(direct_spatial_mv_pred_flag);
+
+  // TODO posciak: make sure parser sets those even when override flags
+  // in slice header is off.
+  SHDRToSP(num_ref_idx_l0_active_minus1);
+  SHDRToSP(num_ref_idx_l1_active_minus1);
+  SHDRToSP(cabac_init_idc);
+  SHDRToSP(slice_qp_delta);
+  SHDRToSP(disable_deblocking_filter_idc);
+  SHDRToSP(slice_alpha_c0_offset_div2);
+  SHDRToSP(slice_beta_offset_div2);
+
+  if (((slice_hdr->IsPSlice() || slice_hdr->IsSPSlice()) &&
+       pps->weighted_pred_flag) ||
+      (slice_hdr->IsBSlice() && pps->weighted_bipred_idc == 1)) {
+    SHDRToSP(luma_log2_weight_denom);
+    SHDRToSP(chroma_log2_weight_denom);
+
+    SHDRToSP(luma_weight_l0_flag);
+    SHDRToSP(luma_weight_l1_flag);
+
+    SHDRToSP(chroma_weight_l0_flag);
+    SHDRToSP(chroma_weight_l1_flag);
+
+    for (int i = 0; i <= slice_param.num_ref_idx_l0_active_minus1; ++i) {
+      slice_param.luma_weight_l0[i] =
+          slice_hdr->pred_weight_table_l0.luma_weight[i];
+      slice_param.luma_offset_l0[i] =
+          slice_hdr->pred_weight_table_l0.luma_offset[i];
+
+      for (int j = 0; j < 2; ++j) {
+        slice_param.chroma_weight_l0[i][j] =
+            slice_hdr->pred_weight_table_l0.chroma_weight[i][j];
+        slice_param.chroma_offset_l0[i][j] =
+            slice_hdr->pred_weight_table_l0.chroma_offset[i][j];
+      }
+    }
+
+    if (slice_hdr->IsBSlice()) {
+      for (int i = 0; i <= slice_param.num_ref_idx_l1_active_minus1; ++i) {
+        slice_param.luma_weight_l1[i] =
+            slice_hdr->pred_weight_table_l1.luma_weight[i];
+        slice_param.luma_offset_l1[i] =
+            slice_hdr->pred_weight_table_l1.luma_offset[i];
+
+        for (int j = 0; j < 2; ++j) {
+          slice_param.chroma_weight_l1[i][j] =
+              slice_hdr->pred_weight_table_l1.chroma_weight[i][j];
+          slice_param.chroma_offset_l1[i][j] =
+              slice_hdr->pred_weight_table_l1.chroma_offset[i][j];
+        }
+      }
+    }
+  }
+
+  static_assert(
+      arraysize(slice_param.RefPicList0) == arraysize(slice_param.RefPicList1),
+      "Invalid RefPicList sizes");
+
+  for (size_t i = 0; i < arraysize(slice_param.RefPicList0); ++i) {
+    InitVAPicture(&slice_param.RefPicList0[i]);
+    InitVAPicture(&slice_param.RefPicList1[i]);
+  }
+
+  for (size_t i = 0;
+       i < ref_pic_list0.size() && i < arraysize(slice_param.RefPicList0);
+       ++i) {
+    if (ref_pic_list0[i])
+      FillVAPicture(&slice_param.RefPicList0[i], ref_pic_list0[i]);
+  }
+  for (size_t i = 0;
+       i < ref_pic_list1.size() && i < arraysize(slice_param.RefPicList1);
+       ++i) {
+    if (ref_pic_list1[i])
+      FillVAPicture(&slice_param.RefPicList1[i], ref_pic_list1[i]);
+  }
+
+  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
+                                    sizeof(slice_param), &slice_param))
+    return false;
+
+  // Can't help it, blame libva...
+  void* non_const_ptr = const_cast<uint8_t*>(data);
+  return vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType, size,
+                                      non_const_ptr);
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitDecode(
+    const scoped_refptr<H264Picture>& pic) {
+  VLOGF(4) << "Decoding POC " << pic->pic_order_cnt;
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      H264PictureToVaapiDecodeSurface(pic);
+
+  return vaapi_dec_->DecodeSurface(dec_surface);
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::OutputPicture(
+    const scoped_refptr<H264Picture>& pic) {
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      H264PictureToVaapiDecodeSurface(pic);
+  dec_surface->set_visible_rect(pic->visible_rect);
+  vaapi_dec_->SurfaceReady(dec_surface);
+
+  return true;
+}
+
+void VaapiVideoDecodeAccelerator::VaapiH264Accelerator::Reset() {
+  vaapi_wrapper_->DestroyPendingBuffers();
+}
+
+scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
+VaapiVideoDecodeAccelerator::VaapiH264Accelerator::
+    H264PictureToVaapiDecodeSurface(const scoped_refptr<H264Picture>& pic) {
+  VaapiH264Picture* vaapi_pic = pic->AsVaapiH264Picture();
+  CHECK(vaapi_pic);
+  return vaapi_pic->dec_surface();
+}
+
+void VaapiVideoDecodeAccelerator::VaapiH264Accelerator::FillVAPicture(
+    VAPictureH264* va_pic,
+    scoped_refptr<H264Picture> pic) {
+  VASurfaceID va_surface_id = VA_INVALID_SURFACE;
+
+  if (!pic->nonexisting) {
+    scoped_refptr<VaapiDecodeSurface> dec_surface =
+        H264PictureToVaapiDecodeSurface(pic);
+    va_surface_id = dec_surface->va_surface()->id();
+  }
+
+  va_pic->picture_id = va_surface_id;
+  va_pic->frame_idx = pic->frame_num;
+  va_pic->flags = 0;
+
+  switch (pic->field) {
+    case H264Picture::FIELD_NONE:
+      break;
+    case H264Picture::FIELD_TOP:
+      va_pic->flags |= VA_PICTURE_H264_TOP_FIELD;
+      break;
+    case H264Picture::FIELD_BOTTOM:
+      va_pic->flags |= VA_PICTURE_H264_BOTTOM_FIELD;
+      break;
+  }
+
+  if (pic->ref) {
+    va_pic->flags |= pic->long_term ? VA_PICTURE_H264_LONG_TERM_REFERENCE
+                                    : VA_PICTURE_H264_SHORT_TERM_REFERENCE;
+  }
+
+  va_pic->TopFieldOrderCnt = pic->top_field_order_cnt;
+  va_pic->BottomFieldOrderCnt = pic->bottom_field_order_cnt;
+}
+
+int VaapiVideoDecodeAccelerator::VaapiH264Accelerator::FillVARefFramesFromDPB(
+    const H264DPB& dpb,
+    VAPictureH264* va_pics,
+    int num_pics) {
+  H264Picture::Vector::const_reverse_iterator rit;
+  int i;
+
+  // Return reference frames in reverse order of insertion.
+  // Libva does not document this, but other implementations (e.g. mplayer)
+  // do it this way as well.
+  for (rit = dpb.rbegin(), i = 0; rit != dpb.rend() && i < num_pics; ++rit) {
+    if ((*rit)->ref)
+      FillVAPicture(&va_pics[i++], *rit);
+  }
+
+  return i;
+}
+
+VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::VaapiVP8Accelerator(
+    VaapiVideoDecodeAccelerator* vaapi_dec,
+    VaapiWrapper* vaapi_wrapper)
+    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
+  DCHECK(vaapi_wrapper_);
+  DCHECK(vaapi_dec_);
+}
+
+VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::~VaapiVP8Accelerator() {}
+
+scoped_refptr<VP8Picture>
+VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::CreateVP8Picture() {
+  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
+  if (!va_surface)
+    return nullptr;
+
+  return new VaapiVP8Picture(std::move(va_surface));
+}
+
+#define ARRAY_MEMCPY_CHECKED(to, from)                               \
+  do {                                                               \
+    static_assert(sizeof(to) == sizeof(from),                        \
+                  #from " and " #to " arrays must be of same size"); \
+    memcpy(to, from, sizeof(to));                                    \
+  } while (0)
+
+bool VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::SubmitDecode(
+    const scoped_refptr<VP8Picture>& pic,
+    const Vp8FrameHeader* frame_hdr,
+    const scoped_refptr<VP8Picture>& last_frame,
+    const scoped_refptr<VP8Picture>& golden_frame,
+    const scoped_refptr<VP8Picture>& alt_frame) {
+  VAIQMatrixBufferVP8 iq_matrix_buf;
+  memset(&iq_matrix_buf, 0, sizeof(VAIQMatrixBufferVP8));
+
+  const Vp8SegmentationHeader& sgmnt_hdr = frame_hdr->segmentation_hdr;
+  const Vp8QuantizationHeader& quant_hdr = frame_hdr->quantization_hdr;
+  static_assert(arraysize(iq_matrix_buf.quantization_index) == kMaxMBSegments,
+                "incorrect quantization matrix size");
+  for (size_t i = 0; i < kMaxMBSegments; ++i) {
+    int q = quant_hdr.y_ac_qi;
+
+    if (sgmnt_hdr.segmentation_enabled) {
+      if (sgmnt_hdr.segment_feature_mode ==
+          Vp8SegmentationHeader::FEATURE_MODE_ABSOLUTE)
+        q = sgmnt_hdr.quantizer_update_value[i];
+      else
+        q += sgmnt_hdr.quantizer_update_value[i];
+    }
+
+#define CLAMP_Q(q) std::min(std::max(q, 0), 127)
+    static_assert(arraysize(iq_matrix_buf.quantization_index[i]) == 6,
+                  "incorrect quantization matrix size");
+    iq_matrix_buf.quantization_index[i][0] = CLAMP_Q(q);
+    iq_matrix_buf.quantization_index[i][1] = CLAMP_Q(q + quant_hdr.y_dc_delta);
+    iq_matrix_buf.quantization_index[i][2] = CLAMP_Q(q + quant_hdr.y2_dc_delta);
+    iq_matrix_buf.quantization_index[i][3] = CLAMP_Q(q + quant_hdr.y2_ac_delta);
+    iq_matrix_buf.quantization_index[i][4] = CLAMP_Q(q + quant_hdr.uv_dc_delta);
+    iq_matrix_buf.quantization_index[i][5] = CLAMP_Q(q + quant_hdr.uv_ac_delta);
+#undef CLAMP_Q
+  }
+
+  if (!vaapi_wrapper_->SubmitBuffer(
+          VAIQMatrixBufferType, sizeof(VAIQMatrixBufferVP8), &iq_matrix_buf))
+    return false;
+
+  VAProbabilityDataBufferVP8 prob_buf;
+  memset(&prob_buf, 0, sizeof(VAProbabilityDataBufferVP8));
+
+  const Vp8EntropyHeader& entr_hdr = frame_hdr->entropy_hdr;
+  ARRAY_MEMCPY_CHECKED(prob_buf.dct_coeff_probs, entr_hdr.coeff_probs);
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAProbabilityBufferType,
+                                    sizeof(VAProbabilityDataBufferVP8),
+                                    &prob_buf))
+    return false;
+
+  VAPictureParameterBufferVP8 pic_param;
+  memset(&pic_param, 0, sizeof(VAPictureParameterBufferVP8));
+  pic_param.frame_width = frame_hdr->width;
+  pic_param.frame_height = frame_hdr->height;
+
+  if (last_frame) {
+    scoped_refptr<VaapiDecodeSurface> last_frame_surface =
+        VP8PictureToVaapiDecodeSurface(last_frame);
+    pic_param.last_ref_frame = last_frame_surface->va_surface()->id();
+  } else {
+    pic_param.last_ref_frame = VA_INVALID_SURFACE;
+  }
+
+  if (golden_frame) {
+    scoped_refptr<VaapiDecodeSurface> golden_frame_surface =
+        VP8PictureToVaapiDecodeSurface(golden_frame);
+    pic_param.golden_ref_frame = golden_frame_surface->va_surface()->id();
+  } else {
+    pic_param.golden_ref_frame = VA_INVALID_SURFACE;
+  }
+
+  if (alt_frame) {
+    scoped_refptr<VaapiDecodeSurface> alt_frame_surface =
+        VP8PictureToVaapiDecodeSurface(alt_frame);
+    pic_param.alt_ref_frame = alt_frame_surface->va_surface()->id();
+  } else {
+    pic_param.alt_ref_frame = VA_INVALID_SURFACE;
+  }
+
+  pic_param.out_of_loop_frame = VA_INVALID_SURFACE;
+
+  const Vp8LoopFilterHeader& lf_hdr = frame_hdr->loopfilter_hdr;
+
+#define FHDR_TO_PP_PF(a, b) pic_param.pic_fields.bits.a = (b)
+  FHDR_TO_PP_PF(key_frame, frame_hdr->IsKeyframe() ? 0 : 1);
+  FHDR_TO_PP_PF(version, frame_hdr->version);
+  FHDR_TO_PP_PF(segmentation_enabled, sgmnt_hdr.segmentation_enabled);
+  FHDR_TO_PP_PF(update_mb_segmentation_map,
+                sgmnt_hdr.update_mb_segmentation_map);
+  FHDR_TO_PP_PF(update_segment_feature_data,
+                sgmnt_hdr.update_segment_feature_data);
+  FHDR_TO_PP_PF(filter_type, lf_hdr.type);
+  FHDR_TO_PP_PF(sharpness_level, lf_hdr.sharpness_level);
+  FHDR_TO_PP_PF(loop_filter_adj_enable, lf_hdr.loop_filter_adj_enable);
+  FHDR_TO_PP_PF(mode_ref_lf_delta_update, lf_hdr.mode_ref_lf_delta_update);
+  FHDR_TO_PP_PF(sign_bias_golden, frame_hdr->sign_bias_golden);
+  FHDR_TO_PP_PF(sign_bias_alternate, frame_hdr->sign_bias_alternate);
+  FHDR_TO_PP_PF(mb_no_coeff_skip, frame_hdr->mb_no_skip_coeff);
+  FHDR_TO_PP_PF(loop_filter_disable, lf_hdr.level == 0);
+#undef FHDR_TO_PP_PF
+
+  ARRAY_MEMCPY_CHECKED(pic_param.mb_segment_tree_probs, sgmnt_hdr.segment_prob);
+
+  static_assert(arraysize(sgmnt_hdr.lf_update_value) ==
+                    arraysize(pic_param.loop_filter_level),
+                "loop filter level arrays mismatch");
+  for (size_t i = 0; i < arraysize(sgmnt_hdr.lf_update_value); ++i) {
+    int lf_level = lf_hdr.level;
+    if (sgmnt_hdr.segmentation_enabled) {
+      if (sgmnt_hdr.segment_feature_mode ==
+          Vp8SegmentationHeader::FEATURE_MODE_ABSOLUTE)
+        lf_level = sgmnt_hdr.lf_update_value[i];
+      else
+        lf_level += sgmnt_hdr.lf_update_value[i];
+    }
+
+    // Clamp to [0..63] range.
+    lf_level = std::min(std::max(lf_level, 0), 63);
+    pic_param.loop_filter_level[i] = lf_level;
+  }
+
+  static_assert(
+      arraysize(lf_hdr.ref_frame_delta) ==
+              arraysize(pic_param.loop_filter_deltas_ref_frame) &&
+          arraysize(lf_hdr.mb_mode_delta) ==
+              arraysize(pic_param.loop_filter_deltas_mode) &&
+          arraysize(lf_hdr.ref_frame_delta) == arraysize(lf_hdr.mb_mode_delta),
+      "loop filter deltas arrays size mismatch");
+  for (size_t i = 0; i < arraysize(lf_hdr.ref_frame_delta); ++i) {
+    pic_param.loop_filter_deltas_ref_frame[i] = lf_hdr.ref_frame_delta[i];
+    pic_param.loop_filter_deltas_mode[i] = lf_hdr.mb_mode_delta[i];
+  }
+
+#define FHDR_TO_PP(a) pic_param.a = frame_hdr->a
+  FHDR_TO_PP(prob_skip_false);
+  FHDR_TO_PP(prob_intra);
+  FHDR_TO_PP(prob_last);
+  FHDR_TO_PP(prob_gf);
+#undef FHDR_TO_PP
+
+  ARRAY_MEMCPY_CHECKED(pic_param.y_mode_probs, entr_hdr.y_mode_probs);
+  ARRAY_MEMCPY_CHECKED(pic_param.uv_mode_probs, entr_hdr.uv_mode_probs);
+  ARRAY_MEMCPY_CHECKED(pic_param.mv_probs, entr_hdr.mv_probs);
+
+  pic_param.bool_coder_ctx.range = frame_hdr->bool_dec_range;
+  pic_param.bool_coder_ctx.value = frame_hdr->bool_dec_value;
+  pic_param.bool_coder_ctx.count = frame_hdr->bool_dec_count;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
+                                    sizeof(pic_param), &pic_param))
+    return false;
+
+  VASliceParameterBufferVP8 slice_param;
+  memset(&slice_param, 0, sizeof(slice_param));
+  slice_param.slice_data_size = frame_hdr->frame_size;
+  slice_param.slice_data_offset = frame_hdr->first_part_offset;
+  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
+  slice_param.macroblock_offset = frame_hdr->macroblock_bit_offset;
+  // Number of DCT partitions plus control partition.
+  slice_param.num_of_partitions = frame_hdr->num_of_dct_partitions + 1;
+
+  // Per VAAPI, this size only includes the size of the macroblock data in
+  // the first partition (in bytes), so we have to subtract the header size.
+  slice_param.partition_size[0] =
+      frame_hdr->first_part_size - ((frame_hdr->macroblock_bit_offset + 7) / 8);
+
+  for (size_t i = 0; i < frame_hdr->num_of_dct_partitions; ++i)
+    slice_param.partition_size[i + 1] = frame_hdr->dct_partition_sizes[i];
+
+  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
+                                    sizeof(VASliceParameterBufferVP8),
+                                    &slice_param))
+    return false;
+
+  void* non_const_ptr = const_cast<uint8_t*>(frame_hdr->data);
+  if (!vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType,
+                                    frame_hdr->frame_size, non_const_ptr))
+    return false;
+
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      VP8PictureToVaapiDecodeSurface(pic);
+
+  return vaapi_dec_->DecodeSurface(dec_surface);
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::OutputPicture(
+    const scoped_refptr<VP8Picture>& pic) {
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      VP8PictureToVaapiDecodeSurface(pic);
+  dec_surface->set_visible_rect(pic->visible_rect);
+  vaapi_dec_->SurfaceReady(dec_surface);
+  return true;
+}
+
+scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
+VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::
+    VP8PictureToVaapiDecodeSurface(const scoped_refptr<VP8Picture>& pic) {
+  VaapiVP8Picture* vaapi_pic = pic->AsVaapiVP8Picture();
+  CHECK(vaapi_pic);
+  return vaapi_pic->dec_surface();
+}
+
+VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::VaapiVP9Accelerator(
+    VaapiVideoDecodeAccelerator* vaapi_dec,
+    VaapiWrapper* vaapi_wrapper)
+    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
+  DCHECK(vaapi_wrapper_);
+  DCHECK(vaapi_dec_);
+}
+
+VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::~VaapiVP9Accelerator() {}
+
+scoped_refptr<VP9Picture>
+VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::CreateVP9Picture() {
+  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
+  if (!va_surface)
+    return nullptr;
+
+  return new VaapiVP9Picture(std::move(va_surface));
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::SubmitDecode(
+    const scoped_refptr<VP9Picture>& pic,
+    const Vp9SegmentationParams& seg,
+    const Vp9LoopFilterParams& lf,
+    const std::vector<scoped_refptr<VP9Picture>>& ref_pictures,
+    const base::Closure& done_cb) {
+  // |done_cb| should be null as we return false from IsFrameContextRequired().
+  DCHECK(done_cb.is_null());
+
+  VADecPictureParameterBufferVP9 pic_param;
+  memset(&pic_param, 0, sizeof(pic_param));
+
+  const Vp9FrameHeader* frame_hdr = pic->frame_hdr.get();
+  DCHECK(frame_hdr);
+
+  pic_param.frame_width = base::checked_cast<uint16_t>(frame_hdr->frame_width);
+  pic_param.frame_height =
+      base::checked_cast<uint16_t>(frame_hdr->frame_height);
+
+  CHECK_EQ(ref_pictures.size(), arraysize(pic_param.reference_frames));
+  for (size_t i = 0; i < arraysize(pic_param.reference_frames); ++i) {
+    VASurfaceID va_surface_id;
+    if (ref_pictures[i]) {
+      scoped_refptr<VaapiDecodeSurface> surface =
+          VP9PictureToVaapiDecodeSurface(ref_pictures[i]);
+      va_surface_id = surface->va_surface()->id();
+    } else {
+      va_surface_id = VA_INVALID_SURFACE;
+    }
+
+    pic_param.reference_frames[i] = va_surface_id;
+  }
+
+#define FHDR_TO_PP_PF1(a) pic_param.pic_fields.bits.a = frame_hdr->a
+#define FHDR_TO_PP_PF2(a, b) pic_param.pic_fields.bits.a = b
+  FHDR_TO_PP_PF2(subsampling_x, frame_hdr->subsampling_x == 1);
+  FHDR_TO_PP_PF2(subsampling_y, frame_hdr->subsampling_y == 1);
+  FHDR_TO_PP_PF2(frame_type, frame_hdr->IsKeyframe() ? 0 : 1);
+  FHDR_TO_PP_PF1(show_frame);
+  FHDR_TO_PP_PF1(error_resilient_mode);
+  FHDR_TO_PP_PF1(intra_only);
+  FHDR_TO_PP_PF1(allow_high_precision_mv);
+  FHDR_TO_PP_PF2(mcomp_filter_type, frame_hdr->interpolation_filter);
+  FHDR_TO_PP_PF1(frame_parallel_decoding_mode);
+  FHDR_TO_PP_PF1(reset_frame_context);
+  FHDR_TO_PP_PF1(refresh_frame_context);
+  FHDR_TO_PP_PF2(frame_context_idx, frame_hdr->frame_context_idx_to_save_probs);
+  FHDR_TO_PP_PF2(segmentation_enabled, seg.enabled);
+  FHDR_TO_PP_PF2(segmentation_temporal_update, seg.temporal_update);
+  FHDR_TO_PP_PF2(segmentation_update_map, seg.update_map);
+  FHDR_TO_PP_PF2(last_ref_frame, frame_hdr->ref_frame_idx[0]);
+  FHDR_TO_PP_PF2(last_ref_frame_sign_bias,
+                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_LAST]);
+  FHDR_TO_PP_PF2(golden_ref_frame, frame_hdr->ref_frame_idx[1]);
+  FHDR_TO_PP_PF2(golden_ref_frame_sign_bias,
+                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_GOLDEN]);
+  FHDR_TO_PP_PF2(alt_ref_frame, frame_hdr->ref_frame_idx[2]);
+  FHDR_TO_PP_PF2(alt_ref_frame_sign_bias,
+                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_ALTREF]);
+  FHDR_TO_PP_PF2(lossless_flag, frame_hdr->quant_params.IsLossless());
+#undef FHDR_TO_PP_PF2
+#undef FHDR_TO_PP_PF1
+
+  pic_param.filter_level = lf.level;
+  pic_param.sharpness_level = lf.sharpness;
+  pic_param.log2_tile_rows = frame_hdr->tile_rows_log2;
+  pic_param.log2_tile_columns = frame_hdr->tile_cols_log2;
+  pic_param.frame_header_length_in_bytes = frame_hdr->uncompressed_header_size;
+  pic_param.first_partition_size = frame_hdr->header_size_in_bytes;
+
+  ARRAY_MEMCPY_CHECKED(pic_param.mb_segment_tree_probs, seg.tree_probs);
+  ARRAY_MEMCPY_CHECKED(pic_param.segment_pred_probs, seg.pred_probs);
+
+  pic_param.profile = frame_hdr->profile;
+  pic_param.bit_depth = frame_hdr->bit_depth;
+  DCHECK((pic_param.profile == 0 && pic_param.bit_depth == 8) ||
+         (pic_param.profile == 2 && pic_param.bit_depth == 10));
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
+                                    sizeof(pic_param), &pic_param))
+    return false;
+
+  VASliceParameterBufferVP9 slice_param;
+  memset(&slice_param, 0, sizeof(slice_param));
+  slice_param.slice_data_size = frame_hdr->frame_size;
+  slice_param.slice_data_offset = 0;
+  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
+
+  static_assert(arraysize(Vp9SegmentationParams::feature_enabled) ==
+                    arraysize(slice_param.seg_param),
+                "seg_param array of incorrect size");
+  for (size_t i = 0; i < arraysize(slice_param.seg_param); ++i) {
+    VASegmentParameterVP9& seg_param = slice_param.seg_param[i];
+#define SEG_TO_SP_SF(a, b) seg_param.segment_flags.fields.a = b
+    SEG_TO_SP_SF(
+        segment_reference_enabled,
+        seg.FeatureEnabled(i, Vp9SegmentationParams::SEG_LVL_REF_FRAME));
+    SEG_TO_SP_SF(segment_reference,
+                 seg.FeatureData(i, Vp9SegmentationParams::SEG_LVL_REF_FRAME));
+    SEG_TO_SP_SF(segment_reference_skipped,
+                 seg.FeatureEnabled(i, Vp9SegmentationParams::SEG_LVL_SKIP));
+#undef SEG_TO_SP_SF
+
+    ARRAY_MEMCPY_CHECKED(seg_param.filter_level, lf.lvl[i]);
+
+    seg_param.luma_dc_quant_scale = seg.y_dequant[i][0];
+    seg_param.luma_ac_quant_scale = seg.y_dequant[i][1];
+    seg_param.chroma_dc_quant_scale = seg.uv_dequant[i][0];
+    seg_param.chroma_ac_quant_scale = seg.uv_dequant[i][1];
+  }
+
+  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
+                                    sizeof(slice_param), &slice_param))
+    return false;
+
+  void* non_const_ptr = const_cast<uint8_t*>(frame_hdr->data);
+  if (!vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType,
+                                    frame_hdr->frame_size, non_const_ptr))
+    return false;
+
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      VP9PictureToVaapiDecodeSurface(pic);
+
+  return vaapi_dec_->DecodeSurface(dec_surface);
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::OutputPicture(
+    const scoped_refptr<VP9Picture>& pic) {
+  scoped_refptr<VaapiDecodeSurface> dec_surface =
+      VP9PictureToVaapiDecodeSurface(pic);
+  dec_surface->set_visible_rect(pic->visible_rect);
+  vaapi_dec_->SurfaceReady(dec_surface);
+  return true;
+}
+
+bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::GetFrameContext(
+    const scoped_refptr<VP9Picture>& pic,
+    Vp9FrameContext* frame_ctx) {
+  NOTIMPLEMENTED() << "Frame context update not supported";
+  return false;
+}
+
+scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
+VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::
+    VP9PictureToVaapiDecodeSurface(const scoped_refptr<VP9Picture>& pic) {
+  VaapiVP9Picture* vaapi_pic = pic->AsVaapiVP9Picture();
+  CHECK(vaapi_pic);
+  return vaapi_pic->dec_surface();
+}
+
+// static
+VideoDecodeAccelerator::SupportedProfiles
+VaapiVideoDecodeAccelerator::GetSupportedProfiles() {
+  return VaapiWrapper::GetSupportedDecodeProfiles();
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator.h
@@ -0,0 +1,325 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+//
+// This file contains an implementation of VideoDecoderAccelerator
+// that utilizes hardware video decoder present on Intel CPUs.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
+#define MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <list>
+#include <map>
+#include <memory>
+#include <utility>
+#include <vector>
+
+#include "base/containers/queue.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/memory/linked_ptr.h"
+#include "base/memory/ref_counted.h"
+#include "base/memory/weak_ptr.h"
+#include "base/single_thread_task_runner.h"
+#include "base/synchronization/condition_variable.h"
+#include "base/synchronization/lock.h"
+#include "base/threading/thread.h"
+#include "media/base/bitstream_buffer.h"
+#include "media/gpu/gpu_video_decode_accelerator_helpers.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/shared_memory_region.h"
+#include "media/gpu/vaapi/vaapi_picture_factory.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/picture.h"
+#include "media/video/video_decode_accelerator.h"
+
+namespace gl {
+class GLImage;
+}
+
+namespace media {
+
+class AcceleratedVideoDecoder;
+class VaapiPicture;
+
+// Class to provide video decode acceleration for Intel systems with hardware
+// support for it, and on which libva is available.
+// Decoding tasks are performed in a separate decoding thread.
+//
+// Threading/life-cycle: this object is created & destroyed on the GPU
+// ChildThread.  A few methods on it are called on the decoder thread which is
+// stopped during |this->Destroy()|, so any tasks posted to the decoder thread
+// can assume |*this| is still alive.  See |weak_this_| below for more details.
+class MEDIA_GPU_EXPORT VaapiVideoDecodeAccelerator
+    : public VideoDecodeAccelerator {
+ public:
+  // Wrapper of a VASurface with id and visible area.
+  class VaapiDecodeSurface;
+
+  VaapiVideoDecodeAccelerator(
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb);
+
+  ~VaapiVideoDecodeAccelerator() override;
+
+  // VideoDecodeAccelerator implementation.
+  bool Initialize(const Config& config, Client* client) override;
+  void Decode(const BitstreamBuffer& bitstream_buffer) override;
+  void AssignPictureBuffers(const std::vector<PictureBuffer>& buffers) override;
+#if defined(USE_OZONE)
+  void ImportBufferForPicture(
+      int32_t picture_buffer_id,
+      const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) override;
+#endif
+  void ReusePictureBuffer(int32_t picture_buffer_id) override;
+  void Flush() override;
+  void Reset() override;
+  void Destroy() override;
+  bool TryToSetupDecodeOnSeparateThread(
+      const base::WeakPtr<Client>& decode_client,
+      const scoped_refptr<base::SingleThreadTaskRunner>& decode_task_runner)
+      override;
+
+  static VideoDecodeAccelerator::SupportedProfiles GetSupportedProfiles();
+
+ private:
+  friend class VaapiVideoDecodeAcceleratorTest;
+  class VaapiH264Accelerator;
+  class VaapiVP8Accelerator;
+  class VaapiVP9Accelerator;
+
+  // An input buffer with id provided by the client and awaiting consumption.
+  class InputBuffer;
+
+  // Notify the client that an error has occurred and decoding cannot continue.
+  void NotifyError(Error error);
+
+  // Queue a input buffer for decode.
+  void QueueInputBuffer(const BitstreamBuffer& bitstream_buffer);
+
+  // Get a new input buffer from the queue and set it up in decoder. This will
+  // sleep if no input buffers are available. Return true if a new buffer has
+  // been set up, false if an early exit has been requested (due to initiated
+  // reset/flush/destroy).
+  bool GetInputBuffer_Locked();
+
+  // Signal the client that the current buffer has been read and can be
+  // returned. Will also release the mapping.
+  void ReturnCurrInputBuffer_Locked();
+
+  // Wait for more surfaces to become available. Return true once they do or
+  // false if an early exit has been requested (due to an initiated
+  // reset/flush/destroy).
+  bool WaitForSurfaces_Locked();
+
+  // Continue decoding given input buffers and sleep waiting for input/output
+  // as needed. Will exit if a new set of surfaces or reset/flush/destroy
+  // is requested.
+  void DecodeTask();
+
+  // Scheduled after receiving a flush request and executed after the current
+  // decoding task finishes decoding pending inputs. Makes the decoder return
+  // all remaining output pictures and puts it in an idle state, ready
+  // to resume if needed and schedules a FinishFlush.
+  void FlushTask();
+
+  // Scheduled by the FlushTask after decoder is flushed to put VAVDA into idle
+  // state and notify the client that flushing has been finished.
+  void FinishFlush();
+
+  // Scheduled after receiving a reset request and executed after the current
+  // decoding task finishes decoding the current frame. Puts the decoder into
+  // an idle state, ready to resume if needed, discarding decoded but not yet
+  // outputted pictures (decoder keeps ownership of their associated picture
+  // buffers). Schedules a FinishReset afterwards.
+  void ResetTask();
+
+  // Scheduled by ResetTask after it's done putting VAVDA into an idle state.
+  // Drops remaining input buffers and notifies the client that reset has been
+  // finished.
+  void FinishReset();
+
+  // Helper for Destroy(), doing all the actual work except for deleting self.
+  void Cleanup();
+
+  // Get a usable framebuffer configuration for use in binding textures
+  // or return false on failure.
+  bool InitializeFBConfig();
+
+  // Callback to be executed once we have a |va_surface| to be output and
+  // an available |picture| to use for output.
+  // Puts contents of |va_surface| into given |picture|, releases the surface
+  // and passes the resulting picture to client to output the given
+  // |visible_rect| part of it.
+  void OutputPicture(const scoped_refptr<VASurface>& va_surface,
+                     int32_t input_id,
+                     gfx::Rect visible_rect,
+                     VaapiPicture* picture);
+
+  // Try to OutputPicture() if we have both a ready surface and picture.
+  void TryOutputSurface();
+
+  // Called when a VASurface is no longer in use by the decoder or is not being
+  // synced/waiting to be synced to a picture. Returns it to available surfaces
+  // pool.
+  void RecycleVASurfaceID(VASurfaceID va_surface_id);
+
+  // Initiate wait cycle for surfaces to be released before we release them
+  // and allocate new ones, as requested by the decoder.
+  void InitiateSurfaceSetChange(size_t num_pics, gfx::Size size);
+
+  // Check if the surfaces have been released or post ourselves for later.
+  void TryFinishSurfaceSetChange();
+
+  //
+  // Below methods are used by accelerator implementations.
+  //
+  // Decode of |dec_surface| is ready to be submitted and all codec-specific
+  // settings are set in hardware.
+  bool DecodeSurface(const scoped_refptr<VaapiDecodeSurface>& dec_surface);
+
+  // |dec_surface| is ready to be outputted once decode is finished.
+  // This can be called before decode is actually done in hardware, and this
+  // method is responsible for maintaining the ordering, i.e. the surfaces have
+  // to be outputted in the same order as SurfaceReady is called.
+  // On Intel, we don't have to explicitly maintain the ordering however, as the
+  // driver will maintain ordering, as well as dependencies, and will process
+  // each submitted command in order, and run each command only if its
+  // dependencies are ready.
+  void SurfaceReady(const scoped_refptr<VaapiDecodeSurface>& dec_surface);
+
+  // Return a new VaapiDecodeSurface for decoding into, or nullptr if not
+  // available.
+  scoped_refptr<VaapiDecodeSurface> CreateSurface();
+
+  // VAVDA state.
+  enum State {
+    // Initialize() not called yet or failed.
+    kUninitialized,
+    // DecodeTask running.
+    kDecoding,
+    // Resetting, waiting for decoder to finish current task and cleanup.
+    kResetting,
+    // Idle, decoder in state ready to start/resume decoding.
+    kIdle,
+    // Destroying, waiting for the decoder to finish current task.
+    kDestroying,
+  };
+
+  // Protects input buffer and surface queues and state_.
+  base::Lock lock_;
+  State state_;
+  Config::OutputMode output_mode_;
+
+  // Queue of available InputBuffers (picture_buffer_ids).
+  base::queue<std::unique_ptr<InputBuffer>> input_buffers_;
+  // Signalled when input buffers are queued onto |input_buffers_| queue.
+  base::ConditionVariable input_ready_;
+
+  // Current input buffer at decoder.
+  std::unique_ptr<InputBuffer> curr_input_buffer_;
+
+  // Queue for incoming output buffers (texture ids).
+  using OutputBuffers = base::queue<int32_t>;
+  OutputBuffers output_buffers_;
+
+  std::unique_ptr<VaapiPictureFactory> vaapi_picture_factory_;
+
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  // All allocated Pictures, regardless of their current state. Pictures are
+  // allocated once using |create_vaapi_picture_callback_| and destroyed at the
+  // end of decode. Comes after |vaapi_wrapper_| to ensure all pictures are
+  // destroyed before said |vaapi_wrapper_| is destroyed.
+  using Pictures = std::map<int32_t, std::unique_ptr<VaapiPicture>>;
+  Pictures pictures_;
+
+  // Return a VaapiPicture associated with given client-provided id.
+  VaapiPicture* PictureById(int32_t picture_buffer_id);
+
+  // VA Surfaces no longer in use that can be passed back to the decoder for
+  // reuse, once it requests them.
+  std::list<VASurfaceID> available_va_surfaces_;
+  // Signalled when output surfaces are queued onto the available_va_surfaces_
+  // queue.
+  base::ConditionVariable surfaces_available_;
+
+  // Pending output requests from the decoder. When it indicates that we should
+  // output a surface and we have an available Picture (i.e. texture) ready
+  // to use, we'll execute the callback passing the Picture. The callback
+  // will put the contents of the surface into the picture and return it to
+  // the client, releasing the surface as well.
+  // If we don't have any available Pictures at the time when the decoder
+  // requests output, we'll store the request on pending_output_cbs_ queue for
+  // later and run it once the client gives us more textures
+  // via ReusePictureBuffer().
+  using OutputCB = base::Callback<void(VaapiPicture*)>;
+  base::queue<OutputCB> pending_output_cbs_;
+
+  // ChildThread's task runner.
+  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
+
+  // WeakPtr<> pointing to |this| for use in posting tasks from the decoder
+  // thread back to the ChildThread.  Because the decoder thread is a member of
+  // this class, any task running on the decoder thread is guaranteed that this
+  // object is still alive.  As a result, tasks posted from ChildThread to
+  // decoder thread should use base::Unretained(this), and tasks posted from the
+  // decoder thread to the ChildThread should use |weak_this_|.
+  base::WeakPtr<VaapiVideoDecodeAccelerator> weak_this_;
+
+  // Callback used when creating VASurface objects.
+  VASurface::ReleaseCB va_surface_release_cb_;
+
+  // To expose client callbacks from VideoDecodeAccelerator.
+  // NOTE: all calls to these objects *MUST* be executed on task_runner_.
+  std::unique_ptr<base::WeakPtrFactory<Client>> client_ptr_factory_;
+  base::WeakPtr<Client> client_;
+
+  // Accelerators come after vaapi_wrapper_ to ensure they are destroyed first.
+  std::unique_ptr<VaapiH264Accelerator> h264_accelerator_;
+  std::unique_ptr<VaapiVP8Accelerator> vp8_accelerator_;
+  std::unique_ptr<VaapiVP9Accelerator> vp9_accelerator_;
+  // After *_accelerator_ to ensure correct destruction order.
+  std::unique_ptr<AcceleratedVideoDecoder> decoder_;
+
+  base::Thread decoder_thread_;
+  // Use this to post tasks to |decoder_thread_| instead of
+  // |decoder_thread_.message_loop()| because the latter will be NULL once
+  // |decoder_thread_.Stop()| returns.
+  scoped_refptr<base::SingleThreadTaskRunner> decoder_thread_task_runner_;
+
+  int num_frames_at_client_;
+
+  // Whether we are waiting for any pending_output_cbs_ to be run before
+  // NotifyingFlushDone.
+  bool finish_flush_pending_;
+
+  // Decoder requested a new surface set and we are waiting for all the surfaces
+  // to be returned before we can free them.
+  bool awaiting_va_surfaces_recycle_;
+
+  // Last requested number/resolution of output picture buffers and their
+  // format.
+  size_t requested_num_pics_;
+  gfx::Size requested_pic_size_;
+  gfx::BufferFormat output_format_;
+  VideoCodecProfile profile_;
+
+  // Callback to make GL context current.
+  MakeGLContextCurrentCallback make_context_current_cb_;
+
+  // Callback to bind a GLImage to a given texture.
+  BindGLImageCallback bind_image_cb_;
+
+  // The WeakPtrFactory for |weak_this_|.
+  base::WeakPtrFactory<VaapiVideoDecodeAccelerator> weak_this_factory_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVideoDecodeAccelerator);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator_unittest.cc
@@ -0,0 +1,367 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
+
+#include "base/bind.h"
+#include "base/memory/ptr_util.h"
+#include "base/run_loop.h"
+#include "base/test/scoped_task_environment.h"
+#include "media/gpu/accelerated_video_decoder.h"
+#include "media/gpu/format_utils.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "media/gpu/vaapi/vaapi_picture_factory.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "testing/gmock/include/gmock/gmock.h"
+#include "testing/gtest/include/gtest/gtest.h"
+
+using ::testing::_;
+using ::testing::DoAll;
+using ::testing::Invoke;
+using ::testing::Return;
+using ::testing::TestWithParam;
+using ::testing::ValuesIn;
+using ::testing::WithArgs;
+
+namespace media {
+
+namespace {
+
+ACTION_P(RunClosure, closure) {
+  closure.Run();
+}
+
+constexpr VideoCodecProfile kCodecProfiles[] = {H264PROFILE_MIN, VP8PROFILE_MIN,
+                                                VP9PROFILE_MIN};
+constexpr int kBitstreamId = 123;
+constexpr size_t kInputSize = 256;
+
+}  // namespace
+
+class MockAcceleratedVideoDecoder : public AcceleratedVideoDecoder {
+ public:
+  MockAcceleratedVideoDecoder() = default;
+  ~MockAcceleratedVideoDecoder() override = default;
+
+  MOCK_METHOD2(SetStream, void(const uint8_t* ptr, size_t size));
+  MOCK_METHOD0(Flush, bool());
+  MOCK_METHOD0(Reset, void());
+  MOCK_METHOD0(Decode, DecodeResult());
+  MOCK_CONST_METHOD0(GetPicSize, gfx::Size());
+  MOCK_CONST_METHOD0(GetRequiredNumOfPictures, size_t());
+};
+
+class MockVaapiWrapper : public VaapiWrapper {
+ public:
+  MockVaapiWrapper() = default;
+  MOCK_METHOD4(
+      CreateSurfaces,
+      bool(unsigned int, const gfx::Size&, size_t, std::vector<VASurfaceID>*));
+  MOCK_METHOD0(DestroySurfaces, void());
+
+ private:
+  ~MockVaapiWrapper() override = default;
+};
+
+class MockVaapiPicture : public VaapiPicture {
+ public:
+  MockVaapiPicture(const scoped_refptr<VaapiWrapper>& vaapi_wrapper,
+                   const MakeGLContextCurrentCallback& make_context_current_cb,
+                   const BindGLImageCallback& bind_image_cb,
+                   int32_t picture_buffer_id,
+                   const gfx::Size& size,
+                   uint32_t texture_id,
+                   uint32_t client_texture_id)
+      : VaapiPicture(vaapi_wrapper,
+                     make_context_current_cb,
+                     bind_image_cb,
+                     picture_buffer_id,
+                     size,
+                     texture_id,
+                     client_texture_id) {}
+  ~MockVaapiPicture() override = default;
+
+  // VaapiPicture implementation.
+  bool Allocate(gfx::BufferFormat format) override { return true; }
+  bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) override {
+    return true;
+  }
+  bool DownloadFromSurface(
+      const scoped_refptr<VASurface>& va_surface) override {
+    return true;
+  }
+  bool AllowOverlay() const override { return false; }
+};
+
+class MockVaapiPictureFactory : public VaapiPictureFactory {
+ public:
+  MockVaapiPictureFactory() = default;
+  ~MockVaapiPictureFactory() override = default;
+
+  MOCK_METHOD2(MockCreateVaapiPicture, void(VaapiWrapper*, const gfx::Size&));
+  std::unique_ptr<VaapiPicture> Create(
+      const scoped_refptr<VaapiWrapper>& vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb,
+      int32_t picture_buffer_id,
+      const gfx::Size& size,
+      uint32_t texture_id,
+      uint32_t client_texture_id) override {
+    MockCreateVaapiPicture(vaapi_wrapper.get(), size);
+    return std::make_unique<MockVaapiPicture>(
+        vaapi_wrapper, make_context_current_cb, bind_image_cb,
+        picture_buffer_id, size, texture_id, client_texture_id);
+  }
+};
+
+class VaapiVideoDecodeAcceleratorTest : public TestWithParam<VideoCodecProfile>,
+                                        public VideoDecodeAccelerator::Client {
+ public:
+  VaapiVideoDecodeAcceleratorTest()
+      : vda_(base::Bind([] { return true; }),
+             base::Bind([](uint32_t client_texture_id,
+                           uint32_t texture_target,
+                           const scoped_refptr<gl::GLImage>& image,
+                           bool can_bind_to_sampler) { return true; })),
+        decoder_thread_("VaapiVideoDecodeAcceleratorTestThread"),
+        mock_decoder_(new MockAcceleratedVideoDecoder),
+        mock_vaapi_picture_factory_(new MockVaapiPictureFactory()),
+        mock_vaapi_wrapper_(new MockVaapiWrapper()),
+        weak_ptr_factory_(this) {
+    decoder_thread_.Start();
+
+    // Don't want to go through a vda_->Initialize() because it binds too many
+    // items of the environment. Instead, just start the decoder thread.
+    vda_.decoder_thread_task_runner_ = decoder_thread_.task_runner();
+
+    // Plug in all the mocks and ourselves as the |client_|.
+    vda_.decoder_.reset(mock_decoder_);
+    vda_.client_ = weak_ptr_factory_.GetWeakPtr();
+    vda_.vaapi_wrapper_ = mock_vaapi_wrapper_;
+    vda_.vaapi_picture_factory_.reset(mock_vaapi_picture_factory_);
+
+    vda_.state_ = VaapiVideoDecodeAccelerator::kIdle;
+  }
+  ~VaapiVideoDecodeAcceleratorTest() {}
+
+  void SetUp() override {
+    in_shm_.reset(new base::SharedMemory);
+    ASSERT_TRUE(in_shm_->CreateAndMapAnonymous(kInputSize));
+  }
+
+  void SetVdaStateToUnitialized() {
+    vda_.state_ = VaapiVideoDecodeAccelerator::kUninitialized;
+  }
+
+  void QueueInputBuffer(const BitstreamBuffer& bitstream_buffer) {
+    vda_.QueueInputBuffer(bitstream_buffer);
+  }
+
+  void AssignPictureBuffers(const std::vector<PictureBuffer>& picture_buffers) {
+    vda_.AssignPictureBuffers(picture_buffers);
+  }
+
+  // Reset epilogue, needed to get |vda_| worker thread out of its Wait().
+  void ResetSequence() {
+    base::RunLoop run_loop;
+    base::Closure quit_closure = run_loop.QuitClosure();
+    EXPECT_CALL(*mock_decoder_, Reset());
+    EXPECT_CALL(*this, NotifyResetDone()).WillOnce(RunClosure(quit_closure));
+    vda_.Reset();
+    run_loop.Run();
+  }
+
+  // VideoDecodeAccelerator::Client methods.
+  MOCK_METHOD1(NotifyInitializationComplete, void(bool));
+  MOCK_METHOD5(
+      ProvidePictureBuffers,
+      void(uint32_t, VideoPixelFormat, uint32_t, const gfx::Size&, uint32_t));
+  MOCK_METHOD1(DismissPictureBuffer, void(int32_t));
+  MOCK_METHOD1(PictureReady, void(const Picture&));
+  MOCK_METHOD1(NotifyEndOfBitstreamBuffer, void(int32_t));
+  MOCK_METHOD0(NotifyFlushDone, void());
+  MOCK_METHOD0(NotifyResetDone, void());
+  MOCK_METHOD1(NotifyError, void(VideoDecodeAccelerator::Error));
+
+  base::test::ScopedTaskEnvironment scoped_task_environment_;
+
+  // The class under test and a worker thread for it.
+  VaapiVideoDecodeAccelerator vda_;
+  base::Thread decoder_thread_;
+
+  // Ownership passed to |vda_|, but we retain a pointer to it for MOCK checks.
+  MockAcceleratedVideoDecoder* mock_decoder_;
+  MockVaapiPictureFactory* mock_vaapi_picture_factory_;
+
+  scoped_refptr<MockVaapiWrapper> mock_vaapi_wrapper_;
+
+  std::unique_ptr<base::SharedMemory> in_shm_;
+
+ private:
+  base::WeakPtrFactory<VaapiVideoDecodeAcceleratorTest> weak_ptr_factory_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVideoDecodeAcceleratorTest);
+};
+
+// This test checks that QueueInputBuffer() fails when state is kUnitialized.
+TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndError) {
+  SetVdaStateToUnitialized();
+
+  base::SharedMemoryHandle handle;
+  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
+  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
+
+  EXPECT_CALL(*this,
+              NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE));
+  QueueInputBuffer(bitstream_buffer);
+}
+
+// Verifies that Decode() returning kDecodeError ends up pinging NotifyError().
+TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndDecodeError) {
+  base::SharedMemoryHandle handle;
+  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
+  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
+
+  base::RunLoop run_loop;
+  base::Closure quit_closure = run_loop.QuitClosure();
+  EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
+  EXPECT_CALL(*mock_decoder_, Decode())
+      .WillOnce(Return(AcceleratedVideoDecoder::kDecodeError));
+  EXPECT_CALL(*this, NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE))
+      .WillOnce(RunClosure(quit_closure));
+
+  QueueInputBuffer(bitstream_buffer);
+  run_loop.Run();
+}
+
+// Tests usual startup sequence: a BitstreamBuffer is enqueued for decode,
+// |vda_| asks for PictureBuffers, that we provide, and then the same Decode()
+// is tried again.
+TEST_P(VaapiVideoDecodeAcceleratorTest,
+       QueueInputBufferAndAssignPictureBuffersAndDecode) {
+  // Try and QueueInputBuffer(), |vda_| will ping us to ProvidePictureBuffers().
+  const uint32_t kNumPictures = 2;
+  const gfx::Size kPictureSize(64, 48);
+  {
+    base::SharedMemoryHandle handle;
+    handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
+    BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
+
+    base::RunLoop run_loop;
+    base::Closure quit_closure = run_loop.QuitClosure();
+    EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kAllocateNewSurfaces));
+
+    EXPECT_CALL(*mock_decoder_, GetRequiredNumOfPictures())
+        .WillOnce(Return(kNumPictures));
+    EXPECT_CALL(*mock_decoder_, GetPicSize()).WillOnce(Return(kPictureSize));
+    EXPECT_CALL(*mock_vaapi_wrapper_, DestroySurfaces());
+
+    EXPECT_CALL(*this,
+                ProvidePictureBuffers(kNumPictures, _, 1, kPictureSize, _))
+        .WillOnce(RunClosure(quit_closure));
+
+    QueueInputBuffer(bitstream_buffer);
+    run_loop.Run();
+  }
+  // AssignPictureBuffers() accordingly and expect another go at Decode().
+  {
+    base::RunLoop run_loop;
+    base::Closure quit_closure = run_loop.QuitClosure();
+
+    const std::vector<PictureBuffer> kPictureBuffers(
+        {{2, kPictureSize}, {3, kPictureSize}});
+    EXPECT_EQ(kPictureBuffers.size(), kNumPictures);
+
+    EXPECT_CALL(*mock_vaapi_wrapper_,
+                CreateSurfaces(_, kPictureSize, kNumPictures, _))
+        .WillOnce(DoAll(
+            WithArgs<3>(Invoke([](std::vector<VASurfaceID>* va_surface_ids) {
+              va_surface_ids->resize(kNumPictures);
+            })),
+            Return(true)));
+    EXPECT_CALL(*mock_vaapi_picture_factory_,
+                MockCreateVaapiPicture(mock_vaapi_wrapper_.get(), kPictureSize))
+        .Times(2);
+
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
+    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(kBitstreamId))
+        .WillOnce(RunClosure(quit_closure));
+
+    AssignPictureBuffers(kPictureBuffers);
+    run_loop.Run();
+  }
+
+  ResetSequence();
+}
+
+// Verifies that Decode() replying kRanOutOfStreamData (to signal it's finished)
+// rolls to a NotifyEndOfBitstreamBuffer().
+TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndDecodeFinished) {
+  base::SharedMemoryHandle handle;
+  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
+  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
+
+  {
+    base::RunLoop run_loop;
+    base::Closure quit_closure = run_loop.QuitClosure();
+    EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
+    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(kBitstreamId))
+        .WillOnce(RunClosure(quit_closure));
+
+    QueueInputBuffer(bitstream_buffer);
+    run_loop.Run();
+  }
+
+  ResetSequence();
+}
+
+// Verify that it is possible to select DRM(egl) and TFP(glx) at runtime.
+TEST_P(VaapiVideoDecodeAcceleratorTest, SupportedPlatforms) {
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationNone,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationNone));
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationDrm,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationEGLGLES2));
+
+#if defined(USE_X11)
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationX11,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationDesktopGL));
+#endif
+}
+
+// Verifies the expected buffer format for each output mode.
+TEST_P(VaapiVideoDecodeAcceleratorTest, PictureBufferFormat) {
+  gfx::BufferFormat allocate_format =
+      mock_vaapi_picture_factory_->GetBufferFormatForAllocateMode();
+  gfx::BufferFormat import_format =
+      mock_vaapi_picture_factory_->GetBufferFormatForImportMode();
+
+#if defined(USE_OZONE)
+  EXPECT_EQ(gfx::BufferFormat::BGRX_8888, allocate_format);
+#else
+  EXPECT_EQ(gfx::BufferFormat::RGBX_8888, allocate_format);
+#endif  // USE_OZONE
+
+  EXPECT_EQ(gfx::BufferFormat::YVU_420, import_format);
+
+  EXPECT_EQ(PIXEL_FORMAT_XRGB,
+            GfxBufferFormatToVideoPixelFormat(allocate_format));
+  EXPECT_EQ(PIXEL_FORMAT_YV12,
+            GfxBufferFormatToVideoPixelFormat(import_format));
+}
+
+INSTANTIATE_TEST_CASE_P(/* No prefix. */,
+                        VaapiVideoDecodeAcceleratorTest,
+                        ValuesIn(kCodecProfiles));
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_encode_accelerator.cc
@@ -0,0 +1,1102 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_video_encode_accelerator.h"
+
+#include <string.h>
+
+#include <memory>
+#include <utility>
+
+#include <va/va.h>
+
+#include "base/bind.h"
+#include "base/callback.h"
+#include "base/macros.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/numerics/safe_conversions.h"
+#include "base/single_thread_task_runner.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "media/base/bind_to_current_loop.h"
+#include "media/gpu/h264_dpb.h"
+#include "media/gpu/shared_memory_region.h"
+
+#define VLOGF(level) VLOG(level) << __func__ << "(): "
+#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
+
+#define NOTIFY_ERROR(error, msg)                        \
+  do {                                                  \
+    SetState(kError);                                   \
+    VLOGF(1) << msg;                                    \
+    VLOGF(1) << "Calling NotifyError(" << error << ")"; \
+    NotifyError(error);                                 \
+  } while (0)
+
+namespace media {
+
+namespace {
+// Need 2 surfaces for each frame: one for input data and one for
+// reconstructed picture, which is later used for reference.
+const size_t kMinSurfacesToEncode = 2;
+
+// Subjectively chosen.
+const size_t kNumInputBuffers = 4;
+const size_t kMaxNumReferenceFrames = 4;
+
+// TODO(owenlin): Adjust the value after b/71367113 is fixed.
+const size_t kExtraOutputBufferSize = 32768;  // bytes
+
+// We need up to kMaxNumReferenceFrames surfaces for reference, plus one
+// for input and one for encode (which will be added to the set of reference
+// frames for subsequent frames). Actual execution of HW encode is done
+// in parallel, and we want to process more frames in the meantime.
+// To have kNumInputBuffers in flight, we need a full set of reference +
+// encode surfaces (i.e. kMaxNumReferenceFrames + kMinSurfacesToEncode), and
+// (kNumInputBuffers - 1) of kMinSurfacesToEncode for the remaining frames
+// in flight.
+const size_t kNumSurfaces = kMaxNumReferenceFrames + kMinSurfacesToEncode +
+                            kMinSurfacesToEncode * (kNumInputBuffers - 1);
+
+// An IDR every 2048 frames, an I frame every 256 and no B frames.
+// We choose IDR period to equal MaxFrameNum so it must be a power of 2.
+const int kIDRPeriod = 2048;
+const int kIPeriod = 256;
+const int kIPPeriod = 1;
+
+const int kDefaultFramerate = 30;
+
+// HRD parameters (ch. E.2.2 in spec).
+const int kBitRateScale = 0;  // bit_rate_scale for SPS HRD parameters.
+const int kCPBSizeScale = 0;  // cpb_size_scale for SPS HRD parameters.
+
+const int kDefaultQP = 26;
+// All Intel codecs can do at least 4.1.
+const int kDefaultLevelIDC = 41;
+const int kChromaFormatIDC = 1;  // 4:2:0
+
+// Arbitrarily chosen bitrate window size for rate control, in ms.
+const int kCPBWindowSizeMs = 1500;
+
+// UMA errors that the VaapiVideoEncodeAccelerator class reports.
+enum VAVEAEncoderFailure {
+  VAAPI_ERROR = 0,
+  VAVEA_ENCODER_FAILURES_MAX,
+};
+}
+
+// Round |value| up to |alignment|, which must be a power of 2.
+static inline size_t RoundUpToPowerOf2(size_t value, size_t alignment) {
+  // Check that |alignment| is a power of 2.
+  DCHECK((alignment + (alignment - 1)) == (alignment | (alignment - 1)));
+  return ((value + (alignment - 1)) & ~(alignment - 1));
+}
+
+static void ReportToUMA(VAVEAEncoderFailure failure) {
+  UMA_HISTOGRAM_ENUMERATION("Media.VAVEA.EncoderFailure", failure,
+                            VAVEA_ENCODER_FAILURES_MAX + 1);
+}
+
+struct VaapiVideoEncodeAccelerator::InputFrameRef {
+  InputFrameRef(const scoped_refptr<VideoFrame>& frame, bool force_keyframe)
+      : frame(frame), force_keyframe(force_keyframe) {}
+  const scoped_refptr<VideoFrame> frame;
+  const bool force_keyframe;
+};
+
+struct VaapiVideoEncodeAccelerator::BitstreamBufferRef {
+  BitstreamBufferRef(int32_t id, std::unique_ptr<SharedMemoryRegion> shm)
+      : id(id), shm(std::move(shm)) {}
+  const int32_t id;
+  const std::unique_ptr<SharedMemoryRegion> shm;
+};
+
+VideoEncodeAccelerator::SupportedProfiles
+VaapiVideoEncodeAccelerator::GetSupportedProfiles() {
+  return VaapiWrapper::GetSupportedEncodeProfiles();
+}
+
+static unsigned int Log2OfPowerOf2(unsigned int x) {
+  CHECK_GT(x, 0u);
+  DCHECK_EQ(x & (x - 1), 0u);
+
+  int log = 0;
+  while (x > 1) {
+    x >>= 1;
+    ++log;
+  }
+  return log;
+}
+
+VaapiVideoEncodeAccelerator::VaapiVideoEncodeAccelerator()
+    : profile_(VIDEO_CODEC_PROFILE_UNKNOWN),
+      mb_width_(0),
+      mb_height_(0),
+      output_buffer_byte_size_(0),
+      state_(kUninitialized),
+      frame_num_(0),
+      idr_pic_id_(0),
+      bitrate_(0),
+      framerate_(0),
+      cpb_size_(0),
+      encoding_parameters_changed_(false),
+      encoder_thread_("VAVEAEncoderThread"),
+      child_task_runner_(base::ThreadTaskRunnerHandle::Get()),
+      weak_this_ptr_factory_(this) {
+  VLOGF(2);
+  weak_this_ = weak_this_ptr_factory_.GetWeakPtr();
+  max_ref_idx_l0_size_ = kMaxNumReferenceFrames;
+  qp_ = kDefaultQP;
+  idr_period_ = kIDRPeriod;
+  i_period_ = kIPeriod;
+  ip_period_ = kIPPeriod;
+}
+
+VaapiVideoEncodeAccelerator::~VaapiVideoEncodeAccelerator() {
+  VLOGF(2);
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+  DCHECK(!encoder_thread_.IsRunning());
+}
+
+bool VaapiVideoEncodeAccelerator::Initialize(
+    VideoPixelFormat format,
+    const gfx::Size& input_visible_size,
+    VideoCodecProfile output_profile,
+    uint32_t initial_bitrate,
+    Client* client) {
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+  DCHECK(!encoder_thread_.IsRunning());
+  DCHECK_EQ(state_, kUninitialized);
+
+  VLOGF(2) << "Initializing VAVEA, input_format: "
+           << VideoPixelFormatToString(format)
+           << ", input_visible_size: " << input_visible_size.ToString()
+           << ", output_profile: " << GetProfileName(output_profile)
+           << ", initial_bitrate: " << initial_bitrate;
+
+  client_ptr_factory_.reset(new base::WeakPtrFactory<Client>(client));
+  client_ = client_ptr_factory_->GetWeakPtr();
+
+  const SupportedProfiles& profiles = GetSupportedProfiles();
+  auto profile = find_if(profiles.begin(), profiles.end(),
+                         [output_profile](const SupportedProfile& profile) {
+                           return profile.profile == output_profile;
+                         });
+  if (profile == profiles.end()) {
+    VLOGF(1) << "Unsupported output profile " << GetProfileName(output_profile);
+    return false;
+  }
+  if (input_visible_size.width() > profile->max_resolution.width() ||
+      input_visible_size.height() > profile->max_resolution.height()) {
+    VLOGF(1) << "Input size too big: " << input_visible_size.ToString()
+             << ", max supported size: " << profile->max_resolution.ToString();
+    return false;
+  }
+
+  if (format != PIXEL_FORMAT_I420) {
+    VLOGF(1) << "Unsupported input format: "
+             << VideoPixelFormatToString(format);
+    return false;
+  }
+
+  profile_ = output_profile;
+  visible_size_ = input_visible_size;
+  // 4:2:0 format has to be 2-aligned.
+  DCHECK_EQ(visible_size_.width() % 2, 0);
+  DCHECK_EQ(visible_size_.height() % 2, 0);
+  coded_size_ = gfx::Size(RoundUpToPowerOf2(visible_size_.width(), 16),
+                          RoundUpToPowerOf2(visible_size_.height(), 16));
+  mb_width_ = coded_size_.width() / 16;
+  mb_height_ = coded_size_.height() / 16;
+  output_buffer_byte_size_ = coded_size_.GetArea() + kExtraOutputBufferSize;
+
+  UpdateRates(initial_bitrate, kDefaultFramerate);
+
+  vaapi_wrapper_ =
+      VaapiWrapper::CreateForVideoCodec(VaapiWrapper::kEncode, output_profile,
+                                        base::Bind(&ReportToUMA, VAAPI_ERROR));
+  if (!vaapi_wrapper_.get()) {
+    VLOGF(1) << "Failed initializing VAAPI for profile "
+             << GetProfileName(output_profile);
+    return false;
+  }
+
+  if (!encoder_thread_.Start()) {
+    VLOGF(1) << "Failed to start encoder thread";
+    return false;
+  }
+  encoder_thread_task_runner_ = encoder_thread_.task_runner();
+
+  // Finish the remaining initialization on the encoder thread.
+  encoder_thread_task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::InitializeTask,
+                            base::Unretained(this)));
+
+  return true;
+}
+
+void VaapiVideoEncodeAccelerator::InitializeTask() {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK_EQ(state_, kUninitialized);
+  VLOGF(2);
+
+  va_surface_release_cb_ = BindToCurrentLoop(
+      base::Bind(&VaapiVideoEncodeAccelerator::RecycleVASurfaceID,
+                 base::Unretained(this)));
+
+  if (!vaapi_wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, coded_size_,
+                                      kNumSurfaces,
+                                      &available_va_surface_ids_)) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed creating VASurfaces");
+    return;
+  }
+
+  UpdateSPS();
+  GeneratePackedSPS();
+
+  UpdatePPS();
+  GeneratePackedPPS();
+
+  child_task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(&Client::RequireBitstreamBuffers, client_, kNumInputBuffers,
+                 coded_size_, output_buffer_byte_size_));
+
+  SetState(kEncoding);
+}
+
+void VaapiVideoEncodeAccelerator::RecycleVASurfaceID(
+    VASurfaceID va_surface_id) {
+  DVLOGF(4) << "va_surface_id: " << va_surface_id;
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+
+  available_va_surface_ids_.push_back(va_surface_id);
+  EncodeFrameTask();
+}
+
+void VaapiVideoEncodeAccelerator::BeginFrame(bool force_keyframe) {
+  current_pic_ = new H264Picture();
+
+  // If the current picture is an IDR picture, frame_num shall be equal to 0.
+  if (force_keyframe)
+    frame_num_ = 0;
+
+  current_pic_->frame_num = frame_num_++;
+  frame_num_ %= idr_period_;
+
+  if (current_pic_->frame_num == 0) {
+    current_pic_->idr = true;
+    // H264 spec mandates idr_pic_id to differ between two consecutive IDRs.
+    idr_pic_id_ ^= 1;
+    ref_pic_list0_.clear();
+  }
+
+  if (current_pic_->frame_num % i_period_ == 0)
+    current_pic_->type = H264SliceHeader::kISlice;
+  else
+    current_pic_->type = H264SliceHeader::kPSlice;
+
+  if (current_pic_->type != H264SliceHeader::kBSlice)
+    current_pic_->ref = true;
+
+  current_pic_->pic_order_cnt = current_pic_->frame_num * 2;
+  current_pic_->top_field_order_cnt = current_pic_->pic_order_cnt;
+  current_pic_->pic_order_cnt_lsb = current_pic_->pic_order_cnt;
+
+  current_encode_job_->keyframe = current_pic_->idr;
+
+  DVLOGF(4) << "Starting a new frame, type: " << current_pic_->type
+            << (force_keyframe ? " (forced keyframe)" : "")
+            << " frame_num: " << current_pic_->frame_num
+            << " POC: " << current_pic_->pic_order_cnt;
+}
+
+void VaapiVideoEncodeAccelerator::EndFrame() {
+  DCHECK(current_pic_);
+  // Store the picture on the list of reference pictures and keep the list
+  // below maximum size, dropping oldest references.
+  if (current_pic_->ref)
+    ref_pic_list0_.push_front(current_encode_job_->recon_surface);
+  size_t max_num_ref_frames =
+      base::checked_cast<size_t>(current_sps_.max_num_ref_frames);
+  while (ref_pic_list0_.size() > max_num_ref_frames)
+    ref_pic_list0_.pop_back();
+
+  submitted_encode_jobs_.push(make_linked_ptr(current_encode_job_.release()));
+}
+
+static void InitVAPicture(VAPictureH264* va_pic) {
+  memset(va_pic, 0, sizeof(*va_pic));
+  va_pic->picture_id = VA_INVALID_ID;
+  va_pic->flags = VA_PICTURE_H264_INVALID;
+}
+
+bool VaapiVideoEncodeAccelerator::SubmitFrameParameters() {
+  DCHECK(current_pic_);
+  VAEncSequenceParameterBufferH264 seq_param;
+  memset(&seq_param, 0, sizeof(seq_param));
+
+#define SPS_TO_SP(a) seq_param.a = current_sps_.a;
+  SPS_TO_SP(seq_parameter_set_id);
+  SPS_TO_SP(level_idc);
+
+  seq_param.intra_period = i_period_;
+  seq_param.intra_idr_period = idr_period_;
+  seq_param.ip_period = ip_period_;
+  seq_param.bits_per_second = bitrate_;
+
+  SPS_TO_SP(max_num_ref_frames);
+  seq_param.picture_width_in_mbs = mb_width_;
+  seq_param.picture_height_in_mbs = mb_height_;
+
+#define SPS_TO_SP_FS(a) seq_param.seq_fields.bits.a = current_sps_.a;
+  SPS_TO_SP_FS(chroma_format_idc);
+  SPS_TO_SP_FS(frame_mbs_only_flag);
+  SPS_TO_SP_FS(log2_max_frame_num_minus4);
+  SPS_TO_SP_FS(pic_order_cnt_type);
+  SPS_TO_SP_FS(log2_max_pic_order_cnt_lsb_minus4);
+#undef SPS_TO_SP_FS
+
+  SPS_TO_SP(bit_depth_luma_minus8);
+  SPS_TO_SP(bit_depth_chroma_minus8);
+
+  SPS_TO_SP(frame_cropping_flag);
+  if (current_sps_.frame_cropping_flag) {
+    SPS_TO_SP(frame_crop_left_offset);
+    SPS_TO_SP(frame_crop_right_offset);
+    SPS_TO_SP(frame_crop_top_offset);
+    SPS_TO_SP(frame_crop_bottom_offset);
+  }
+
+  SPS_TO_SP(vui_parameters_present_flag);
+#define SPS_TO_SP_VF(a) seq_param.vui_fields.bits.a = current_sps_.a;
+  SPS_TO_SP_VF(timing_info_present_flag);
+#undef SPS_TO_SP_VF
+  SPS_TO_SP(num_units_in_tick);
+  SPS_TO_SP(time_scale);
+#undef SPS_TO_SP
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncSequenceParameterBufferType,
+                                    sizeof(seq_param), &seq_param))
+    return false;
+
+  VAEncPictureParameterBufferH264 pic_param;
+  memset(&pic_param, 0, sizeof(pic_param));
+
+  pic_param.CurrPic.picture_id = current_encode_job_->recon_surface->id();
+  pic_param.CurrPic.TopFieldOrderCnt = current_pic_->top_field_order_cnt;
+  pic_param.CurrPic.BottomFieldOrderCnt = current_pic_->bottom_field_order_cnt;
+  pic_param.CurrPic.flags = 0;
+
+  for (size_t i = 0; i < arraysize(pic_param.ReferenceFrames); ++i)
+    InitVAPicture(&pic_param.ReferenceFrames[i]);
+
+  DCHECK_LE(ref_pic_list0_.size(), arraysize(pic_param.ReferenceFrames));
+  RefPicList::const_iterator iter = ref_pic_list0_.begin();
+  for (size_t i = 0;
+       i < arraysize(pic_param.ReferenceFrames) && iter != ref_pic_list0_.end();
+       ++iter, ++i) {
+    pic_param.ReferenceFrames[i].picture_id = (*iter)->id();
+    pic_param.ReferenceFrames[i].flags = 0;
+  }
+
+  pic_param.coded_buf = current_encode_job_->coded_buffer;
+  pic_param.pic_parameter_set_id = current_pps_.pic_parameter_set_id;
+  pic_param.seq_parameter_set_id = current_pps_.seq_parameter_set_id;
+  pic_param.frame_num = current_pic_->frame_num;
+  pic_param.pic_init_qp = qp_;
+  pic_param.num_ref_idx_l0_active_minus1 = max_ref_idx_l0_size_ - 1;
+  pic_param.pic_fields.bits.idr_pic_flag = current_pic_->idr;
+  pic_param.pic_fields.bits.reference_pic_flag = current_pic_->ref;
+#define PPS_TO_PP_PF(a) pic_param.pic_fields.bits.a = current_pps_.a;
+  PPS_TO_PP_PF(entropy_coding_mode_flag);
+  PPS_TO_PP_PF(transform_8x8_mode_flag);
+  PPS_TO_PP_PF(deblocking_filter_control_present_flag);
+#undef PPS_TO_PP_PF
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPictureParameterBufferType,
+                                    sizeof(pic_param), &pic_param))
+    return false;
+
+  VAEncSliceParameterBufferH264 slice_param;
+  memset(&slice_param, 0, sizeof(slice_param));
+
+  slice_param.num_macroblocks = mb_width_ * mb_height_;
+  slice_param.macroblock_info = VA_INVALID_ID;
+  slice_param.slice_type = current_pic_->type;
+  slice_param.pic_parameter_set_id = current_pps_.pic_parameter_set_id;
+  slice_param.idr_pic_id = idr_pic_id_;
+  slice_param.pic_order_cnt_lsb = current_pic_->pic_order_cnt_lsb;
+  slice_param.num_ref_idx_active_override_flag = true;
+
+  for (size_t i = 0; i < arraysize(slice_param.RefPicList0); ++i)
+    InitVAPicture(&slice_param.RefPicList0[i]);
+
+  for (size_t i = 0; i < arraysize(slice_param.RefPicList1); ++i)
+    InitVAPicture(&slice_param.RefPicList1[i]);
+
+  DCHECK_LE(ref_pic_list0_.size(), arraysize(slice_param.RefPicList0));
+  iter = ref_pic_list0_.begin();
+  for (size_t i = 0;
+       i < arraysize(slice_param.RefPicList0) && iter != ref_pic_list0_.end();
+       ++iter, ++i) {
+    InitVAPicture(&slice_param.RefPicList0[i]);
+    slice_param.RefPicList0[i].picture_id = (*iter)->id();
+    slice_param.RefPicList0[i].flags = 0;
+  }
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncSliceParameterBufferType,
+                                    sizeof(slice_param), &slice_param))
+    return false;
+
+  VAEncMiscParameterRateControl rate_control_param;
+  memset(&rate_control_param, 0, sizeof(rate_control_param));
+  rate_control_param.bits_per_second = bitrate_;
+  rate_control_param.target_percentage = 90;
+  rate_control_param.window_size = kCPBWindowSizeMs;
+  rate_control_param.initial_qp = qp_;
+  rate_control_param.rc_flags.bits.disable_frame_skip = true;
+
+  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
+          VAEncMiscParameterTypeRateControl, sizeof(rate_control_param),
+          &rate_control_param))
+    return false;
+
+  VAEncMiscParameterFrameRate framerate_param;
+  memset(&framerate_param, 0, sizeof(framerate_param));
+  framerate_param.framerate = framerate_;
+  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
+          VAEncMiscParameterTypeFrameRate, sizeof(framerate_param),
+          &framerate_param))
+    return false;
+
+  VAEncMiscParameterHRD hrd_param;
+  memset(&hrd_param, 0, sizeof(hrd_param));
+  hrd_param.buffer_size = cpb_size_;
+  hrd_param.initial_buffer_fullness = cpb_size_ / 2;
+  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
+          VAEncMiscParameterTypeHRD, sizeof(hrd_param), &hrd_param))
+    return false;
+
+  return true;
+}
+
+bool VaapiVideoEncodeAccelerator::SubmitHeadersIfNeeded() {
+  DCHECK(current_pic_);
+  if (current_pic_->type != H264SliceHeader::kISlice)
+    return true;
+
+  // Submit SPS.
+  VAEncPackedHeaderParameterBuffer par_buffer;
+  memset(&par_buffer, 0, sizeof(par_buffer));
+  par_buffer.type = VAEncPackedHeaderSequence;
+  par_buffer.bit_length = packed_sps_.BytesInBuffer() * 8;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
+                                    sizeof(par_buffer), &par_buffer))
+    return false;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
+                                    packed_sps_.BytesInBuffer(),
+                                    packed_sps_.data()))
+    return false;
+
+  // Submit PPS.
+  memset(&par_buffer, 0, sizeof(par_buffer));
+  par_buffer.type = VAEncPackedHeaderPicture;
+  par_buffer.bit_length = packed_pps_.BytesInBuffer() * 8;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
+                                    sizeof(par_buffer), &par_buffer))
+    return false;
+
+  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
+                                    packed_pps_.BytesInBuffer(),
+                                    packed_pps_.data()))
+    return false;
+
+  return true;
+}
+
+bool VaapiVideoEncodeAccelerator::ExecuteEncode() {
+  DCHECK(current_pic_);
+  DVLOGF(4) << "Encoding frame_num: " << current_pic_->frame_num;
+  return vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(
+      current_encode_job_->input_surface->id());
+}
+
+bool VaapiVideoEncodeAccelerator::UploadFrame(
+    const scoped_refptr<VideoFrame>& frame) {
+  return vaapi_wrapper_->UploadVideoFrameToSurface(
+      frame, current_encode_job_->input_surface->id());
+}
+
+void VaapiVideoEncodeAccelerator::TryToReturnBitstreamBuffer() {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+
+  if (state_ != kEncoding)
+    return;
+
+  while (!submitted_encode_jobs_.empty()) {
+    linked_ptr<EncodeJob> encode_job = submitted_encode_jobs_.front();
+    // An null job indicates a flush command.
+    if (encode_job == nullptr) {
+      submitted_encode_jobs_.pop();
+      DVLOGF(2) << "FlushDone";
+      DCHECK(flush_callback_);
+      child_task_runner_->PostTask(
+          FROM_HERE, base::BindOnce(std::move(flush_callback_), true));
+      continue;
+    }
+
+    if (available_bitstream_buffers_.empty())
+      break;
+    auto buffer = available_bitstream_buffers_.front();
+
+    available_bitstream_buffers_.pop();
+    submitted_encode_jobs_.pop();
+
+    uint8_t* target_data = reinterpret_cast<uint8_t*>(buffer->shm->memory());
+
+    size_t data_size = 0;
+    if (!vaapi_wrapper_->DownloadAndDestroyCodedBuffer(
+            encode_job->coded_buffer, encode_job->input_surface->id(),
+            target_data, buffer->shm->size(), &data_size)) {
+      NOTIFY_ERROR(kPlatformFailureError, "Failed downloading coded buffer");
+      return;
+    }
+
+    DVLOGF(4) << "Returning bitstream buffer "
+              << (encode_job->keyframe ? "(keyframe)" : "")
+              << " id: " << buffer->id << " size: " << data_size;
+
+    child_task_runner_->PostTask(
+        FROM_HERE,
+        base::Bind(&Client::BitstreamBufferReady, client_, buffer->id,
+                   data_size, encode_job->keyframe, encode_job->timestamp));
+    break;
+  }
+}
+
+void VaapiVideoEncodeAccelerator::Encode(const scoped_refptr<VideoFrame>& frame,
+                                         bool force_keyframe) {
+  DVLOGF(4) << "Frame timestamp: " << frame->timestamp().InMilliseconds()
+            << " force_keyframe: " << force_keyframe;
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+
+  encoder_thread_task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::EncodeTask,
+                            base::Unretained(this), frame, force_keyframe));
+}
+
+bool VaapiVideoEncodeAccelerator::PrepareNextJob(base::TimeDelta timestamp) {
+  if (available_va_surface_ids_.size() < kMinSurfacesToEncode)
+    return false;
+
+  DCHECK(!current_encode_job_);
+  current_encode_job_.reset(new EncodeJob());
+
+  if (!vaapi_wrapper_->CreateCodedBuffer(output_buffer_byte_size_,
+                                         &current_encode_job_->coded_buffer)) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed creating coded buffer");
+    return false;
+  }
+
+  current_encode_job_->timestamp = timestamp;
+
+  current_encode_job_->input_surface = new VASurface(
+      available_va_surface_ids_.back(), coded_size_,
+      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_);
+  available_va_surface_ids_.pop_back();
+
+  current_encode_job_->recon_surface = new VASurface(
+      available_va_surface_ids_.back(), coded_size_,
+      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_);
+  available_va_surface_ids_.pop_back();
+
+  // Reference surfaces are needed until the job is done, but they get
+  // removed from ref_pic_list0_ when it's full at the end of job submission.
+  // Keep refs to them along with the job and only release after sync.
+  current_encode_job_->reference_surfaces = ref_pic_list0_;
+
+  return true;
+}
+
+void VaapiVideoEncodeAccelerator::EncodeTask(
+    const scoped_refptr<VideoFrame>& frame,
+    bool force_keyframe) {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK_NE(state_, kUninitialized);
+
+  encoder_input_queue_.push(
+      make_linked_ptr(new InputFrameRef(frame, force_keyframe)));
+  EncodeFrameTask();
+}
+
+void VaapiVideoEncodeAccelerator::EncodeFrameTask() {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+
+  if (state_ != kEncoding || encoder_input_queue_.empty())
+    return;
+
+  if (!PrepareNextJob(encoder_input_queue_.front()->frame->timestamp())) {
+    DVLOGF(4) << "Not ready for next frame yet";
+    return;
+  }
+
+  linked_ptr<InputFrameRef> frame_ref = encoder_input_queue_.front();
+  encoder_input_queue_.pop();
+
+  if (!UploadFrame(frame_ref->frame)) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed uploading source frame to HW.");
+    return;
+  }
+
+  BeginFrame(frame_ref->force_keyframe || encoding_parameters_changed_);
+  encoding_parameters_changed_ = false;
+
+  if (!SubmitFrameParameters()) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting frame parameters.");
+    return;
+  }
+
+  if (!SubmitHeadersIfNeeded()) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting frame headers.");
+    return;
+  }
+
+  if (!ExecuteEncode()) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting encode job to HW.");
+    return;
+  }
+
+  EndFrame();
+  TryToReturnBitstreamBuffer();
+}
+
+void VaapiVideoEncodeAccelerator::UseOutputBitstreamBuffer(
+    const BitstreamBuffer& buffer) {
+  DVLOGF(4) << "id: " << buffer.id();
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+
+  if (buffer.size() < output_buffer_byte_size_) {
+    NOTIFY_ERROR(kInvalidArgumentError, "Provided bitstream buffer too small");
+    return;
+  }
+
+  std::unique_ptr<SharedMemoryRegion> shm(
+      new SharedMemoryRegion(buffer, false));
+  if (!shm->Map()) {
+    NOTIFY_ERROR(kPlatformFailureError, "Failed mapping shared memory.");
+    return;
+  }
+
+  std::unique_ptr<BitstreamBufferRef> buffer_ref(
+      new BitstreamBufferRef(buffer.id(), std::move(shm)));
+
+  encoder_thread_task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(&VaapiVideoEncodeAccelerator::UseOutputBitstreamBufferTask,
+                 base::Unretained(this), base::Passed(&buffer_ref)));
+}
+
+void VaapiVideoEncodeAccelerator::UseOutputBitstreamBufferTask(
+    std::unique_ptr<BitstreamBufferRef> buffer_ref) {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK_NE(state_, kUninitialized);
+
+  available_bitstream_buffers_.push(make_linked_ptr(buffer_ref.release()));
+  TryToReturnBitstreamBuffer();
+}
+
+void VaapiVideoEncodeAccelerator::RequestEncodingParametersChange(
+    uint32_t bitrate,
+    uint32_t framerate) {
+  VLOGF(2) << "bitrate: " << bitrate << " framerate: " << framerate;
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+
+  encoder_thread_task_runner_->PostTask(
+      FROM_HERE,
+      base::Bind(
+          &VaapiVideoEncodeAccelerator::RequestEncodingParametersChangeTask,
+          base::Unretained(this), bitrate, framerate));
+}
+
+void VaapiVideoEncodeAccelerator::UpdateRates(uint32_t bitrate,
+                                              uint32_t framerate) {
+  if (encoder_thread_.IsRunning())
+    DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK_NE(bitrate, 0u);
+  DCHECK_NE(framerate, 0u);
+  bitrate_ = bitrate;
+  framerate_ = framerate;
+  cpb_size_ = bitrate_ * kCPBWindowSizeMs / 1000;
+}
+
+void VaapiVideoEncodeAccelerator::RequestEncodingParametersChangeTask(
+    uint32_t bitrate,
+    uint32_t framerate) {
+  VLOGF(2) << "bitrate: " << bitrate << " framerate: " << framerate;
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK_NE(state_, kUninitialized);
+
+  // This is a workaround to zero being temporarily, as part of the initial
+  // setup, provided by the webrtc video encode and a zero bitrate and
+  // framerate not being accepted by VAAPI
+  // TODO: This code is common with v4l2_video_encode_accelerator.cc, perhaps
+  // it could be pulled up to RTCVideoEncoder
+  if (bitrate < 1)
+    bitrate = 1;
+  if (framerate < 1)
+    framerate = 1;
+
+  if (bitrate_ == bitrate && framerate_ == framerate)
+    return;
+
+  UpdateRates(bitrate, framerate);
+
+  UpdateSPS();
+  GeneratePackedSPS();
+
+  // Submit new parameters along with next frame that will be processed.
+  encoding_parameters_changed_ = true;
+}
+
+void VaapiVideoEncodeAccelerator::Flush(FlushCallback flush_callback) {
+  DVLOGF(2);
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+  if (flush_callback_) {
+    NOTIFY_ERROR(kIllegalStateError, "There is a pending flush");
+    std::move(flush_callback).Run(false);
+    return;
+  }
+  flush_callback_ = std::move(flush_callback);
+  encoder_thread_task_runner_->PostTask(
+      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::FlushTask,
+                            base::Unretained(this)));
+}
+
+void VaapiVideoEncodeAccelerator::FlushTask() {
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+
+  // Insert an null job to indicate a flush command.
+  submitted_encode_jobs_.push(linked_ptr<EncodeJob>(nullptr));
+  TryToReturnBitstreamBuffer();
+}
+
+void VaapiVideoEncodeAccelerator::Destroy() {
+  DCHECK(child_task_runner_->BelongsToCurrentThread());
+
+  // Can't call client anymore after Destroy() returns.
+  client_ptr_factory_.reset();
+  weak_this_ptr_factory_.InvalidateWeakPtrs();
+
+  // Early-exit encoder tasks if they are running and join the thread.
+  if (encoder_thread_.IsRunning()) {
+    encoder_thread_.task_runner()->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::DestroyTask,
+                              base::Unretained(this)));
+    encoder_thread_.Stop();
+  }
+
+  if (flush_callback_)
+    std::move(flush_callback_).Run(false);
+
+  delete this;
+}
+
+void VaapiVideoEncodeAccelerator::DestroyTask() {
+  VLOGF(2);
+  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
+  SetState(kError);
+}
+
+void VaapiVideoEncodeAccelerator::UpdateSPS() {
+  memset(&current_sps_, 0, sizeof(H264SPS));
+
+  // Spec A.2 and A.3.
+  switch (profile_) {
+    case H264PROFILE_BASELINE:
+      // Due to crbug.com/345569, we don't distinguish between constrained
+      // and non-constrained baseline profiles. Since many codecs can't do
+      // non-constrained, and constrained is usually what we mean (and it's a
+      // subset of non-constrained), default to it.
+      current_sps_.profile_idc = H264SPS::kProfileIDCBaseline;
+      current_sps_.constraint_set0_flag = true;
+      break;
+    case H264PROFILE_MAIN:
+      current_sps_.profile_idc = H264SPS::kProfileIDCMain;
+      current_sps_.constraint_set1_flag = true;
+      break;
+    case H264PROFILE_HIGH:
+      current_sps_.profile_idc = H264SPS::kProfileIDCHigh;
+      break;
+    default:
+      NOTIMPLEMENTED();
+      return;
+  }
+
+  current_sps_.level_idc = kDefaultLevelIDC;
+  current_sps_.seq_parameter_set_id = 0;
+  current_sps_.chroma_format_idc = kChromaFormatIDC;
+
+  DCHECK_GE(idr_period_, 1u << 4);
+  current_sps_.log2_max_frame_num_minus4 = Log2OfPowerOf2(idr_period_) - 4;
+  current_sps_.pic_order_cnt_type = 0;
+  current_sps_.log2_max_pic_order_cnt_lsb_minus4 =
+      Log2OfPowerOf2(idr_period_ * 2) - 4;
+  current_sps_.max_num_ref_frames = max_ref_idx_l0_size_;
+
+  current_sps_.frame_mbs_only_flag = true;
+
+  DCHECK_GT(mb_width_, 0u);
+  DCHECK_GT(mb_height_, 0u);
+  current_sps_.pic_width_in_mbs_minus1 = mb_width_ - 1;
+  DCHECK(current_sps_.frame_mbs_only_flag);
+  current_sps_.pic_height_in_map_units_minus1 = mb_height_ - 1;
+
+  if (visible_size_ != coded_size_) {
+    // Visible size differs from coded size, fill crop information.
+    current_sps_.frame_cropping_flag = true;
+    DCHECK(!current_sps_.separate_colour_plane_flag);
+    // Spec table 6-1. Only 4:2:0 for now.
+    DCHECK_EQ(current_sps_.chroma_format_idc, 1);
+    // Spec 7.4.2.1.1. Crop is in crop units, which is 2 pixels for 4:2:0.
+    const unsigned int crop_unit_x = 2;
+    const unsigned int crop_unit_y = 2 * (2 - current_sps_.frame_mbs_only_flag);
+    current_sps_.frame_crop_left_offset = 0;
+    current_sps_.frame_crop_right_offset =
+        (coded_size_.width() - visible_size_.width()) / crop_unit_x;
+    current_sps_.frame_crop_top_offset = 0;
+    current_sps_.frame_crop_bottom_offset =
+        (coded_size_.height() - visible_size_.height()) / crop_unit_y;
+  }
+
+  current_sps_.vui_parameters_present_flag = true;
+  current_sps_.timing_info_present_flag = true;
+  current_sps_.num_units_in_tick = 1;
+  current_sps_.time_scale = framerate_ * 2;  // See equation D-2 in spec.
+  current_sps_.fixed_frame_rate_flag = true;
+
+  current_sps_.nal_hrd_parameters_present_flag = true;
+  // H.264 spec ch. E.2.2.
+  current_sps_.cpb_cnt_minus1 = 0;
+  current_sps_.bit_rate_scale = kBitRateScale;
+  current_sps_.cpb_size_scale = kCPBSizeScale;
+  current_sps_.bit_rate_value_minus1[0] =
+      (bitrate_ >> (kBitRateScale + H264SPS::kBitRateScaleConstantTerm)) - 1;
+  current_sps_.cpb_size_value_minus1[0] =
+      (cpb_size_ >> (kCPBSizeScale + H264SPS::kCPBSizeScaleConstantTerm)) - 1;
+  current_sps_.cbr_flag[0] = true;
+  current_sps_.initial_cpb_removal_delay_length_minus_1 =
+      H264SPS::kDefaultInitialCPBRemovalDelayLength - 1;
+  current_sps_.cpb_removal_delay_length_minus1 =
+      H264SPS::kDefaultInitialCPBRemovalDelayLength - 1;
+  current_sps_.dpb_output_delay_length_minus1 =
+      H264SPS::kDefaultDPBOutputDelayLength - 1;
+  current_sps_.time_offset_length = H264SPS::kDefaultTimeOffsetLength;
+  current_sps_.low_delay_hrd_flag = false;
+}
+
+void VaapiVideoEncodeAccelerator::GeneratePackedSPS() {
+  packed_sps_.Reset();
+
+  packed_sps_.BeginNALU(H264NALU::kSPS, 3);
+
+  packed_sps_.AppendBits(8, current_sps_.profile_idc);
+  packed_sps_.AppendBool(current_sps_.constraint_set0_flag);
+  packed_sps_.AppendBool(current_sps_.constraint_set1_flag);
+  packed_sps_.AppendBool(current_sps_.constraint_set2_flag);
+  packed_sps_.AppendBool(current_sps_.constraint_set3_flag);
+  packed_sps_.AppendBool(current_sps_.constraint_set4_flag);
+  packed_sps_.AppendBool(current_sps_.constraint_set5_flag);
+  packed_sps_.AppendBits(2, 0);  // reserved_zero_2bits
+  packed_sps_.AppendBits(8, current_sps_.level_idc);
+  packed_sps_.AppendUE(current_sps_.seq_parameter_set_id);
+
+  if (current_sps_.profile_idc == H264SPS::kProfileIDCHigh) {
+    packed_sps_.AppendUE(current_sps_.chroma_format_idc);
+    if (current_sps_.chroma_format_idc == 3)
+      packed_sps_.AppendBool(current_sps_.separate_colour_plane_flag);
+    packed_sps_.AppendUE(current_sps_.bit_depth_luma_minus8);
+    packed_sps_.AppendUE(current_sps_.bit_depth_chroma_minus8);
+    packed_sps_.AppendBool(current_sps_.qpprime_y_zero_transform_bypass_flag);
+    packed_sps_.AppendBool(current_sps_.seq_scaling_matrix_present_flag);
+    CHECK(!current_sps_.seq_scaling_matrix_present_flag);
+  }
+
+  packed_sps_.AppendUE(current_sps_.log2_max_frame_num_minus4);
+  packed_sps_.AppendUE(current_sps_.pic_order_cnt_type);
+  if (current_sps_.pic_order_cnt_type == 0)
+    packed_sps_.AppendUE(current_sps_.log2_max_pic_order_cnt_lsb_minus4);
+  else if (current_sps_.pic_order_cnt_type == 1) {
+    CHECK(1);
+  }
+
+  packed_sps_.AppendUE(current_sps_.max_num_ref_frames);
+  packed_sps_.AppendBool(current_sps_.gaps_in_frame_num_value_allowed_flag);
+  packed_sps_.AppendUE(current_sps_.pic_width_in_mbs_minus1);
+  packed_sps_.AppendUE(current_sps_.pic_height_in_map_units_minus1);
+
+  packed_sps_.AppendBool(current_sps_.frame_mbs_only_flag);
+  if (!current_sps_.frame_mbs_only_flag)
+    packed_sps_.AppendBool(current_sps_.mb_adaptive_frame_field_flag);
+
+  packed_sps_.AppendBool(current_sps_.direct_8x8_inference_flag);
+
+  packed_sps_.AppendBool(current_sps_.frame_cropping_flag);
+  if (current_sps_.frame_cropping_flag) {
+    packed_sps_.AppendUE(current_sps_.frame_crop_left_offset);
+    packed_sps_.AppendUE(current_sps_.frame_crop_right_offset);
+    packed_sps_.AppendUE(current_sps_.frame_crop_top_offset);
+    packed_sps_.AppendUE(current_sps_.frame_crop_bottom_offset);
+  }
+
+  packed_sps_.AppendBool(current_sps_.vui_parameters_present_flag);
+  if (current_sps_.vui_parameters_present_flag) {
+    packed_sps_.AppendBool(false);  // aspect_ratio_info_present_flag
+    packed_sps_.AppendBool(false);  // overscan_info_present_flag
+    packed_sps_.AppendBool(false);  // video_signal_type_present_flag
+    packed_sps_.AppendBool(false);  // chroma_loc_info_present_flag
+
+    packed_sps_.AppendBool(current_sps_.timing_info_present_flag);
+    if (current_sps_.timing_info_present_flag) {
+      packed_sps_.AppendBits(32, current_sps_.num_units_in_tick);
+      packed_sps_.AppendBits(32, current_sps_.time_scale);
+      packed_sps_.AppendBool(current_sps_.fixed_frame_rate_flag);
+    }
+
+    packed_sps_.AppendBool(current_sps_.nal_hrd_parameters_present_flag);
+    if (current_sps_.nal_hrd_parameters_present_flag) {
+      packed_sps_.AppendUE(current_sps_.cpb_cnt_minus1);
+      packed_sps_.AppendBits(4, current_sps_.bit_rate_scale);
+      packed_sps_.AppendBits(4, current_sps_.cpb_size_scale);
+      CHECK_LT(base::checked_cast<size_t>(current_sps_.cpb_cnt_minus1),
+               arraysize(current_sps_.bit_rate_value_minus1));
+      for (int i = 0; i <= current_sps_.cpb_cnt_minus1; ++i) {
+        packed_sps_.AppendUE(current_sps_.bit_rate_value_minus1[i]);
+        packed_sps_.AppendUE(current_sps_.cpb_size_value_minus1[i]);
+        packed_sps_.AppendBool(current_sps_.cbr_flag[i]);
+      }
+      packed_sps_.AppendBits(
+          5, current_sps_.initial_cpb_removal_delay_length_minus_1);
+      packed_sps_.AppendBits(5, current_sps_.cpb_removal_delay_length_minus1);
+      packed_sps_.AppendBits(5, current_sps_.dpb_output_delay_length_minus1);
+      packed_sps_.AppendBits(5, current_sps_.time_offset_length);
+    }
+
+    packed_sps_.AppendBool(false);  // vcl_hrd_parameters_flag
+    if (current_sps_.nal_hrd_parameters_present_flag)
+      packed_sps_.AppendBool(current_sps_.low_delay_hrd_flag);
+
+    packed_sps_.AppendBool(false);  // pic_struct_present_flag
+    packed_sps_.AppendBool(true);   // bitstream_restriction_flag
+
+    packed_sps_.AppendBool(false);  // motion_vectors_over_pic_boundaries_flag
+    packed_sps_.AppendUE(2);        // max_bytes_per_pic_denom
+    packed_sps_.AppendUE(1);        // max_bits_per_mb_denom
+    packed_sps_.AppendUE(16);       // log2_max_mv_length_horizontal
+    packed_sps_.AppendUE(16);       // log2_max_mv_length_vertical
+
+    // Explicitly set max_num_reorder_frames to 0 to allow the decoder to
+    // output pictures early.
+    packed_sps_.AppendUE(0);  // max_num_reorder_frames
+
+    // The value of max_dec_frame_buffering shall be greater than or equal to
+    // max_num_ref_frames.
+    const unsigned int max_dec_frame_buffering =
+        current_sps_.max_num_ref_frames;
+    packed_sps_.AppendUE(max_dec_frame_buffering);
+  }
+
+  packed_sps_.FinishNALU();
+}
+
+void VaapiVideoEncodeAccelerator::UpdatePPS() {
+  memset(&current_pps_, 0, sizeof(H264PPS));
+
+  current_pps_.seq_parameter_set_id = current_sps_.seq_parameter_set_id;
+  current_pps_.pic_parameter_set_id = 0;
+
+  current_pps_.entropy_coding_mode_flag =
+      current_sps_.profile_idc >= H264SPS::kProfileIDCMain;
+
+  CHECK_GT(max_ref_idx_l0_size_, 0u);
+  current_pps_.num_ref_idx_l0_default_active_minus1 = max_ref_idx_l0_size_ - 1;
+  current_pps_.num_ref_idx_l1_default_active_minus1 = 0;
+  DCHECK_LE(qp_, 51u);
+  current_pps_.pic_init_qp_minus26 = qp_ - 26;
+  current_pps_.deblocking_filter_control_present_flag = true;
+  current_pps_.transform_8x8_mode_flag =
+      (current_sps_.profile_idc == H264SPS::kProfileIDCHigh);
+}
+
+void VaapiVideoEncodeAccelerator::GeneratePackedPPS() {
+  packed_pps_.Reset();
+
+  packed_pps_.BeginNALU(H264NALU::kPPS, 3);
+
+  packed_pps_.AppendUE(current_pps_.pic_parameter_set_id);
+  packed_pps_.AppendUE(current_pps_.seq_parameter_set_id);
+  packed_pps_.AppendBool(current_pps_.entropy_coding_mode_flag);
+  packed_pps_.AppendBool(
+      current_pps_.bottom_field_pic_order_in_frame_present_flag);
+  CHECK_EQ(current_pps_.num_slice_groups_minus1, 0);
+  packed_pps_.AppendUE(current_pps_.num_slice_groups_minus1);
+
+  packed_pps_.AppendUE(current_pps_.num_ref_idx_l0_default_active_minus1);
+  packed_pps_.AppendUE(current_pps_.num_ref_idx_l1_default_active_minus1);
+
+  packed_pps_.AppendBool(current_pps_.weighted_pred_flag);
+  packed_pps_.AppendBits(2, current_pps_.weighted_bipred_idc);
+
+  packed_pps_.AppendSE(current_pps_.pic_init_qp_minus26);
+  packed_pps_.AppendSE(current_pps_.pic_init_qs_minus26);
+  packed_pps_.AppendSE(current_pps_.chroma_qp_index_offset);
+
+  packed_pps_.AppendBool(current_pps_.deblocking_filter_control_present_flag);
+  packed_pps_.AppendBool(current_pps_.constrained_intra_pred_flag);
+  packed_pps_.AppendBool(current_pps_.redundant_pic_cnt_present_flag);
+
+  packed_pps_.AppendBool(current_pps_.transform_8x8_mode_flag);
+  packed_pps_.AppendBool(current_pps_.pic_scaling_matrix_present_flag);
+  DCHECK(!current_pps_.pic_scaling_matrix_present_flag);
+  packed_pps_.AppendSE(current_pps_.second_chroma_qp_index_offset);
+
+  packed_pps_.FinishNALU();
+}
+
+void VaapiVideoEncodeAccelerator::SetState(State state) {
+  // Only touch state on encoder thread, unless it's not running.
+  if (encoder_thread_.IsRunning() &&
+      !encoder_thread_task_runner_->BelongsToCurrentThread()) {
+    encoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::SetState,
+                              base::Unretained(this), state));
+    return;
+  }
+
+  VLOGF(2) << "setting state to: " << state;
+  state_ = state;
+}
+
+void VaapiVideoEncodeAccelerator::NotifyError(Error error) {
+  if (!child_task_runner_->BelongsToCurrentThread()) {
+    child_task_runner_->PostTask(
+        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::NotifyError,
+                              weak_this_, error));
+    return;
+  }
+
+  if (client_) {
+    client_->NotifyError(error);
+    client_ptr_factory_.reset();
+  }
+}
+
+VaapiVideoEncodeAccelerator::EncodeJob::EncodeJob()
+    : coded_buffer(VA_INVALID_ID), keyframe(false) {}
+
+VaapiVideoEncodeAccelerator::EncodeJob::~EncodeJob() {}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_encode_accelerator.h
@@ -0,0 +1,275 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
+#define MEDIA_GPU_VAAPI_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <list>
+#include <memory>
+
+#include "base/containers/queue.h"
+#include "base/macros.h"
+#include "base/memory/linked_ptr.h"
+#include "base/threading/thread.h"
+#include "media/filters/h264_bitstream_buffer.h"
+#include "media/gpu/h264_dpb.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/video_encode_accelerator.h"
+
+namespace media {
+
+// A VideoEncodeAccelerator implementation that uses VA-API
+// (http://www.freedesktop.org/wiki/Software/vaapi) for HW-accelerated
+// video encode.
+class MEDIA_GPU_EXPORT VaapiVideoEncodeAccelerator
+    : public VideoEncodeAccelerator {
+ public:
+  VaapiVideoEncodeAccelerator();
+  ~VaapiVideoEncodeAccelerator() override;
+
+  // VideoEncodeAccelerator implementation.
+  VideoEncodeAccelerator::SupportedProfiles GetSupportedProfiles() override;
+  bool Initialize(VideoPixelFormat format,
+                  const gfx::Size& input_visible_size,
+                  VideoCodecProfile output_profile,
+                  uint32_t initial_bitrate,
+                  Client* client) override;
+  void Encode(const scoped_refptr<VideoFrame>& frame,
+              bool force_keyframe) override;
+  void UseOutputBitstreamBuffer(const BitstreamBuffer& buffer) override;
+  void RequestEncodingParametersChange(uint32_t bitrate,
+                                       uint32_t framerate) override;
+  void Destroy() override;
+  void Flush(FlushCallback flush_callback) override;
+
+ private:
+  // Reference picture list.
+  typedef std::list<scoped_refptr<VASurface>> RefPicList;
+
+  // Encode job for one frame. Created when an input frame is awaiting and
+  // enough resources are available to proceed. Once the job is prepared and
+  // submitted to the hardware, it awaits on the submitted_encode_jobs_ queue
+  // for an output bitstream buffer to become available. Once one is ready,
+  // the encoded bytes are downloaded to it and job resources are released
+  // and become available for reuse.
+  struct EncodeJob {
+    // Input surface for video frame data.
+    scoped_refptr<VASurface> input_surface;
+    // Surface for a reconstructed picture, which is used for reference
+    // for subsequent frames.
+    scoped_refptr<VASurface> recon_surface;
+    // Buffer that will contain output bitstream for this frame.
+    VABufferID coded_buffer;
+    // Reference surfaces required to encode this picture. We keep references
+    // to them here, because we may discard some of them from ref_pic_list*
+    // before the HW job is done.
+    RefPicList reference_surfaces;
+    // True if this job will produce a keyframe. Used to report
+    // to BitstreamBufferReady().
+    bool keyframe;
+    // Source timestamp.
+    base::TimeDelta timestamp;
+
+    EncodeJob();
+    ~EncodeJob();
+  };
+
+  // Encoder state.
+  enum State {
+    kUninitialized,
+    kEncoding,
+    kError,
+  };
+
+  // Holds input frames coming from the client ready to be encoded.
+  struct InputFrameRef;
+  // Holds output buffers coming from the client ready to be filled.
+  struct BitstreamBufferRef;
+
+  // Tasks for each of the VEA interface calls to be executed on the
+  // encoder thread.
+  void InitializeTask();
+  void EncodeTask(const scoped_refptr<VideoFrame>& frame, bool force_keyframe);
+  void UseOutputBitstreamBufferTask(
+      std::unique_ptr<BitstreamBufferRef> buffer_ref);
+  void RequestEncodingParametersChangeTask(uint32_t bitrate,
+                                           uint32_t framerate);
+  void DestroyTask();
+  void FlushTask();
+
+  // Prepare and schedule an encode job if we have an input to encode
+  // and enough resources to proceed.
+  void EncodeFrameTask();
+
+  // Fill current_sps_/current_pps_ with current values.
+  void UpdateSPS();
+  void UpdatePPS();
+  void UpdateRates(uint32_t bitrate, uint32_t framerate);
+
+  // Generate packed SPS and PPS in packed_sps_/packed_pps_, using
+  // values in current_sps_/current_pps_.
+  void GeneratePackedSPS();
+  void GeneratePackedPPS();
+
+  // Check if we have sufficient resources for a new encode job, claim them and
+  // fill current_encode_job_ with them.
+  // Return false if we cannot start a new job yet, true otherwise.
+  bool PrepareNextJob(base::TimeDelta timestamp);
+
+  // Begin a new frame, making it a keyframe if |force_keyframe| is true,
+  // updating current_pic_.
+  void BeginFrame(bool force_keyframe);
+
+  // End current frame, updating reference picture lists and storing current
+  // job in the jobs awaiting completion on submitted_encode_jobs_.
+  void EndFrame();
+
+  // Submit parameters for the current frame to the hardware.
+  bool SubmitFrameParameters();
+  // Submit keyframe headers to the hardware if the current frame is a keyframe.
+  bool SubmitHeadersIfNeeded();
+
+  // Upload image data from |frame| to the input surface for current job.
+  bool UploadFrame(const scoped_refptr<VideoFrame>& frame);
+
+  // Execute encode in hardware. This does not block and will return before
+  // the job is finished.
+  bool ExecuteEncode();
+
+  // Callback that returns a no longer used VASurfaceID to
+  // available_va_surface_ids_ for reuse.
+  void RecycleVASurfaceID(VASurfaceID va_surface_id);
+
+  // Tries to return a bitstream buffer if both a submitted job awaits to
+  // be completed and we have bitstream buffers from the client available
+  // to download the encoded data to.
+  void TryToReturnBitstreamBuffer();
+
+  // Puts the encoder into en error state and notifies client about the error.
+  void NotifyError(Error error);
+
+  // Sets the encoder state on the correct thread.
+  void SetState(State state);
+
+  // VaapiWrapper is the owner of all HW resources (surfaces and buffers)
+  // and will free them on destruction.
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  // Input profile and sizes.
+  VideoCodecProfile profile_;
+  gfx::Size visible_size_;
+  gfx::Size coded_size_;  // Macroblock-aligned.
+  // Width/height in macroblocks.
+  unsigned int mb_width_;
+  unsigned int mb_height_;
+
+  // Maximum size of the reference list 0.
+  unsigned int max_ref_idx_l0_size_;
+
+  // Initial QP.
+  unsigned int qp_;
+
+  // IDR frame period.
+  unsigned int idr_period_;
+  // I frame period.
+  unsigned int i_period_;
+  // IP period, i.e. how often do we need to have either an I or a P frame in
+  // the stream. Period of 1 means we can have no B frames.
+  unsigned int ip_period_;
+
+  // Size in bytes required for input bitstream buffers.
+  size_t output_buffer_byte_size_;
+
+  // All of the members below must be accessed on the encoder_thread_,
+  // while it is running.
+
+  // Encoder state. Encode tasks will only run in kEncoding state.
+  State state_;
+
+  // frame_num to be used for the next frame.
+  unsigned int frame_num_;
+  // idr_pic_id to be used for the next frame.
+  unsigned int idr_pic_id_;
+
+  // Current bitrate in bps.
+  unsigned int bitrate_;
+  // Current fps.
+  unsigned int framerate_;
+  // CPB size in bits, i.e. bitrate in kbps * window size in ms/1000.
+  unsigned int cpb_size_;
+  // True if the parameters have changed and we need to submit a keyframe
+  // with updated parameters.
+  bool encoding_parameters_changed_;
+
+  // Job currently being prepared for encode.
+  std::unique_ptr<EncodeJob> current_encode_job_;
+
+  // Current SPS, PPS and their packed versions. Packed versions are their NALUs
+  // in AnnexB format *without* emulation prevention three-byte sequences
+  // (those will be added by the driver).
+  H264SPS current_sps_;
+  H264BitstreamBuffer packed_sps_;
+  H264PPS current_pps_;
+  H264BitstreamBuffer packed_pps_;
+
+  // Picture currently being prepared for encode.
+  scoped_refptr<H264Picture> current_pic_;
+
+  // VA surfaces available for reuse.
+  std::vector<VASurfaceID> available_va_surface_ids_;
+
+  // VA buffers for coded frames.
+  std::vector<VABufferID> available_va_buffer_ids_;
+
+  // Currently active reference surfaces.
+  RefPicList ref_pic_list0_;
+
+  // Callback via which finished VA surfaces are returned to us.
+  VASurface::ReleaseCB va_surface_release_cb_;
+
+  // VideoFrames passed from the client, waiting to be encoded.
+  base::queue<linked_ptr<InputFrameRef>> encoder_input_queue_;
+
+  // BitstreamBuffers mapped, ready to be filled.
+  base::queue<linked_ptr<BitstreamBufferRef>> available_bitstream_buffers_;
+
+  // Jobs submitted for encode, awaiting bitstream buffers to become available.
+  // A pending flush command, indicated by a null job, will be also put in the
+  // queue.
+  base::queue<linked_ptr<EncodeJob>> submitted_encode_jobs_;
+
+  // Encoder thread. All tasks are executed on it.
+  base::Thread encoder_thread_;
+  scoped_refptr<base::SingleThreadTaskRunner> encoder_thread_task_runner_;
+
+  const scoped_refptr<base::SingleThreadTaskRunner> child_task_runner_;
+
+  // To expose client callbacks from VideoEncodeAccelerator.
+  // NOTE: all calls to these objects *MUST* be executed on
+  // child_task_runner_.
+  std::unique_ptr<base::WeakPtrFactory<Client>> client_ptr_factory_;
+  base::WeakPtr<Client> client_;
+
+  // WeakPtr to post from the encoder thread back to the ChildThread, as it may
+  // outlive this. Posting from the ChildThread using base::Unretained(this)
+  // to the encoder thread is safe, because |this| always outlives the encoder
+  // thread (it's a member of this class).
+  base::WeakPtr<VaapiVideoEncodeAccelerator> weak_this_;
+
+  // The completion callback of the Flush() function.
+  FlushCallback flush_callback_;
+
+  base::WeakPtrFactory<VaapiVideoEncodeAccelerator> weak_this_ptr_factory_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiVideoEncodeAccelerator);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_wrapper.cc
@@ -0,0 +1,1372 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+
+#include <dlfcn.h>
+#include <string.h>
+
+#include <va/va.h>
+#include <va/va_drm.h>
+#include <va/va_drmcommon.h>
+#include <va/va_version.h>
+
+#include "base/bind.h"
+#include "base/callback_helpers.h"
+#include "base/environment.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/numerics/safe_conversions.h"
+#include "base/stl_util.h"
+#include "base/sys_info.h"
+#include "build/build_config.h"
+
+// Auto-generated for dlopen libva libraries
+#include "media/gpu/vaapi/va_stubs.h"
+
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "third_party/libyuv/include/libyuv.h"
+#include "ui/gfx/buffer_format_util.h"
+#include "ui/gfx/native_pixmap.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/gl_implementation.h"
+
+#if defined(USE_X11)
+#include <va/va_x11.h>
+#include "ui/gfx/x/x11_types.h"  // nogncheck
+#endif
+
+#if defined(USE_OZONE)
+#include "ui/ozone/public/ozone_platform.h"
+#include "ui/ozone/public/surface_factory_ozone.h"
+#endif
+
+using media_gpu_vaapi::kModuleVa;
+using media_gpu_vaapi::kModuleVa_drm;
+#if defined(USE_X11)
+using media_gpu_vaapi::kModuleVa_x11;
+#endif
+using media_gpu_vaapi::InitializeStubs;
+using media_gpu_vaapi::StubPathMap;
+
+#define LOG_VA_ERROR_AND_REPORT(va_error, err_msg)                  \
+  do {                                                              \
+    LOG(ERROR) << err_msg << " VA error: " << vaErrorStr(va_error); \
+    report_error_to_uma_cb_.Run();                                  \
+  } while (0)
+
+#define VA_LOG_ON_ERROR(va_error, err_msg)        \
+  do {                                            \
+    if ((va_error) != VA_STATUS_SUCCESS)          \
+      LOG_VA_ERROR_AND_REPORT(va_error, err_msg); \
+  } while (0)
+
+#define VA_SUCCESS_OR_RETURN(va_error, err_msg, ret) \
+  do {                                               \
+    if ((va_error) != VA_STATUS_SUCCESS) {           \
+      LOG_VA_ERROR_AND_REPORT(va_error, err_msg);    \
+      return (ret);                                  \
+    }                                                \
+  } while (0)
+
+namespace {
+
+uint32_t BufferFormatToVAFourCC(gfx::BufferFormat fmt) {
+  switch (fmt) {
+    case gfx::BufferFormat::BGRX_8888:
+      return VA_FOURCC_BGRX;
+    case gfx::BufferFormat::BGRA_8888:
+      return VA_FOURCC_BGRA;
+    case gfx::BufferFormat::RGBX_8888:
+      return VA_FOURCC_RGBX;
+    case gfx::BufferFormat::UYVY_422:
+      return VA_FOURCC_UYVY;
+    case gfx::BufferFormat::YVU_420:
+      return VA_FOURCC_YV12;
+    default:
+      NOTREACHED();
+      return 0;
+  }
+}
+
+uint32_t BufferFormatToVARTFormat(gfx::BufferFormat fmt) {
+  switch (fmt) {
+    case gfx::BufferFormat::UYVY_422:
+      return VA_RT_FORMAT_YUV422;
+    case gfx::BufferFormat::BGRX_8888:
+    case gfx::BufferFormat::BGRA_8888:
+    case gfx::BufferFormat::RGBX_8888:
+      return VA_RT_FORMAT_RGB32;
+    case gfx::BufferFormat::YVU_420:
+      return VA_RT_FORMAT_YUV420;
+    default:
+      NOTREACHED();
+      return 0;
+  }
+}
+
+}  // namespace
+
+namespace media {
+
+namespace {
+
+// Maximum framerate of encoded profile. This value is an arbitary limit
+// and not taken from HW documentation.
+const int kMaxEncoderFramerate = 30;
+
+// Attributes required for encode. This only applies to video encode, not JPEG
+// encode.
+static const VAConfigAttrib kVideoEncodeVAConfigAttribs[] = {
+    {VAConfigAttribRateControl, VA_RC_CBR},
+    {VAConfigAttribEncPackedHeaders,
+     VA_ENC_PACKED_HEADER_SEQUENCE | VA_ENC_PACKED_HEADER_PICTURE},
+};
+
+// A map between VideoCodecProfile and VAProfile.
+static const struct {
+  VideoCodecProfile profile;
+  VAProfile va_profile;
+} kProfileMap[] = {
+    {H264PROFILE_BASELINE, VAProfileH264Baseline},
+    {H264PROFILE_MAIN, VAProfileH264Main},
+    // TODO(posciak): See if we can/want to support other variants of
+    // H264PROFILE_HIGH*.
+    {H264PROFILE_HIGH, VAProfileH264High},
+    {VP8PROFILE_ANY, VAProfileVP8Version0_3},
+    {VP9PROFILE_PROFILE0, VAProfileVP9Profile0},
+    {VP9PROFILE_PROFILE1, VAProfileVP9Profile1},
+    {VP9PROFILE_PROFILE2, VAProfileVP9Profile2},
+    {VP9PROFILE_PROFILE3, VAProfileVP9Profile3},
+};
+
+// This class is a wrapper around its |va_display_| (and its associated
+// |va_lock_|) to guarantee mutual exclusion and singleton behaviour.
+class VADisplayState {
+ public:
+  static VADisplayState* Get();
+
+  // Initialize static data before sandbox is enabled.
+  static void PreSandboxInitialization();
+
+  VADisplayState();
+  ~VADisplayState() = delete;
+
+  // |va_lock_| must be held on entry.
+  bool Initialize();
+  void Deinitialize(VAStatus* status);
+
+  base::Lock* va_lock() { return &va_lock_; }
+  VADisplay va_display() const { return va_display_; }
+
+  void SetDrmFd(base::PlatformFile fd) { drm_fd_.reset(HANDLE_EINTR(dup(fd))); }
+
+ private:
+  // Returns false on init failure.
+  static bool PostSandboxInitialization();
+
+  // Protected by |va_lock_|.
+  int refcount_;
+
+  // Libva is not thread safe, so we have to do locking for it ourselves.
+  // This lock is to be taken for the duration of all VA-API calls and for
+  // the entire job submission sequence in ExecuteAndDestroyPendingBuffers().
+  base::Lock va_lock_;
+
+  // Drm fd used to obtain access to the driver interface by VA.
+  base::ScopedFD drm_fd_;
+
+  // The VADisplay handle.
+  VADisplay va_display_;
+
+  // True if vaInitialize() has been called successfully.
+  bool va_initialized_;
+};
+
+// static
+VADisplayState* VADisplayState::Get() {
+  static VADisplayState* display_state = new VADisplayState();
+  return display_state;
+}
+
+// static
+void VADisplayState::PreSandboxInitialization() {
+  const char kDriRenderNode0Path[] = "/dev/dri/renderD128";
+  base::File drm_file = base::File(
+      base::FilePath::FromUTF8Unsafe(kDriRenderNode0Path),
+      base::File::FLAG_OPEN | base::File::FLAG_READ | base::File::FLAG_WRITE);
+  if (drm_file.IsValid())
+    VADisplayState::Get()->SetDrmFd(drm_file.GetPlatformFile());
+}
+
+// static
+bool VADisplayState::PostSandboxInitialization() {
+  const std::string va_suffix(std::to_string(VA_MAJOR_VERSION + 1));
+  StubPathMap paths;
+
+  paths[kModuleVa].push_back(std::string("libva.so.") + va_suffix);
+  paths[kModuleVa_drm].push_back(std::string("libva-drm.so.") + va_suffix);
+#if defined(USE_X11)
+  // libva-x11 does not exist on libva >= 2
+  if (VA_MAJOR_VERSION == 0)
+    paths[kModuleVa_x11].push_back("libva-x11.so.1");
+#endif
+
+  const bool success = InitializeStubs(paths);
+  if (!success) {
+    static const char kErrorMsg[] = "Failed to initialize VAAPI libs";
+#if defined(OS_CHROMEOS)
+    // When Chrome runs on Linux with target_os="chromeos", do not log error
+    // message without VAAPI libraries.
+    LOG_IF(ERROR, base::SysInfo::IsRunningOnChromeOS()) << kErrorMsg;
+#else
+    DVLOG(1) << kErrorMsg;
+#endif
+  }
+  return success;
+}
+
+VADisplayState::VADisplayState()
+    : refcount_(0), va_display_(nullptr), va_initialized_(false) {}
+
+bool VADisplayState::Initialize() {
+  va_lock_.AssertAcquired();
+
+  static bool result = PostSandboxInitialization();
+  if (!result)
+    return false;
+
+  if (refcount_++ > 0)
+    return true;
+
+  switch (gl::GetGLImplementation()) {
+    case gl::kGLImplementationEGLGLES2:
+      va_display_ = vaGetDisplayDRM(drm_fd_.get());
+      break;
+    case gl::kGLImplementationDesktopGL:
+#if defined(USE_X11)
+      va_display_ = vaGetDisplay(gfx::GetXDisplay());
+#else
+      LOG(WARNING) << "HW video decode acceleration not available without "
+                      "DesktopGL (GLX).";
+#endif  // USE_X11
+      break;
+    // Cannot infer platform from GL, try all available displays
+    case gl::kGLImplementationNone:
+#if defined(USE_X11)
+      va_display_ = vaGetDisplay(gfx::GetXDisplay());
+      if (vaDisplayIsValid(va_display_))
+        break;
+#endif  // USE_X11
+      va_display_ = vaGetDisplayDRM(drm_fd_.get());
+      break;
+
+    default:
+      LOG(WARNING) << "HW video decode acceleration not available for "
+                   << gl::GetGLImplementationName(gl::GetGLImplementation());
+      return false;
+  }
+
+  if (!vaDisplayIsValid(va_display_)) {
+    LOG(ERROR) << "Could not get a valid VA display";
+    return false;
+  }
+
+  // Set VA logging level to enable error messages, unless already set
+  constexpr char libva_log_level_env[] = "LIBVA_MESSAGING_LEVEL";
+  std::unique_ptr<base::Environment> env(base::Environment::Create());
+  if (!env->HasVar(libva_log_level_env))
+    env->SetVar(libva_log_level_env, "1");
+
+  // The VAAPI version.
+  int major_version, minor_version;
+  VAStatus va_res = vaInitialize(va_display_, &major_version, &minor_version);
+  if (va_res != VA_STATUS_SUCCESS) {
+    LOG(ERROR) << "vaInitialize failed: " << vaErrorStr(va_res);
+    return false;
+  }
+
+  va_initialized_ = true;
+  DVLOG(1) << "VAAPI version: " << major_version << "." << minor_version;
+
+  if (major_version != VA_MAJOR_VERSION || minor_version != VA_MINOR_VERSION) {
+    LOG(ERROR) << "This build of Chromium requires VA-API version "
+               << VA_MAJOR_VERSION << "." << VA_MINOR_VERSION
+               << ", system version: " << major_version << "." << minor_version;
+    return false;
+  }
+  return true;
+}
+
+void VADisplayState::Deinitialize(VAStatus* status) {
+  va_lock_.AssertAcquired();
+  if (--refcount_ > 0)
+    return;
+
+  // Must check if vaInitialize completed successfully, to work around a bug in
+  // libva. The bug was fixed upstream:
+  // http://lists.freedesktop.org/archives/libva/2013-July/001807.html
+  // TODO(mgiuca): Remove this check, and the |va_initialized_| variable, once
+  // the fix has rolled out sufficiently.
+  if (va_initialized_ && va_display_)
+    *status = vaTerminate(va_display_);
+  va_initialized_ = false;
+  va_display_ = nullptr;
+}
+
+static std::vector<VAConfigAttrib> GetRequiredAttribs(
+    VaapiWrapper::CodecMode mode,
+    VAProfile profile) {
+  std::vector<VAConfigAttrib> required_attribs;
+  // VAConfigAttribRTFormat is common to both encode and decode |mode|s.
+  if (profile == VAProfileVP9Profile2 || profile == VAProfileVP9Profile3) {
+    required_attribs.push_back(
+        {VAConfigAttribRTFormat, VA_RT_FORMAT_YUV420_10BPP});
+  } else {
+    required_attribs.push_back({VAConfigAttribRTFormat, VA_RT_FORMAT_YUV420});
+  }
+  if (mode == VaapiWrapper::kEncode && profile != VAProfileJPEGBaseline) {
+    required_attribs.insert(
+        required_attribs.end(), kVideoEncodeVAConfigAttribs,
+        kVideoEncodeVAConfigAttribs + arraysize(kVideoEncodeVAConfigAttribs));
+  }
+  return required_attribs;
+}
+
+static VAEntrypoint GetVaEntryPoint(VaapiWrapper::CodecMode mode,
+                                    VAProfile profile) {
+  switch (mode) {
+    case VaapiWrapper::kDecode:
+      return VAEntrypointVLD;
+    case VaapiWrapper::kEncode:
+      if (profile == VAProfileJPEGBaseline)
+        return VAEntrypointEncPicture;
+      else
+        return VAEntrypointEncSlice;
+    case VaapiWrapper::kCodecModeMax:
+      NOTREACHED();
+      return VAEntrypointVLD;
+  }
+}
+
+// This class encapsulates reading and giving access to the list of supported
+// ProfileInfo entries, in a singleton way.
+class VASupportedProfiles {
+ public:
+  struct ProfileInfo {
+    VAProfile va_profile;
+    gfx::Size max_resolution;
+  };
+  static VASupportedProfiles* Get();
+
+  std::vector<ProfileInfo> GetSupportedProfileInfosForCodecMode(
+      VaapiWrapper::CodecMode mode);
+
+  bool IsProfileSupported(VaapiWrapper::CodecMode mode, VAProfile va_profile);
+
+ private:
+  VASupportedProfiles();
+  ~VASupportedProfiles() = default;
+
+  bool GetSupportedVAProfiles(std::vector<VAProfile>* profiles);
+
+  // Gets supported profile infos for |mode|.
+  std::vector<ProfileInfo> GetSupportedProfileInfosForCodecModeInternal(
+      VaapiWrapper::CodecMode mode);
+
+  // |va_lock_| must be held on entry in the following _Locked methods.
+
+  // Checks if |va_profile| supports |entrypoint| or not.
+  bool IsEntrypointSupported_Locked(VAProfile va_profile,
+                                    VAEntrypoint entrypoint);
+  // Returns true if |va_profile| for |entrypoint| with |required_attribs| is
+  // supported.
+  bool AreAttribsSupported_Locked(
+      VAProfile va_profile,
+      VAEntrypoint entrypoint,
+      const std::vector<VAConfigAttrib>& required_attribs);
+  // Gets maximum resolution for |va_profile| and |entrypoint| with
+  // |required_attribs|. If return value is true, |resolution| is the maximum
+  // resolution.
+  bool GetMaxResolution_Locked(VAProfile va_profile,
+                               VAEntrypoint entrypoint,
+                               std::vector<VAConfigAttrib>& required_attribs,
+                               gfx::Size* resolution);
+
+  std::vector<ProfileInfo> supported_profiles_[VaapiWrapper::kCodecModeMax];
+
+  // Pointer to VADisplayState's members |va_lock_| and its |va_display_|.
+  base::Lock* va_lock_;
+  VADisplay va_display_;
+
+  const base::Closure report_error_to_uma_cb_;
+};
+
+// static
+VASupportedProfiles* VASupportedProfiles::Get() {
+  static VASupportedProfiles* profile_infos = new VASupportedProfiles();
+  return profile_infos;
+}
+
+std::vector<VASupportedProfiles::ProfileInfo>
+VASupportedProfiles::GetSupportedProfileInfosForCodecMode(
+    VaapiWrapper::CodecMode mode) {
+  return supported_profiles_[mode];
+}
+
+bool VASupportedProfiles::IsProfileSupported(VaapiWrapper::CodecMode mode,
+                                             VAProfile va_profile) {
+  for (const auto& profile : supported_profiles_[mode]) {
+    if (profile.va_profile == va_profile)
+      return true;
+  }
+  return false;
+}
+
+VASupportedProfiles::VASupportedProfiles()
+    : va_lock_(VADisplayState::Get()->va_lock()),
+      va_display_(nullptr),
+      report_error_to_uma_cb_(base::Bind(&base::DoNothing)) {
+  static_assert(arraysize(supported_profiles_) == VaapiWrapper::kCodecModeMax,
+                "The array size of supported profile is incorrect.");
+  {
+    base::AutoLock auto_lock(*va_lock_);
+    if (!VADisplayState::Get()->Initialize())
+      return;
+  }
+
+  va_display_ = VADisplayState::Get()->va_display();
+  DCHECK(va_display_) << "VADisplayState hasn't been properly Initialize()d";
+
+  for (size_t i = 0; i < VaapiWrapper::kCodecModeMax; ++i) {
+    supported_profiles_[i] = GetSupportedProfileInfosForCodecModeInternal(
+        static_cast<VaapiWrapper::CodecMode>(i));
+  }
+
+  {
+    base::AutoLock auto_lock(*va_lock_);
+    VAStatus va_res = VA_STATUS_SUCCESS;
+    VADisplayState::Get()->Deinitialize(&va_res);
+    VA_LOG_ON_ERROR(va_res, "vaTerminate failed");
+    va_display_ = nullptr;
+  }
+}
+
+std::vector<VASupportedProfiles::ProfileInfo>
+VASupportedProfiles::GetSupportedProfileInfosForCodecModeInternal(
+    VaapiWrapper::CodecMode mode) {
+  std::vector<ProfileInfo> supported_profile_infos;
+  std::vector<VAProfile> va_profiles;
+  if (!GetSupportedVAProfiles(&va_profiles))
+    return supported_profile_infos;
+
+  base::AutoLock auto_lock(*va_lock_);
+  for (const auto& va_profile : va_profiles) {
+    VAEntrypoint entrypoint = GetVaEntryPoint(mode, va_profile);
+    std::vector<VAConfigAttrib> required_attribs =
+        GetRequiredAttribs(mode, va_profile);
+    if (!IsEntrypointSupported_Locked(va_profile, entrypoint))
+      continue;
+    if (!AreAttribsSupported_Locked(va_profile, entrypoint, required_attribs))
+      continue;
+    ProfileInfo profile_info;
+    if (!GetMaxResolution_Locked(va_profile, entrypoint, required_attribs,
+                                 &profile_info.max_resolution)) {
+      LOG(ERROR) << "GetMaxResolution failed for va_profile " << va_profile
+                 << " and entrypoint " << entrypoint;
+      continue;
+    }
+    profile_info.va_profile = va_profile;
+    supported_profile_infos.push_back(profile_info);
+  }
+  return supported_profile_infos;
+}
+
+bool VASupportedProfiles::GetSupportedVAProfiles(
+    std::vector<VAProfile>* profiles) {
+  base::AutoLock auto_lock(*va_lock_);
+  // Query the driver for supported profiles.
+  const int max_profiles = vaMaxNumProfiles(va_display_);
+  std::vector<VAProfile> supported_profiles(
+      base::checked_cast<size_t>(max_profiles));
+
+  int num_supported_profiles;
+  VAStatus va_res = vaQueryConfigProfiles(va_display_, &supported_profiles[0],
+                                          &num_supported_profiles);
+  VA_SUCCESS_OR_RETURN(va_res, "vaQueryConfigProfiles failed", false);
+  if (num_supported_profiles < 0 || num_supported_profiles > max_profiles) {
+    LOG(ERROR) << "vaQueryConfigProfiles returned: " << num_supported_profiles;
+    return false;
+  }
+
+  supported_profiles.resize(base::checked_cast<size_t>(num_supported_profiles));
+  *profiles = supported_profiles;
+  return true;
+}
+
+bool VASupportedProfiles::IsEntrypointSupported_Locked(
+    VAProfile va_profile,
+    VAEntrypoint entrypoint) {
+  va_lock_->AssertAcquired();
+  // Query the driver for supported entrypoints.
+  int max_entrypoints = vaMaxNumEntrypoints(va_display_);
+  std::vector<VAEntrypoint> supported_entrypoints(
+      base::checked_cast<size_t>(max_entrypoints));
+
+  int num_supported_entrypoints;
+  VAStatus va_res = vaQueryConfigEntrypoints(va_display_, va_profile,
+                                             &supported_entrypoints[0],
+                                             &num_supported_entrypoints);
+  VA_SUCCESS_OR_RETURN(va_res, "vaQueryConfigEntrypoints failed", false);
+  if (num_supported_entrypoints < 0 ||
+      num_supported_entrypoints > max_entrypoints) {
+    LOG(ERROR) << "vaQueryConfigEntrypoints returned: "
+               << num_supported_entrypoints;
+    return false;
+  }
+
+  return base::ContainsValue(supported_entrypoints, entrypoint);
+}
+
+bool VASupportedProfiles::AreAttribsSupported_Locked(
+    VAProfile va_profile,
+    VAEntrypoint entrypoint,
+    const std::vector<VAConfigAttrib>& required_attribs) {
+  va_lock_->AssertAcquired();
+  // Query the driver for required attributes.
+  std::vector<VAConfigAttrib> attribs = required_attribs;
+  for (size_t i = 0; i < required_attribs.size(); ++i)
+    attribs[i].value = 0;
+
+  VAStatus va_res = vaGetConfigAttributes(va_display_, va_profile, entrypoint,
+                                          &attribs[0], attribs.size());
+  VA_SUCCESS_OR_RETURN(va_res, "vaGetConfigAttributes failed", false);
+
+  for (size_t i = 0; i < required_attribs.size(); ++i) {
+    if (attribs[i].type != required_attribs[i].type ||
+        (attribs[i].value & required_attribs[i].value) !=
+            required_attribs[i].value) {
+      DVLOG(1) << "Unsupported value " << required_attribs[i].value
+               << " for attribute type " << required_attribs[i].type;
+      return false;
+    }
+  }
+  return true;
+}
+
+bool VASupportedProfiles::GetMaxResolution_Locked(
+    VAProfile va_profile,
+    VAEntrypoint entrypoint,
+    std::vector<VAConfigAttrib>& required_attribs,
+    gfx::Size* resolution) {
+  va_lock_->AssertAcquired();
+  VAConfigID va_config_id;
+  VAStatus va_res =
+      vaCreateConfig(va_display_, va_profile, entrypoint, &required_attribs[0],
+                     required_attribs.size(), &va_config_id);
+  VA_SUCCESS_OR_RETURN(va_res, "vaCreateConfig failed", false);
+
+  // Calls vaQuerySurfaceAttributes twice. The first time is to get the number
+  // of attributes to prepare the space and the second time is to get all
+  // attributes.
+  unsigned int num_attribs;
+  va_res = vaQuerySurfaceAttributes(va_display_, va_config_id, nullptr,
+                                    &num_attribs);
+  VA_SUCCESS_OR_RETURN(va_res, "vaQuerySurfaceAttributes failed", false);
+  if (!num_attribs)
+    return false;
+
+  std::vector<VASurfaceAttrib> attrib_list(
+      base::checked_cast<size_t>(num_attribs));
+
+  va_res = vaQuerySurfaceAttributes(va_display_, va_config_id, &attrib_list[0],
+                                    &num_attribs);
+  VA_SUCCESS_OR_RETURN(va_res, "vaQuerySurfaceAttributes failed", false);
+
+  resolution->SetSize(0, 0);
+  for (const auto& attrib : attrib_list) {
+    if (attrib.type == VASurfaceAttribMaxWidth)
+      resolution->set_width(attrib.value.value.i);
+    else if (attrib.type == VASurfaceAttribMaxHeight)
+      resolution->set_height(attrib.value.value.i);
+  }
+  if (resolution->IsEmpty()) {
+    LOG(ERROR) << "Wrong codec resolution: " << resolution->ToString();
+    return false;
+  }
+  return true;
+}
+
+// Maps VideoCodecProfile enum values to VaProfile values. This function
+// includes a workaround for https://crbug.com/345569: if va_profile is h264
+// baseline and it is not supported, we try constrained baseline.
+VAProfile ProfileToVAProfile(VideoCodecProfile profile,
+                             VaapiWrapper::CodecMode mode) {
+  VAProfile va_profile = VAProfileNone;
+  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
+    if (kProfileMap[i].profile == profile) {
+      va_profile = kProfileMap[i].va_profile;
+      break;
+    }
+  }
+  if (!VASupportedProfiles::Get()->IsProfileSupported(mode, va_profile) &&
+      va_profile == VAProfileH264Baseline) {
+    // https://crbug.com/345569: ProfileIDToVideoCodecProfile() currently strips
+    // the information whether the profile is constrained or not, so we have no
+    // way to know here. Try for baseline first, but if it is not supported,
+    // try constrained baseline and hope this is what it actually is
+    // (which in practice is true for a great majority of cases).
+    if (VASupportedProfiles::Get()->IsProfileSupported(
+            mode, VAProfileH264ConstrainedBaseline)) {
+      va_profile = VAProfileH264ConstrainedBaseline;
+      DVLOG(1) << "Fall back to constrained baseline profile.";
+    }
+  }
+  return va_profile;
+}
+
+void DestroyVAImage(VADisplay va_display, VAImage image) {
+  if (image.image_id != VA_INVALID_ID)
+    vaDestroyImage(va_display, image.image_id);
+}
+
+}  // namespace
+
+VaapiWrapper::VaapiWrapper()
+    : va_surface_format_(0),
+      va_display_(NULL),
+      va_config_id_(VA_INVALID_ID),
+      va_context_id_(VA_INVALID_ID),
+      va_vpp_config_id_(VA_INVALID_ID),
+      va_vpp_context_id_(VA_INVALID_ID),
+      va_vpp_buffer_id_(VA_INVALID_ID) {
+  va_lock_ = VADisplayState::Get()->va_lock();
+}
+
+VaapiWrapper::~VaapiWrapper() {
+  DestroyPendingBuffers();
+  DestroyCodedBuffers();
+  DestroySurfaces();
+  DeinitializeVpp();
+  Deinitialize();
+}
+
+// static
+scoped_refptr<VaapiWrapper> VaapiWrapper::Create(
+    CodecMode mode,
+    VAProfile va_profile,
+    const base::Closure& report_error_to_uma_cb) {
+  if (!VASupportedProfiles::Get()->IsProfileSupported(mode, va_profile)) {
+    DVLOG(1) << "Unsupported va_profile: " << va_profile;
+    return nullptr;
+  }
+
+  scoped_refptr<VaapiWrapper> vaapi_wrapper(new VaapiWrapper());
+  if (vaapi_wrapper->VaInitialize(report_error_to_uma_cb)) {
+    if (vaapi_wrapper->Initialize(mode, va_profile))
+      return vaapi_wrapper;
+  }
+  LOG(ERROR) << "Failed to create VaapiWrapper for va_profile: " << va_profile;
+  return nullptr;
+}
+
+// static
+scoped_refptr<VaapiWrapper> VaapiWrapper::CreateForVideoCodec(
+    CodecMode mode,
+    VideoCodecProfile profile,
+    const base::Closure& report_error_to_uma_cb) {
+  VAProfile va_profile = ProfileToVAProfile(profile, mode);
+  return Create(mode, va_profile, report_error_to_uma_cb);
+}
+
+// static
+VideoEncodeAccelerator::SupportedProfiles
+VaapiWrapper::GetSupportedEncodeProfiles() {
+  VideoEncodeAccelerator::SupportedProfiles profiles;
+  std::vector<VASupportedProfiles::ProfileInfo> encode_profile_infos =
+      VASupportedProfiles::Get()->GetSupportedProfileInfosForCodecMode(kEncode);
+
+  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
+    VAProfile va_profile = ProfileToVAProfile(kProfileMap[i].profile, kEncode);
+    if (va_profile == VAProfileNone)
+      continue;
+    for (const auto& profile_info : encode_profile_infos) {
+      if (profile_info.va_profile == va_profile) {
+        VideoEncodeAccelerator::SupportedProfile profile;
+        profile.profile = kProfileMap[i].profile;
+        profile.max_resolution = profile_info.max_resolution;
+        profile.max_framerate_numerator = kMaxEncoderFramerate;
+        profile.max_framerate_denominator = 1;
+        profiles.push_back(profile);
+        break;
+      }
+    }
+  }
+  return profiles;
+}
+
+// static
+VideoDecodeAccelerator::SupportedProfiles
+VaapiWrapper::GetSupportedDecodeProfiles() {
+  VideoDecodeAccelerator::SupportedProfiles profiles;
+  std::vector<VASupportedProfiles::ProfileInfo> decode_profile_infos =
+      VASupportedProfiles::Get()->GetSupportedProfileInfosForCodecMode(kDecode);
+
+  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
+    VAProfile va_profile = ProfileToVAProfile(kProfileMap[i].profile, kDecode);
+    if (va_profile == VAProfileNone)
+      continue;
+    for (const auto& profile_info : decode_profile_infos) {
+      if (profile_info.va_profile == va_profile) {
+        VideoDecodeAccelerator::SupportedProfile profile;
+        profile.profile = kProfileMap[i].profile;
+        profile.max_resolution = profile_info.max_resolution;
+        profile.min_resolution.SetSize(16, 16);
+        profiles.push_back(profile);
+        break;
+      }
+    }
+  }
+  return profiles;
+}
+
+// static
+bool VaapiWrapper::IsJpegDecodeSupported() {
+  return VASupportedProfiles::Get()->IsProfileSupported(kDecode,
+                                                        VAProfileJPEGBaseline);
+}
+
+// static
+bool VaapiWrapper::IsJpegEncodeSupported() {
+  return VASupportedProfiles::Get()->IsProfileSupported(kEncode,
+                                                        VAProfileJPEGBaseline);
+}
+
+void VaapiWrapper::TryToSetVADisplayAttributeToLocalGPU() {
+  base::AutoLock auto_lock(*va_lock_);
+  VADisplayAttribute item = {VADisplayAttribRenderMode,
+                             1,   // At least support '_LOCAL_OVERLAY'.
+                             -1,  // The maximum possible support 'ALL'.
+                             VA_RENDER_MODE_LOCAL_GPU,
+                             VA_DISPLAY_ATTRIB_SETTABLE};
+
+  VAStatus va_res = vaSetDisplayAttributes(va_display_, &item, 1);
+  if (va_res != VA_STATUS_SUCCESS)
+    DVLOG(2) << "vaSetDisplayAttributes unsupported, ignoring by default.";
+}
+
+bool VaapiWrapper::VaInitialize(const base::Closure& report_error_to_uma_cb) {
+  report_error_to_uma_cb_ = report_error_to_uma_cb;
+  {
+    base::AutoLock auto_lock(*va_lock_);
+    if (!VADisplayState::Get()->Initialize())
+      return false;
+  }
+
+  va_display_ = VADisplayState::Get()->va_display();
+  DCHECK(va_display_) << "VADisplayState hasn't been properly Initialize()d";
+  return true;
+}
+
+bool VaapiWrapper::Initialize(CodecMode mode, VAProfile va_profile) {
+  TryToSetVADisplayAttributeToLocalGPU();
+
+  VAEntrypoint entrypoint = GetVaEntryPoint(mode, va_profile);
+  std::vector<VAConfigAttrib> required_attribs =
+      GetRequiredAttribs(mode, va_profile);
+  base::AutoLock auto_lock(*va_lock_);
+  VAStatus va_res =
+      vaCreateConfig(va_display_, va_profile, entrypoint, &required_attribs[0],
+                     required_attribs.size(), &va_config_id_);
+  VA_SUCCESS_OR_RETURN(va_res, "vaCreateConfig failed", false);
+
+  return true;
+}
+
+void VaapiWrapper::Deinitialize() {
+  base::AutoLock auto_lock(*va_lock_);
+
+  if (va_config_id_ != VA_INVALID_ID) {
+    VAStatus va_res = vaDestroyConfig(va_display_, va_config_id_);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyConfig failed");
+  }
+
+  VAStatus va_res = VA_STATUS_SUCCESS;
+  VADisplayState::Get()->Deinitialize(&va_res);
+  VA_LOG_ON_ERROR(va_res, "vaTerminate failed");
+
+  va_config_id_ = VA_INVALID_ID;
+  va_display_ = NULL;
+}
+
+bool VaapiWrapper::CreateSurfaces(unsigned int va_format,
+                                  const gfx::Size& size,
+                                  size_t num_surfaces,
+                                  std::vector<VASurfaceID>* va_surfaces) {
+  base::AutoLock auto_lock(*va_lock_);
+  DVLOG(2) << "Creating " << num_surfaces << " surfaces";
+
+  DCHECK(va_surfaces->empty());
+  DCHECK(va_surface_ids_.empty());
+  DCHECK_EQ(va_surface_format_, 0u);
+  va_surface_ids_.resize(num_surfaces);
+
+  // Allocate surfaces in driver.
+  VAStatus va_res =
+      vaCreateSurfaces(va_display_, va_format, size.width(), size.height(),
+                       &va_surface_ids_[0], va_surface_ids_.size(), NULL, 0);
+
+  VA_LOG_ON_ERROR(va_res, "vaCreateSurfaces failed");
+  if (va_res != VA_STATUS_SUCCESS) {
+    va_surface_ids_.clear();
+    return false;
+  }
+
+  // And create a context associated with them.
+  va_res = vaCreateContext(va_display_, va_config_id_, size.width(),
+                           size.height(), VA_PROGRESSIVE, &va_surface_ids_[0],
+                           va_surface_ids_.size(), &va_context_id_);
+
+  VA_LOG_ON_ERROR(va_res, "vaCreateContext failed");
+  if (va_res != VA_STATUS_SUCCESS) {
+    DestroySurfaces_Locked();
+    return false;
+  }
+
+  *va_surfaces = va_surface_ids_;
+  va_surface_format_ = va_format;
+  return true;
+}
+
+void VaapiWrapper::DestroySurfaces() {
+  base::AutoLock auto_lock(*va_lock_);
+  DVLOG(2) << "Destroying " << va_surface_ids_.size() << " surfaces";
+
+  DestroySurfaces_Locked();
+}
+
+void VaapiWrapper::DestroySurfaces_Locked() {
+  va_lock_->AssertAcquired();
+
+  if (va_context_id_ != VA_INVALID_ID) {
+    VAStatus va_res = vaDestroyContext(va_display_, va_context_id_);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyContext failed");
+  }
+
+  if (!va_surface_ids_.empty()) {
+    VAStatus va_res = vaDestroySurfaces(va_display_, &va_surface_ids_[0],
+                                        va_surface_ids_.size());
+    VA_LOG_ON_ERROR(va_res, "vaDestroySurfaces failed");
+  }
+
+  va_surface_ids_.clear();
+  va_context_id_ = VA_INVALID_ID;
+  va_surface_format_ = 0;
+}
+
+scoped_refptr<VASurface> VaapiWrapper::CreateUnownedSurface(
+    unsigned int va_format,
+    const gfx::Size& size,
+    const std::vector<VASurfaceAttrib>& va_attribs) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  std::vector<VASurfaceAttrib> attribs(va_attribs);
+  VASurfaceID va_surface_id;
+  VAStatus va_res =
+      vaCreateSurfaces(va_display_, va_format, size.width(), size.height(),
+                       &va_surface_id, 1, &attribs[0], attribs.size());
+
+  scoped_refptr<VASurface> va_surface;
+  VA_SUCCESS_OR_RETURN(va_res, "Failed to create unowned VASurface",
+                       va_surface);
+
+  // This is safe to use Unretained() here, because the VDA takes care
+  // of the destruction order. All the surfaces will be destroyed
+  // before VaapiWrapper.
+  va_surface = new VASurface(
+      va_surface_id, size, va_format,
+      base::Bind(&VaapiWrapper::DestroyUnownedSurface, base::Unretained(this)));
+
+  return va_surface;
+}
+
+scoped_refptr<VASurface> VaapiWrapper::CreateVASurfaceForPixmap(
+    const scoped_refptr<gfx::NativePixmap>& pixmap) {
+  // Create a VASurface for a NativePixmap by importing the underlying dmabufs.
+  VASurfaceAttribExternalBuffers va_attrib_extbuf;
+  memset(&va_attrib_extbuf, 0, sizeof(va_attrib_extbuf));
+
+  va_attrib_extbuf.pixel_format =
+      BufferFormatToVAFourCC(pixmap->GetBufferFormat());
+  gfx::Size size = pixmap->GetBufferSize();
+  va_attrib_extbuf.width = size.width();
+  va_attrib_extbuf.height = size.height();
+
+  size_t num_fds = pixmap->GetDmaBufFdCount();
+  size_t num_planes =
+      gfx::NumberOfPlanesForBufferFormat(pixmap->GetBufferFormat());
+  if (num_fds == 0 || num_fds > num_planes) {
+    LOG(ERROR) << "Invalid number of dmabuf fds: " << num_fds
+               << " , planes: " << num_planes;
+    return nullptr;
+  }
+
+  for (size_t i = 0; i < num_planes; ++i) {
+    va_attrib_extbuf.pitches[i] = pixmap->GetDmaBufPitch(i);
+    va_attrib_extbuf.offsets[i] = pixmap->GetDmaBufOffset(i);
+    DVLOG(4) << "plane " << i << ": pitch: " << va_attrib_extbuf.pitches[i]
+             << " offset: " << va_attrib_extbuf.offsets[i];
+  }
+  va_attrib_extbuf.num_planes = num_planes;
+
+  std::vector<unsigned long> fds(num_fds);
+  for (size_t i = 0; i < num_fds; ++i) {
+    int dmabuf_fd = pixmap->GetDmaBufFd(i);
+    if (dmabuf_fd < 0) {
+      LOG(ERROR) << "Failed to get dmabuf from an Ozone NativePixmap";
+      return nullptr;
+    }
+    fds[i] = dmabuf_fd;
+  }
+  va_attrib_extbuf.buffers = fds.data();
+  va_attrib_extbuf.num_buffers = fds.size();
+
+  va_attrib_extbuf.flags = 0;
+  va_attrib_extbuf.private_data = NULL;
+
+  std::vector<VASurfaceAttrib> va_attribs(2);
+
+  va_attribs[0].type = VASurfaceAttribMemoryType;
+  va_attribs[0].flags = VA_SURFACE_ATTRIB_SETTABLE;
+  va_attribs[0].value.type = VAGenericValueTypeInteger;
+  va_attribs[0].value.value.i = VA_SURFACE_ATTRIB_MEM_TYPE_DRM_PRIME;
+
+  va_attribs[1].type = VASurfaceAttribExternalBufferDescriptor;
+  va_attribs[1].flags = VA_SURFACE_ATTRIB_SETTABLE;
+  va_attribs[1].value.type = VAGenericValueTypePointer;
+  va_attribs[1].value.value.p = &va_attrib_extbuf;
+
+  scoped_refptr<VASurface> va_surface = CreateUnownedSurface(
+      BufferFormatToVARTFormat(pixmap->GetBufferFormat()), size, va_attribs);
+  if (!va_surface) {
+    LOG(ERROR) << "Failed to create VASurface for an Ozone NativePixmap";
+    return nullptr;
+  }
+
+  return va_surface;
+}
+
+void VaapiWrapper::DestroyUnownedSurface(VASurfaceID va_surface_id) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAStatus va_res = vaDestroySurfaces(va_display_, &va_surface_id, 1);
+  VA_LOG_ON_ERROR(va_res, "vaDestroySurfaces on surface failed");
+}
+
+bool VaapiWrapper::SubmitBuffer(VABufferType va_buffer_type,
+                                size_t size,
+                                void* buffer) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VABufferID buffer_id;
+  VAStatus va_res = vaCreateBuffer(va_display_, va_context_id_, va_buffer_type,
+                                   size, 1, buffer, &buffer_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a VA buffer", false);
+
+  switch (va_buffer_type) {
+    case VASliceParameterBufferType:
+    case VASliceDataBufferType:
+    case VAEncSliceParameterBufferType:
+      pending_slice_bufs_.push_back(buffer_id);
+      break;
+
+    default:
+      pending_va_bufs_.push_back(buffer_id);
+      break;
+  }
+
+  return true;
+}
+
+bool VaapiWrapper::SubmitVAEncMiscParamBuffer(
+    VAEncMiscParameterType misc_param_type,
+    size_t size,
+    void* buffer) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VABufferID buffer_id;
+  VAStatus va_res = vaCreateBuffer(
+      va_display_, va_context_id_, VAEncMiscParameterBufferType,
+      sizeof(VAEncMiscParameterBuffer) + size, 1, NULL, &buffer_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a VA buffer", false);
+
+  void* data_ptr = NULL;
+  va_res = vaMapBuffer(va_display_, buffer_id, &data_ptr);
+  VA_LOG_ON_ERROR(va_res, "vaMapBuffer failed");
+  if (va_res != VA_STATUS_SUCCESS) {
+    vaDestroyBuffer(va_display_, buffer_id);
+    return false;
+  }
+
+  DCHECK(data_ptr);
+
+  VAEncMiscParameterBuffer* misc_param =
+      reinterpret_cast<VAEncMiscParameterBuffer*>(data_ptr);
+  misc_param->type = misc_param_type;
+  memcpy(misc_param->data, buffer, size);
+  va_res = vaUnmapBuffer(va_display_, buffer_id);
+  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
+
+  pending_va_bufs_.push_back(buffer_id);
+  return true;
+}
+
+void VaapiWrapper::DestroyPendingBuffers() {
+  base::AutoLock auto_lock(*va_lock_);
+
+  for (const auto& pending_va_buf : pending_va_bufs_) {
+    VAStatus va_res = vaDestroyBuffer(va_display_, pending_va_buf);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
+  }
+
+  for (const auto& pending_slice_buf : pending_slice_bufs_) {
+    VAStatus va_res = vaDestroyBuffer(va_display_, pending_slice_buf);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
+  }
+
+  pending_va_bufs_.clear();
+  pending_slice_bufs_.clear();
+}
+
+bool VaapiWrapper::CreateCodedBuffer(size_t size, VABufferID* buffer_id) {
+  base::AutoLock auto_lock(*va_lock_);
+  VAStatus va_res =
+      vaCreateBuffer(va_display_, va_context_id_, VAEncCodedBufferType, size, 1,
+                     NULL, buffer_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a coded buffer", false);
+
+  const auto is_new_entry = coded_buffers_.insert(*buffer_id).second;
+  DCHECK(is_new_entry);
+  return true;
+}
+
+void VaapiWrapper::DestroyCodedBuffers() {
+  base::AutoLock auto_lock(*va_lock_);
+
+  for (std::set<VABufferID>::const_iterator iter = coded_buffers_.begin();
+       iter != coded_buffers_.end(); ++iter) {
+    VAStatus va_res = vaDestroyBuffer(va_display_, *iter);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
+  }
+
+  coded_buffers_.clear();
+}
+
+bool VaapiWrapper::Execute(VASurfaceID va_surface_id) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  DVLOG(4) << "Pending VA bufs to commit: " << pending_va_bufs_.size();
+  DVLOG(4) << "Pending slice bufs to commit: " << pending_slice_bufs_.size();
+  DVLOG(4) << "Target VA surface " << va_surface_id;
+
+  // Get ready to execute for given surface.
+  VAStatus va_res = vaBeginPicture(va_display_, va_context_id_, va_surface_id);
+  VA_SUCCESS_OR_RETURN(va_res, "vaBeginPicture failed", false);
+
+  if (pending_va_bufs_.size() > 0) {
+    // Commit parameter and slice buffers.
+    va_res = vaRenderPicture(va_display_, va_context_id_, &pending_va_bufs_[0],
+                             pending_va_bufs_.size());
+    VA_SUCCESS_OR_RETURN(va_res, "vaRenderPicture for va_bufs failed", false);
+  }
+
+  if (pending_slice_bufs_.size() > 0) {
+    va_res =
+        vaRenderPicture(va_display_, va_context_id_, &pending_slice_bufs_[0],
+                        pending_slice_bufs_.size());
+    VA_SUCCESS_OR_RETURN(va_res, "vaRenderPicture for slices failed", false);
+  }
+
+  // Instruct HW codec to start processing committed buffers.
+  // Does not block and the job is not finished after this returns.
+  va_res = vaEndPicture(va_display_, va_context_id_);
+  VA_SUCCESS_OR_RETURN(va_res, "vaEndPicture failed", false);
+
+  return true;
+}
+
+bool VaapiWrapper::ExecuteAndDestroyPendingBuffers(VASurfaceID va_surface_id) {
+  bool result = Execute(va_surface_id);
+  DestroyPendingBuffers();
+  return result;
+}
+
+#if defined(USE_X11)
+bool VaapiWrapper::PutSurfaceIntoPixmap(VASurfaceID va_surface_id,
+                                        Pixmap x_pixmap,
+                                        gfx::Size dest_size) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAStatus va_res = vaSyncSurface(va_display_, va_surface_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
+
+  // Put the data into an X Pixmap.
+  va_res = vaPutSurface(va_display_,
+                        va_surface_id,
+                        x_pixmap,
+                        0, 0, dest_size.width(), dest_size.height(),
+                        0, 0, dest_size.width(), dest_size.height(),
+                        NULL, 0, 0);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed putting surface to pixmap", false);
+  return true;
+}
+#endif  // USE_X11
+
+bool VaapiWrapper::GetVaImage(VASurfaceID va_surface_id,
+                              VAImageFormat* format,
+                              const gfx::Size& size,
+                              VAImage* image,
+                              void** mem) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAStatus va_res = vaSyncSurface(va_display_, va_surface_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
+
+  va_res =
+      vaCreateImage(va_display_, format, size.width(), size.height(), image);
+  VA_SUCCESS_OR_RETURN(va_res, "vaCreateImage failed", false);
+
+  va_res = vaGetImage(va_display_, va_surface_id, 0, 0, size.width(),
+                      size.height(), image->image_id);
+  VA_LOG_ON_ERROR(va_res, "vaGetImage failed");
+
+  if (va_res == VA_STATUS_SUCCESS) {
+    // Map the VAImage into memory
+    va_res = vaMapBuffer(va_display_, image->buf, mem);
+    VA_LOG_ON_ERROR(va_res, "vaMapBuffer failed");
+  }
+
+  if (va_res != VA_STATUS_SUCCESS) {
+    va_res = vaDestroyImage(va_display_, image->image_id);
+    VA_LOG_ON_ERROR(va_res, "vaDestroyImage failed");
+    return false;
+  }
+
+  return true;
+}
+
+void VaapiWrapper::ReturnVaImage(VAImage* image) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAStatus va_res = vaUnmapBuffer(va_display_, image->buf);
+  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
+
+  va_res = vaDestroyImage(va_display_, image->image_id);
+  VA_LOG_ON_ERROR(va_res, "vaDestroyImage failed");
+}
+
+bool VaapiWrapper::UploadVideoFrameToSurface(
+    const scoped_refptr<VideoFrame>& frame,
+    VASurfaceID va_surface_id) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAImage image;
+  VAStatus va_res = vaDeriveImage(va_display_, va_surface_id, &image);
+  VA_SUCCESS_OR_RETURN(va_res, "vaDeriveImage failed", false);
+  base::ScopedClosureRunner vaimage_deleter(
+      base::Bind(&DestroyVAImage, va_display_, image));
+
+  if (image.format.fourcc != VA_FOURCC_NV12) {
+    LOG(ERROR) << "Unsupported image format: " << image.format.fourcc;
+    return false;
+  }
+
+  if (gfx::Rect(image.width, image.height) < gfx::Rect(frame->coded_size())) {
+    LOG(ERROR) << "Buffer too small to fit the frame.";
+    return false;
+  }
+
+  void* image_ptr = NULL;
+  va_res = vaMapBuffer(va_display_, image.buf, &image_ptr);
+  VA_SUCCESS_OR_RETURN(va_res, "vaMapBuffer failed", false);
+  DCHECK(image_ptr);
+
+  int ret = 0;
+  {
+    base::AutoUnlock auto_unlock(*va_lock_);
+    ret = libyuv::I420ToNV12(
+        frame->data(VideoFrame::kYPlane), frame->stride(VideoFrame::kYPlane),
+        frame->data(VideoFrame::kUPlane), frame->stride(VideoFrame::kUPlane),
+        frame->data(VideoFrame::kVPlane), frame->stride(VideoFrame::kVPlane),
+        static_cast<uint8_t*>(image_ptr) + image.offsets[0], image.pitches[0],
+        static_cast<uint8_t*>(image_ptr) + image.offsets[1], image.pitches[1],
+        image.width, image.height);
+  }
+
+  va_res = vaUnmapBuffer(va_display_, image.buf);
+  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
+
+  return ret == 0;
+}
+
+bool VaapiWrapper::DownloadFromCodedBuffer(VABufferID buffer_id,
+                                           VASurfaceID sync_surface_id,
+                                           uint8_t* target_ptr,
+                                           size_t target_size,
+                                           size_t* coded_data_size) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  VAStatus va_res = vaSyncSurface(va_display_, sync_surface_id);
+  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
+
+  VACodedBufferSegment* buffer_segment = NULL;
+  va_res = vaMapBuffer(va_display_, buffer_id,
+                       reinterpret_cast<void**>(&buffer_segment));
+  VA_SUCCESS_OR_RETURN(va_res, "vaMapBuffer failed", false);
+  DCHECK(target_ptr);
+
+  {
+    base::AutoUnlock auto_unlock(*va_lock_);
+    *coded_data_size = 0;
+
+    while (buffer_segment) {
+      DCHECK(buffer_segment->buf);
+
+      if (buffer_segment->size > target_size) {
+        LOG(ERROR) << "Insufficient output buffer size";
+        break;
+      }
+
+      memcpy(target_ptr, buffer_segment->buf, buffer_segment->size);
+
+      target_ptr += buffer_segment->size;
+      *coded_data_size += buffer_segment->size;
+      target_size -= buffer_segment->size;
+
+      buffer_segment =
+          reinterpret_cast<VACodedBufferSegment*>(buffer_segment->next);
+    }
+  }
+
+  va_res = vaUnmapBuffer(va_display_, buffer_id);
+  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
+  return buffer_segment == NULL;
+}
+
+bool VaapiWrapper::DownloadAndDestroyCodedBuffer(VABufferID buffer_id,
+                                                 VASurfaceID sync_surface_id,
+                                                 uint8_t* target_ptr,
+                                                 size_t target_size,
+                                                 size_t* coded_data_size) {
+  bool result = DownloadFromCodedBuffer(buffer_id, sync_surface_id, target_ptr,
+                                        target_size, coded_data_size);
+
+  VAStatus va_res = vaDestroyBuffer(va_display_, buffer_id);
+  VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
+  const auto was_found = coded_buffers_.erase(buffer_id);
+  DCHECK(was_found);
+
+  return result;
+}
+
+bool VaapiWrapper::BlitSurface(
+    const scoped_refptr<VASurface>& va_surface_src,
+    const scoped_refptr<VASurface>& va_surface_dest) {
+  base::AutoLock auto_lock(*va_lock_);
+
+  // Initialize the post processing engine if not already done.
+  if (va_vpp_buffer_id_ == VA_INVALID_ID) {
+    if (!InitializeVpp_Locked())
+      return false;
+  }
+
+  VAProcPipelineParameterBuffer* pipeline_param;
+  VA_SUCCESS_OR_RETURN(vaMapBuffer(va_display_, va_vpp_buffer_id_,
+                                   reinterpret_cast<void**>(&pipeline_param)),
+                       "Couldn't map vpp buffer", false);
+
+  memset(pipeline_param, 0, sizeof *pipeline_param);
+  const gfx::Size src_size = va_surface_src->size();
+  const gfx::Size dest_size = va_surface_dest->size();
+
+  VARectangle input_region;
+  input_region.x = input_region.y = 0;
+  input_region.width = src_size.width();
+  input_region.height = src_size.height();
+  pipeline_param->surface_region = &input_region;
+  pipeline_param->surface = va_surface_src->id();
+  pipeline_param->surface_color_standard = VAProcColorStandardNone;
+
+  VARectangle output_region;
+  output_region.x = output_region.y = 0;
+  output_region.width = dest_size.width();
+  output_region.height = dest_size.height();
+  pipeline_param->output_region = &output_region;
+  pipeline_param->output_background_color = 0xff000000;
+  pipeline_param->output_color_standard = VAProcColorStandardNone;
+  pipeline_param->filter_flags = VA_FILTER_SCALING_DEFAULT;
+
+  VA_SUCCESS_OR_RETURN(vaUnmapBuffer(va_display_, va_vpp_buffer_id_),
+                       "Couldn't unmap vpp buffer", false);
+
+  VA_SUCCESS_OR_RETURN(
+      vaBeginPicture(va_display_, va_vpp_context_id_, va_surface_dest->id()),
+      "Couldn't begin picture", false);
+
+  VA_SUCCESS_OR_RETURN(
+      vaRenderPicture(va_display_, va_vpp_context_id_, &va_vpp_buffer_id_, 1),
+      "Couldn't render picture", false);
+
+  VA_SUCCESS_OR_RETURN(vaEndPicture(va_display_, va_vpp_context_id_),
+                       "Couldn't end picture", false);
+
+  return true;
+}
+
+bool VaapiWrapper::InitializeVpp_Locked() {
+  va_lock_->AssertAcquired();
+
+  VA_SUCCESS_OR_RETURN(
+      vaCreateConfig(va_display_, VAProfileNone, VAEntrypointVideoProc, NULL, 0,
+                     &va_vpp_config_id_),
+      "Couldn't create config", false);
+
+  // The size of the picture for the context is irrelevant in the case
+  // of the VPP, just passing 1x1.
+  VA_SUCCESS_OR_RETURN(vaCreateContext(va_display_, va_vpp_config_id_, 1, 1, 0,
+                                       NULL, 0, &va_vpp_context_id_),
+                       "Couldn't create context", false);
+
+  VA_SUCCESS_OR_RETURN(vaCreateBuffer(va_display_, va_vpp_context_id_,
+                                      VAProcPipelineParameterBufferType,
+                                      sizeof(VAProcPipelineParameterBuffer), 1,
+                                      NULL, &va_vpp_buffer_id_),
+                       "Couldn't create buffer", false);
+
+  return true;
+}
+
+void VaapiWrapper::DeinitializeVpp() {
+  base::AutoLock auto_lock(*va_lock_);
+
+  if (va_vpp_buffer_id_ != VA_INVALID_ID) {
+    vaDestroyBuffer(va_display_, va_vpp_buffer_id_);
+    va_vpp_buffer_id_ = VA_INVALID_ID;
+  }
+  if (va_vpp_context_id_ != VA_INVALID_ID) {
+    vaDestroyContext(va_display_, va_vpp_context_id_);
+    va_vpp_context_id_ = VA_INVALID_ID;
+  }
+  if (va_vpp_config_id_ != VA_INVALID_ID) {
+    vaDestroyConfig(va_display_, va_vpp_config_id_);
+    va_vpp_config_id_ = VA_INVALID_ID;
+  }
+}
+
+// static
+void VaapiWrapper::PreSandboxInitialization() {
+  VADisplayState::PreSandboxInitialization();
+}
+
+}  // namespace media
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_wrapper.h
@@ -0,0 +1,288 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+//
+// This file contains an implementation of VaapiWrapper, used by
+// VaapiVideoDecodeAccelerator and VaapiH264Decoder for decode,
+// and VaapiVideoEncodeAccelerator for encode, to interface
+// with libva (VA-API library for hardware video codec).
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_WRAPPER_H_
+#define MEDIA_GPU_VAAPI_VAAPI_WRAPPER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <set>
+#include <vector>
+
+#include <va/va.h>
+
+#include "base/files/file.h"
+#include "base/macros.h"
+#include "base/memory/ref_counted.h"
+#include "base/synchronization/lock.h"
+#include "media/base/video_decoder_config.h"
+#include "media/base/video_frame.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/video/jpeg_decode_accelerator.h"
+#include "media/video/video_decode_accelerator.h"
+#include "media/video/video_encode_accelerator.h"
+#include "ui/gfx/geometry/size.h"
+
+#if defined(USE_X11)
+#include "ui/gfx/x/x11.h"
+#endif  // USE_X11
+
+namespace gfx {
+class NativePixmap;
+}
+
+namespace media {
+
+// This class handles VA-API calls and ensures proper locking of VA-API calls
+// to libva, the userspace shim to the HW codec driver. libva is not
+// thread-safe, so we have to perform locking ourselves. This class is fully
+// synchronous and its methods can be called from any thread and may wait on
+// the va_lock_ while other, concurrent calls run.
+//
+// This class is responsible for managing VAAPI connection, contexts and state.
+// It is also responsible for managing and freeing VABuffers (not VASurfaces),
+// which are used to queue parameters and slice data to the HW codec,
+// as well as underlying memory for VASurfaces themselves.
+class MEDIA_GPU_EXPORT VaapiWrapper
+    : public base::RefCountedThreadSafe<VaapiWrapper> {
+ public:
+  enum CodecMode {
+    kDecode,
+    kEncode,
+    kCodecModeMax,
+  };
+
+  // Return an instance of VaapiWrapper initialized for |va_profile| and
+  // |mode|. |report_error_to_uma_cb| will be called independently from
+  // reporting errors to clients via method return values.
+  static scoped_refptr<VaapiWrapper> Create(
+      CodecMode mode,
+      VAProfile va_profile,
+      const base::Closure& report_error_to_uma_cb);
+
+  // Create VaapiWrapper for VideoCodecProfile. It maps VideoCodecProfile
+  // |profile| to VAProfile.
+  // |report_error_to_uma_cb| will be called independently from reporting
+  // errors to clients via method return values.
+  static scoped_refptr<VaapiWrapper> CreateForVideoCodec(
+      CodecMode mode,
+      VideoCodecProfile profile,
+      const base::Closure& report_error_to_uma_cb);
+
+  // Return the supported video encode profiles.
+  static VideoEncodeAccelerator::SupportedProfiles GetSupportedEncodeProfiles();
+
+  // Return the supported video decode profiles.
+  static VideoDecodeAccelerator::SupportedProfiles GetSupportedDecodeProfiles();
+
+  // Return true when JPEG decode is supported.
+  static bool IsJpegDecodeSupported();
+
+  // Return true when JPEG encode is supported.
+  static bool IsJpegEncodeSupported();
+
+  // Create |num_surfaces| backing surfaces in driver for VASurfaces of
+  // |va_format|, each of size |size|. Returns true when successful, with the
+  // created IDs in |va_surfaces| to be managed and later wrapped in
+  // VASurfaces.
+  // The client must DestroySurfaces() each time before calling this method
+  // again to free the allocated surfaces first, but is not required to do so
+  // at destruction time, as this will be done automatically from
+  // the destructor.
+  virtual bool CreateSurfaces(unsigned int va_format,
+                              const gfx::Size& size,
+                              size_t num_surfaces,
+                              std::vector<VASurfaceID>* va_surfaces);
+
+  // Free all memory allocated in CreateSurfaces.
+  virtual void DestroySurfaces();
+
+  // Create a VASurface of |va_format|, |size| and using |va_attribs|
+  // attributes. The ownership of the surface is transferred to the
+  // caller. It differs from surfaces created using CreateSurfaces(),
+  // where VaapiWrapper is the owner of the surfaces.
+  scoped_refptr<VASurface> CreateUnownedSurface(
+      unsigned int va_format,
+      const gfx::Size& size,
+      const std::vector<VASurfaceAttrib>& va_attribs);
+
+  // Create a VASurface for |pixmap|. The ownership of the surface is
+  // transferred to the caller. It differs from surfaces created using
+  // CreateSurfaces(), where VaapiWrapper is the owner of the surfaces.
+  scoped_refptr<VASurface> CreateVASurfaceForPixmap(
+      const scoped_refptr<gfx::NativePixmap>& pixmap);
+
+  // Submit parameters or slice data of |va_buffer_type|, copying them from
+  // |buffer| of size |size|, into HW codec. The data in |buffer| is no
+  // longer needed and can be freed after this method returns.
+  // Data submitted via this method awaits in the HW codec until
+  // ExecuteAndDestroyPendingBuffers() is called to execute or
+  // DestroyPendingBuffers() is used to cancel a pending job.
+  bool SubmitBuffer(VABufferType va_buffer_type, size_t size, void* buffer);
+
+  // Submit a VAEncMiscParameterBuffer of given |misc_param_type|, copying its
+  // data from |buffer| of size |size|, into HW codec. The data in |buffer| is
+  // no longer needed and can be freed after this method returns.
+  // Data submitted via this method awaits in the HW codec until
+  // ExecuteAndDestroyPendingBuffers() is called to execute or
+  // DestroyPendingBuffers() is used to cancel a pending job.
+  bool SubmitVAEncMiscParamBuffer(VAEncMiscParameterType misc_param_type,
+                                  size_t size,
+                                  void* buffer);
+
+  // Cancel and destroy all buffers queued to the HW codec via SubmitBuffer().
+  // Useful when a pending job is to be cancelled (on reset or error).
+  void DestroyPendingBuffers();
+
+  // Execute job in hardware on target |va_surface_id| and destroy pending
+  // buffers. Return false if Execute() fails.
+  bool ExecuteAndDestroyPendingBuffers(VASurfaceID va_surface_id);
+
+#if defined(USE_X11)
+  // Put data from |va_surface_id| into |x_pixmap| of size
+  // |dest_size|, converting/scaling to it.
+  bool PutSurfaceIntoPixmap(VASurfaceID va_surface_id,
+                            Pixmap x_pixmap,
+                            gfx::Size dest_size);
+#endif  // USE_X11
+
+  // Get a VAImage from a VASurface |va_surface_id| and map it into memory with
+  // given |format| and |size|. The output is |image| and the mapped memory is
+  // |mem|. If |format| doesn't equal to the internal format, the underlying
+  // implementation will do format conversion if supported. |size| should be
+  // smaller than or equal to the surface. If |size| is smaller, the image will
+  // be cropped. The VAImage should be released using the ReturnVaImage
+  // function. Returns true when successful.
+  bool GetVaImage(VASurfaceID va_surface_id,
+                  VAImageFormat* format,
+                  const gfx::Size& size,
+                  VAImage* image,
+                  void** mem);
+
+  // Release the VAImage (and the associated memory mapping) obtained from
+  // GetVaImage().
+  void ReturnVaImage(VAImage* image);
+
+  // Upload contents of |frame| into |va_surface_id| for encode.
+  bool UploadVideoFrameToSurface(const scoped_refptr<VideoFrame>& frame,
+                                 VASurfaceID va_surface_id);
+
+  // Create a buffer of |size| bytes to be used as encode output.
+  bool CreateCodedBuffer(size_t size, VABufferID* buffer_id);
+
+  // Download the contents of the buffer with given |buffer_id| into a buffer of
+  // size |target_size|, pointed to by |target_ptr|. The number of bytes
+  // downloaded will be returned in |coded_data_size|. |sync_surface_id| will
+  // be used as a sync point, i.e. it will have to become idle before starting
+  // the download. |sync_surface_id| should be the source surface passed
+  // to the encode job.
+  bool DownloadFromCodedBuffer(VABufferID buffer_id,
+                               VASurfaceID sync_surface_id,
+                               uint8_t* target_ptr,
+                               size_t target_size,
+                               size_t* coded_data_size);
+
+  // See DownloadFromCodedBuffer() for details. After downloading, it deletes
+  // the VA buffer with |buffer_id|.
+  bool DownloadAndDestroyCodedBuffer(VABufferID buffer_id,
+                                     VASurfaceID sync_surface_id,
+                                     uint8_t* target_ptr,
+                                     size_t target_size,
+                                     size_t* coded_data_size);
+
+  // Destroy all previously-allocated (and not yet destroyed) coded buffers.
+  void DestroyCodedBuffers();
+
+  // Blits a VASurface |va_surface_src| into another VASurface
+  // |va_surface_dest| applying pixel format conversion and scaling
+  // if needed.
+  bool BlitSurface(const scoped_refptr<VASurface>& va_surface_src,
+                   const scoped_refptr<VASurface>& va_surface_dest);
+
+  // Initialize static data before sandbox is enabled.
+  static void PreSandboxInitialization();
+
+  // Get the created surfaces format.
+  unsigned int va_surface_format() const { return va_surface_format_; }
+
+ protected:
+  VaapiWrapper();
+  virtual ~VaapiWrapper();
+
+ private:
+  friend class base::RefCountedThreadSafe<VaapiWrapper>;
+
+  bool Initialize(CodecMode mode, VAProfile va_profile);
+  void Deinitialize();
+  bool VaInitialize(const base::Closure& report_error_to_uma_cb);
+
+  // Free all memory allocated in CreateSurfaces.
+  void DestroySurfaces_Locked();
+  // Destroys a |va_surface| created using CreateUnownedSurface.
+  void DestroyUnownedSurface(VASurfaceID va_surface_id);
+
+  // Initialize the video post processing context with the |size| of
+  // the input pictures to be processed.
+  bool InitializeVpp_Locked();
+
+  // Deinitialize the video post processing context.
+  void DeinitializeVpp();
+
+  // Execute pending job in hardware and destroy pending buffers. Return false
+  // if vaapi driver refuses to accept parameter or slice buffers submitted
+  // by client, or if execution fails in hardware.
+  bool Execute(VASurfaceID va_surface_id);
+
+  // Attempt to set render mode to "render to texture.". Failure is non-fatal.
+  void TryToSetVADisplayAttributeToLocalGPU();
+
+  // Pointer to VADisplayState's member |va_lock_|. Guaranteed to be valid for
+  // the lifetime of VaapiWrapper.
+  base::Lock* va_lock_;
+
+  // Allocated ids for VASurfaces.
+  std::vector<VASurfaceID> va_surface_ids_;
+
+  // VA format of surfaces with va_surface_ids_.
+  unsigned int va_surface_format_;
+
+  // VA handles.
+  // All valid after successful Initialize() and until Deinitialize().
+  VADisplay va_display_;
+  VAConfigID va_config_id_;
+  // Created for the current set of va_surface_ids_ in CreateSurfaces() and
+  // valid until DestroySurfaces().
+  VAContextID va_context_id_;
+
+  // Data queued up for HW codec, to be committed on next execution.
+  std::vector<VABufferID> pending_slice_bufs_;
+  std::vector<VABufferID> pending_va_bufs_;
+
+  // Bitstream buffers for encode.
+  std::set<VABufferID> coded_buffers_;
+
+  // Called to report codec errors to UMA. Errors to clients are reported via
+  // return values from public methods.
+  base::Closure report_error_to_uma_cb_;
+
+  // VPP (Video Post Processing) context, this is used to convert
+  // pictures used by the decoder to RGBA pictures usable by GL or the
+  // display hardware.
+  VAConfigID va_vpp_config_id_;
+  VAContextID va_vpp_context_id_;
+  VABufferID va_vpp_buffer_id_;
+
+  DISALLOW_COPY_AND_ASSIGN(VaapiWrapper);
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_WRAPPER_H_
--- a/media/gpu/vaapi_jpeg_decode_accelerator.cc
+++ /dev/null
@@ -1,325 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_jpeg_decode_accelerator.h"
-
-#include <stddef.h>
-#include <string.h>
-
-#include <memory>
-#include <utility>
-
-#include "base/bind.h"
-#include "base/logging.h"
-#include "base/metrics/histogram_macros.h"
-#include "base/threading/thread_task_runner_handle.h"
-#include "base/trace_event/trace_event.h"
-#include "gpu/ipc/service/gpu_channel.h"
-#include "media/base/video_frame.h"
-#include "media/filters/jpeg_parser.h"
-#include "media/gpu/shared_memory_region.h"
-#include "media/gpu/vaapi/vaapi_picture.h"
-#include "third_party/libyuv/include/libyuv.h"
-
-#define VLOGF(level) VLOG(level) << __func__ << "(): "
-#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
-
-namespace media {
-
-namespace {
-// UMA errors that the VaapiJpegDecodeAccelerator class reports.
-enum VAJDADecoderFailure {
-  VAAPI_ERROR = 0,
-  VAJDA_DECODER_FAILURES_MAX,
-};
-
-static void ReportToUMA(VAJDADecoderFailure failure) {
-  UMA_HISTOGRAM_ENUMERATION("Media.VAJDA.DecoderFailure", failure,
-                            VAJDA_DECODER_FAILURES_MAX + 1);
-}
-
-static unsigned int VaSurfaceFormatForJpeg(
-    const JpegFrameHeader& frame_header) {
-  // The range of sampling factor is [1, 4]. Pack them into integer to make the
-  // matching code simpler. For example, 0x211 means the sampling factor are 2,
-  // 1, 1 for 3 components.
-  unsigned int h = 0, v = 0;
-  for (int i = 0; i < frame_header.num_components; i++) {
-    DCHECK_LE(frame_header.components[i].horizontal_sampling_factor, 4);
-    DCHECK_LE(frame_header.components[i].vertical_sampling_factor, 4);
-    h = h << 4 | frame_header.components[i].horizontal_sampling_factor;
-    v = v << 4 | frame_header.components[i].vertical_sampling_factor;
-  }
-
-  switch (frame_header.num_components) {
-    case 1:  // Grey image
-      return VA_RT_FORMAT_YUV400;
-
-    case 3:  // Y Cb Cr color image
-      // See https://en.wikipedia.org/wiki/Chroma_subsampling for the
-      // definition of these numbers.
-      if (h == 0x211 && v == 0x211)
-        return VA_RT_FORMAT_YUV420;
-
-      if (h == 0x211 && v == 0x111)
-        return VA_RT_FORMAT_YUV422;
-
-      if (h == 0x111 && v == 0x111)
-        return VA_RT_FORMAT_YUV444;
-
-      if (h == 0x411 && v == 0x111)
-        return VA_RT_FORMAT_YUV411;
-  }
-  VLOGF(1) << "Unsupported sampling factor: num_components="
-           << frame_header.num_components << ", h=" << std::hex << h
-           << ", v=" << v;
-
-  return 0;
-}
-
-}  // namespace
-
-VaapiJpegDecodeAccelerator::DecodeRequest::DecodeRequest(
-    int32_t bitstream_buffer_id,
-    std::unique_ptr<SharedMemoryRegion> shm,
-    const scoped_refptr<VideoFrame>& video_frame)
-    : bitstream_buffer_id(bitstream_buffer_id),
-      shm(std::move(shm)),
-      video_frame(video_frame) {}
-
-VaapiJpegDecodeAccelerator::DecodeRequest::~DecodeRequest() {}
-
-void VaapiJpegDecodeAccelerator::NotifyError(int32_t bitstream_buffer_id,
-                                             Error error) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  VLOGF(1) << "Notifying of error " << error;
-  DCHECK(client_);
-  client_->NotifyError(bitstream_buffer_id, error);
-}
-
-void VaapiJpegDecodeAccelerator::NotifyErrorFromDecoderThread(
-    int32_t bitstream_buffer_id,
-    Error error) {
-  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
-  task_runner_->PostTask(FROM_HERE,
-                         base::Bind(&VaapiJpegDecodeAccelerator::NotifyError,
-                                    weak_this_, bitstream_buffer_id, error));
-}
-
-void VaapiJpegDecodeAccelerator::VideoFrameReady(int32_t bitstream_buffer_id) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  client_->VideoFrameReady(bitstream_buffer_id);
-}
-
-VaapiJpegDecodeAccelerator::VaapiJpegDecodeAccelerator(
-    const scoped_refptr<base::SingleThreadTaskRunner>& io_task_runner)
-    : task_runner_(base::ThreadTaskRunnerHandle::Get()),
-      io_task_runner_(io_task_runner),
-      decoder_thread_("VaapiJpegDecoderThread"),
-      va_surface_id_(VA_INVALID_SURFACE),
-      weak_this_factory_(this) {
-  weak_this_ = weak_this_factory_.GetWeakPtr();
-}
-
-VaapiJpegDecodeAccelerator::~VaapiJpegDecodeAccelerator() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  VLOGF(2) << "Destroying VaapiJpegDecodeAccelerator";
-
-  weak_this_factory_.InvalidateWeakPtrs();
-  decoder_thread_.Stop();
-}
-
-bool VaapiJpegDecodeAccelerator::Initialize(Client* client) {
-  VLOGF(2);
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  client_ = client;
-
-  vaapi_wrapper_ =
-      VaapiWrapper::Create(VaapiWrapper::kDecode, VAProfileJPEGBaseline,
-                           base::Bind(&ReportToUMA, VAAPI_ERROR));
-
-  if (!vaapi_wrapper_.get()) {
-    VLOGF(1) << "Failed initializing VAAPI";
-    return false;
-  }
-
-  if (!decoder_thread_.Start()) {
-    VLOGF(1) << "Failed to start decoding thread.";
-    return false;
-  }
-  decoder_task_runner_ = decoder_thread_.task_runner();
-
-  return true;
-}
-
-bool VaapiJpegDecodeAccelerator::OutputPicture(
-    VASurfaceID va_surface_id,
-    int32_t input_buffer_id,
-    const scoped_refptr<VideoFrame>& video_frame) {
-  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
-
-  TRACE_EVENT1("jpeg", "VaapiJpegDecodeAccelerator::OutputPicture",
-               "input_buffer_id", input_buffer_id);
-
-  DVLOGF(4) << "Outputting VASurface " << va_surface_id
-            << " into video_frame associated with input buffer id "
-            << input_buffer_id;
-
-  VAImage image;
-  VAImageFormat format;
-  const uint32_t kI420Fourcc = VA_FOURCC('I', '4', '2', '0');
-  memset(&image, 0, sizeof(image));
-  memset(&format, 0, sizeof(format));
-  format.fourcc = kI420Fourcc;
-  format.byte_order = VA_LSB_FIRST;
-  format.bits_per_pixel = 12;  // 12 for I420
-
-  uint8_t* mem = nullptr;
-  gfx::Size coded_size = video_frame->coded_size();
-  if (!vaapi_wrapper_->GetVaImage(va_surface_id, &format, coded_size, &image,
-                                  reinterpret_cast<void**>(&mem))) {
-    VLOGF(1) << "Cannot get VAImage";
-    return false;
-  }
-
-  // Copy image content from VAImage to VideoFrame.
-  // The component order of VAImage I420 are Y, U, and V.
-  DCHECK_EQ(image.num_planes, 3u);
-  DCHECK_GE(image.width, coded_size.width());
-  DCHECK_GE(image.height, coded_size.height());
-  const uint8_t* src_y = mem + image.offsets[0];
-  const uint8_t* src_u = mem + image.offsets[1];
-  const uint8_t* src_v = mem + image.offsets[2];
-  size_t src_y_stride = image.pitches[0];
-  size_t src_u_stride = image.pitches[1];
-  size_t src_v_stride = image.pitches[2];
-  uint8_t* dst_y = video_frame->data(VideoFrame::kYPlane);
-  uint8_t* dst_u = video_frame->data(VideoFrame::kUPlane);
-  uint8_t* dst_v = video_frame->data(VideoFrame::kVPlane);
-  size_t dst_y_stride = video_frame->stride(VideoFrame::kYPlane);
-  size_t dst_u_stride = video_frame->stride(VideoFrame::kUPlane);
-  size_t dst_v_stride = video_frame->stride(VideoFrame::kVPlane);
-
-  if (libyuv::I420Copy(src_y, src_y_stride,  // Y
-                       src_u, src_u_stride,  // U
-                       src_v, src_v_stride,  // V
-                       dst_y, dst_y_stride,  // Y
-                       dst_u, dst_u_stride,  // U
-                       dst_v, dst_v_stride,  // V
-                       coded_size.width(), coded_size.height())) {
-    VLOGF(1) << "I420Copy failed";
-    return false;
-  }
-
-  vaapi_wrapper_->ReturnVaImage(&image);
-
-  task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiJpegDecodeAccelerator::VideoFrameReady,
-                            weak_this_, input_buffer_id));
-
-  return true;
-}
-
-void VaapiJpegDecodeAccelerator::DecodeTask(
-    const std::unique_ptr<DecodeRequest>& request) {
-  DVLOGF(4);
-  DCHECK(decoder_task_runner_->BelongsToCurrentThread());
-  TRACE_EVENT0("jpeg", "DecodeTask");
-
-  JpegParseResult parse_result;
-  if (!ParseJpegPicture(
-          reinterpret_cast<const uint8_t*>(request->shm->memory()),
-          request->shm->size(), &parse_result)) {
-    VLOGF(1) << "ParseJpegPicture failed";
-    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
-                                 PARSE_JPEG_FAILED);
-    return;
-  }
-
-  unsigned int new_va_rt_format =
-      VaSurfaceFormatForJpeg(parse_result.frame_header);
-  if (!new_va_rt_format) {
-    VLOGF(1) << "Unsupported subsampling";
-    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
-                                 UNSUPPORTED_JPEG);
-    return;
-  }
-
-  // Reuse VASurface if size doesn't change.
-  gfx::Size new_coded_size(parse_result.frame_header.coded_width,
-                           parse_result.frame_header.coded_height);
-  if (new_coded_size != coded_size_ || va_surface_id_ == VA_INVALID_SURFACE ||
-      new_va_rt_format != va_rt_format_) {
-    vaapi_wrapper_->DestroySurfaces();
-    va_surface_id_ = VA_INVALID_SURFACE;
-    va_rt_format_ = new_va_rt_format;
-
-    std::vector<VASurfaceID> va_surfaces;
-    if (!vaapi_wrapper_->CreateSurfaces(va_rt_format_, new_coded_size, 1,
-                                        &va_surfaces)) {
-      VLOGF(1) << "Create VA surface failed";
-      NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
-                                   PLATFORM_FAILURE);
-      return;
-    }
-    va_surface_id_ = va_surfaces[0];
-    coded_size_ = new_coded_size;
-  }
-
-  if (!VaapiJpegDecoder::Decode(vaapi_wrapper_.get(), parse_result,
-                                va_surface_id_)) {
-    VLOGF(1) << "Decode JPEG failed";
-    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
-                                 PLATFORM_FAILURE);
-    return;
-  }
-
-  if (!OutputPicture(va_surface_id_, request->bitstream_buffer_id,
-                     request->video_frame)) {
-    VLOGF(1) << "Output picture failed";
-    NotifyErrorFromDecoderThread(request->bitstream_buffer_id,
-                                 PLATFORM_FAILURE);
-    return;
-  }
-}
-
-void VaapiJpegDecodeAccelerator::Decode(
-    const BitstreamBuffer& bitstream_buffer,
-    const scoped_refptr<VideoFrame>& video_frame) {
-  DCHECK(io_task_runner_->BelongsToCurrentThread());
-  TRACE_EVENT1("jpeg", "Decode", "input_id", bitstream_buffer.id());
-
-  DVLOGF(4) << "Mapping new input buffer id: " << bitstream_buffer.id()
-            << " size: " << bitstream_buffer.size();
-
-  // SharedMemoryRegion will take over the |bitstream_buffer.handle()|.
-  std::unique_ptr<SharedMemoryRegion> shm(
-      new SharedMemoryRegion(bitstream_buffer, true));
-
-  if (bitstream_buffer.id() < 0) {
-    VLOGF(1) << "Invalid bitstream_buffer, id: " << bitstream_buffer.id();
-    NotifyErrorFromDecoderThread(bitstream_buffer.id(), INVALID_ARGUMENT);
-    return;
-  }
-
-  if (!shm->Map()) {
-    VLOGF(1) << "Failed to map input buffer";
-    NotifyErrorFromDecoderThread(bitstream_buffer.id(), UNREADABLE_INPUT);
-    return;
-  }
-
-  std::unique_ptr<DecodeRequest> request(
-      new DecodeRequest(bitstream_buffer.id(), std::move(shm), video_frame));
-
-  decoder_task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiJpegDecodeAccelerator::DecodeTask,
-                            base::Unretained(this), base::Passed(&request)));
-}
-
-bool VaapiJpegDecodeAccelerator::IsSupported() {
-  return VaapiWrapper::IsJpegDecodeSupported();
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_jpeg_decode_accelerator.h
+++ /dev/null
@@ -1,121 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef MEDIA_GPU_VAAPI_JPEG_DECODE_ACCELERATOR_H_
-#define MEDIA_GPU_VAAPI_JPEG_DECODE_ACCELERATOR_H_
-
-#include <stdint.h>
-
-#include <memory>
-
-#include "base/macros.h"
-#include "base/memory/linked_ptr.h"
-#include "base/memory/weak_ptr.h"
-#include "base/single_thread_task_runner.h"
-#include "base/synchronization/lock.h"
-#include "base/threading/thread.h"
-#include "media/base/bitstream_buffer.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/shared_memory_region.h"
-#include "media/gpu/vaapi_jpeg_decoder.h"
-#include "media/gpu/vaapi_wrapper.h"
-#include "media/video/jpeg_decode_accelerator.h"
-
-namespace media {
-
-// Class to provide JPEG decode acceleration for Intel systems with hardware
-// support for it, and on which libva is available.
-// Decoding tasks are performed in a separate decoding thread.
-//
-// Threading/life-cycle: this object is created & destroyed on the GPU
-// ChildThread.  A few methods on it are called on the decoder thread which is
-// stopped during |this->Destroy()|, so any tasks posted to the decoder thread
-// can assume |*this| is still alive.  See |weak_this_| below for more details.
-class MEDIA_GPU_EXPORT VaapiJpegDecodeAccelerator
-    : public JpegDecodeAccelerator {
- public:
-  VaapiJpegDecodeAccelerator(
-      const scoped_refptr<base::SingleThreadTaskRunner>& io_task_runner);
-  ~VaapiJpegDecodeAccelerator() override;
-
-  // JpegDecodeAccelerator implementation.
-  bool Initialize(JpegDecodeAccelerator::Client* client) override;
-  void Decode(const BitstreamBuffer& bitstream_buffer,
-              const scoped_refptr<VideoFrame>& video_frame) override;
-  bool IsSupported() override;
-
- private:
-  // An input buffer and the corresponding output video frame awaiting
-  // consumption, provided by the client.
-  struct DecodeRequest {
-    DecodeRequest(int32_t bitstream_buffer_id,
-                  std::unique_ptr<SharedMemoryRegion> shm,
-                  const scoped_refptr<VideoFrame>& video_frame);
-    ~DecodeRequest();
-
-    int32_t bitstream_buffer_id;
-    std::unique_ptr<SharedMemoryRegion> shm;
-    scoped_refptr<VideoFrame> video_frame;
-  };
-
-  // Notifies the client that an error has occurred and decoding cannot
-  // continue.
-  void NotifyError(int32_t bitstream_buffer_id, Error error);
-  void NotifyErrorFromDecoderThread(int32_t bitstream_buffer_id, Error error);
-  void VideoFrameReady(int32_t bitstream_buffer_id);
-
-  // Processes one decode |request|.
-  void DecodeTask(const std::unique_ptr<DecodeRequest>& request);
-
-  // Puts contents of |va_surface| into given |video_frame|, releases the
-  // surface and passes the |input_buffer_id| of the resulting picture to
-  // client for output.
-  bool OutputPicture(VASurfaceID va_surface_id,
-                     int32_t input_buffer_id,
-                     const scoped_refptr<VideoFrame>& video_frame);
-
-  // ChildThread's task runner.
-  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
-
-  // GPU IO task runner.
-  scoped_refptr<base::SingleThreadTaskRunner> io_task_runner_;
-
-  // The client of this class.
-  Client* client_;
-
-  // WeakPtr<> pointing to |this| for use in posting tasks from the decoder
-  // thread back to the ChildThread.  Because the decoder thread is a member of
-  // this class, any task running on the decoder thread is guaranteed that this
-  // object is still alive.  As a result, tasks posted from ChildThread to
-  // decoder thread should use base::Unretained(this), and tasks posted from the
-  // decoder thread to the ChildThread should use |weak_this_|.
-  base::WeakPtr<VaapiJpegDecodeAccelerator> weak_this_;
-
-  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
-
-  // Comes after vaapi_wrapper_ to ensure its destructor is executed before
-  // |vaapi_wrapper_| is destroyed.
-  std::unique_ptr<VaapiJpegDecoder> decoder_;
-  base::Thread decoder_thread_;
-  // Use this to post tasks to |decoder_thread_| instead of
-  // |decoder_thread_.task_runner()| because the latter will be NULL once
-  // |decoder_thread_.Stop()| returns.
-  scoped_refptr<base::SingleThreadTaskRunner> decoder_task_runner_;
-
-  // The current VA surface for decoding.
-  VASurfaceID va_surface_id_;
-  // The coded size associated with |va_surface_id_|.
-  gfx::Size coded_size_;
-  // The VA RT format associated with |va_surface_id_|.
-  unsigned int va_rt_format_;
-
-  // The WeakPtrFactory for |weak_this_|.
-  base::WeakPtrFactory<VaapiJpegDecodeAccelerator> weak_this_factory_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiJpegDecodeAccelerator);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_JPEG_DECODE_ACCELERATOR_H_
--- a/media/gpu/vaapi_jpeg_decoder.cc
+++ /dev/null
@@ -1,229 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_jpeg_decoder.h"
-
-#include <stddef.h>
-#include <string.h>
-
-#include "base/logging.h"
-#include "base/macros.h"
-#include "media/filters/jpeg_parser.h"
-
-namespace media {
-
-// VAAPI only support subset of JPEG profiles. This function determines a given
-// parsed JPEG result is supported or not.
-static bool IsVaapiSupportedJpeg(const JpegParseResult& jpeg) {
-  if (jpeg.frame_header.visible_width < 1 ||
-      jpeg.frame_header.visible_height < 1) {
-    DLOG(ERROR) << "width(" << jpeg.frame_header.visible_width
-                << ") and height(" << jpeg.frame_header.visible_height
-                << ") should be at least 1";
-    return false;
-  }
-
-  // Size 64k*64k is the maximum in the JPEG standard. VAAPI doesn't support
-  // resolutions larger than 16k*16k.
-  const int kMaxDimension = 16384;
-  if (jpeg.frame_header.coded_width > kMaxDimension ||
-      jpeg.frame_header.coded_height > kMaxDimension) {
-    DLOG(ERROR) << "VAAPI doesn't support size("
-                << jpeg.frame_header.coded_width << "*"
-                << jpeg.frame_header.coded_height << ") larger than "
-                << kMaxDimension << "*" << kMaxDimension;
-    return false;
-  }
-
-  if (jpeg.frame_header.num_components != 3) {
-    DLOG(ERROR) << "VAAPI doesn't support num_components("
-                << static_cast<int>(jpeg.frame_header.num_components)
-                << ") != 3";
-    return false;
-  }
-
-  if (jpeg.frame_header.components[0].horizontal_sampling_factor <
-          jpeg.frame_header.components[1].horizontal_sampling_factor ||
-      jpeg.frame_header.components[0].horizontal_sampling_factor <
-          jpeg.frame_header.components[2].horizontal_sampling_factor) {
-    DLOG(ERROR) << "VAAPI doesn't supports horizontal sampling factor of Y"
-                << " smaller than Cb and Cr";
-    return false;
-  }
-
-  if (jpeg.frame_header.components[0].vertical_sampling_factor <
-          jpeg.frame_header.components[1].vertical_sampling_factor ||
-      jpeg.frame_header.components[0].vertical_sampling_factor <
-          jpeg.frame_header.components[2].vertical_sampling_factor) {
-    DLOG(ERROR) << "VAAPI doesn't supports vertical sampling factor of Y"
-                << " smaller than Cb and Cr";
-    return false;
-  }
-
-  return true;
-}
-
-static void FillPictureParameters(
-    const JpegFrameHeader& frame_header,
-    VAPictureParameterBufferJPEGBaseline* pic_param) {
-  memset(pic_param, 0, sizeof(*pic_param));
-  pic_param->picture_width = frame_header.coded_width;
-  pic_param->picture_height = frame_header.coded_height;
-  pic_param->num_components = frame_header.num_components;
-
-  for (int i = 0; i < pic_param->num_components; i++) {
-    pic_param->components[i].component_id = frame_header.components[i].id;
-    pic_param->components[i].h_sampling_factor =
-        frame_header.components[i].horizontal_sampling_factor;
-    pic_param->components[i].v_sampling_factor =
-        frame_header.components[i].vertical_sampling_factor;
-    pic_param->components[i].quantiser_table_selector =
-        frame_header.components[i].quantization_table_selector;
-  }
-}
-
-static void FillIQMatrix(const JpegQuantizationTable* q_table,
-                         VAIQMatrixBufferJPEGBaseline* iq_matrix) {
-  memset(iq_matrix, 0, sizeof(*iq_matrix));
-  static_assert(kJpegMaxQuantizationTableNum ==
-                    arraysize(iq_matrix->load_quantiser_table),
-                "max number of quantization table mismatched");
-  for (size_t i = 0; i < kJpegMaxQuantizationTableNum; i++) {
-    if (!q_table[i].valid)
-      continue;
-    iq_matrix->load_quantiser_table[i] = 1;
-    static_assert(
-        arraysize(iq_matrix->quantiser_table[i]) == arraysize(q_table[i].value),
-        "number of quantization entries mismatched");
-    for (size_t j = 0; j < arraysize(q_table[i].value); j++)
-      iq_matrix->quantiser_table[i][j] = q_table[i].value[j];
-  }
-}
-
-static void FillHuffmanTable(const JpegHuffmanTable* dc_table,
-                             const JpegHuffmanTable* ac_table,
-                             VAHuffmanTableBufferJPEGBaseline* huffman_table) {
-  memset(huffman_table, 0, sizeof(*huffman_table));
-  // Use default huffman tables if not specified in header.
-  bool has_huffman_table = false;
-  for (size_t i = 0; i < kJpegMaxHuffmanTableNumBaseline; i++) {
-    if (dc_table[i].valid || ac_table[i].valid) {
-      has_huffman_table = true;
-      break;
-    }
-  }
-  if (!has_huffman_table) {
-    dc_table = kDefaultDcTable;
-    ac_table = kDefaultAcTable;
-  }
-
-  static_assert(kJpegMaxHuffmanTableNumBaseline ==
-                    arraysize(huffman_table->load_huffman_table),
-                "max number of huffman table mismatched");
-  static_assert(sizeof(huffman_table->huffman_table[0].num_dc_codes) ==
-                    sizeof(dc_table[0].code_length),
-                "size of huffman table code length mismatch");
-  static_assert(sizeof(huffman_table->huffman_table[0].dc_values[0]) ==
-                    sizeof(dc_table[0].code_value[0]),
-                "size of huffman table code value mismatch");
-  for (size_t i = 0; i < kJpegMaxHuffmanTableNumBaseline; i++) {
-    if (!dc_table[i].valid || !ac_table[i].valid)
-      continue;
-    huffman_table->load_huffman_table[i] = 1;
-
-    memcpy(huffman_table->huffman_table[i].num_dc_codes,
-           dc_table[i].code_length,
-           sizeof(huffman_table->huffman_table[i].num_dc_codes));
-    memcpy(huffman_table->huffman_table[i].dc_values, dc_table[i].code_value,
-           sizeof(huffman_table->huffman_table[i].dc_values));
-    memcpy(huffman_table->huffman_table[i].num_ac_codes,
-           ac_table[i].code_length,
-           sizeof(huffman_table->huffman_table[i].num_ac_codes));
-    memcpy(huffman_table->huffman_table[i].ac_values, ac_table[i].code_value,
-           sizeof(huffman_table->huffman_table[i].ac_values));
-  }
-}
-
-static void FillSliceParameters(
-    const JpegParseResult& parse_result,
-    VASliceParameterBufferJPEGBaseline* slice_param) {
-  memset(slice_param, 0, sizeof(*slice_param));
-  slice_param->slice_data_size = parse_result.data_size;
-  slice_param->slice_data_offset = 0;
-  slice_param->slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
-  slice_param->slice_horizontal_position = 0;
-  slice_param->slice_vertical_position = 0;
-  slice_param->num_components = parse_result.scan.num_components;
-  for (int i = 0; i < slice_param->num_components; i++) {
-    slice_param->components[i].component_selector =
-        parse_result.scan.components[i].component_selector;
-    slice_param->components[i].dc_table_selector =
-        parse_result.scan.components[i].dc_selector;
-    slice_param->components[i].ac_table_selector =
-        parse_result.scan.components[i].ac_selector;
-  }
-  slice_param->restart_interval = parse_result.restart_interval;
-
-  // Cast to int to prevent overflow.
-  int max_h_factor =
-      parse_result.frame_header.components[0].horizontal_sampling_factor;
-  int max_v_factor =
-      parse_result.frame_header.components[0].vertical_sampling_factor;
-  int mcu_cols = parse_result.frame_header.coded_width / (max_h_factor * 8);
-  DCHECK_GT(mcu_cols, 0);
-  int mcu_rows = parse_result.frame_header.coded_height / (max_v_factor * 8);
-  DCHECK_GT(mcu_rows, 0);
-  slice_param->num_mcus = mcu_rows * mcu_cols;
-}
-
-// static
-bool VaapiJpegDecoder::Decode(VaapiWrapper* vaapi_wrapper,
-                              const JpegParseResult& parse_result,
-                              VASurfaceID va_surface) {
-  DCHECK_NE(va_surface, VA_INVALID_SURFACE);
-  if (!IsVaapiSupportedJpeg(parse_result))
-    return false;
-
-  // Set picture parameters.
-  VAPictureParameterBufferJPEGBaseline pic_param;
-  FillPictureParameters(parse_result.frame_header, &pic_param);
-  if (!vaapi_wrapper->SubmitBuffer(VAPictureParameterBufferType,
-                                   sizeof(pic_param), &pic_param))
-    return false;
-
-  // Set quantization table.
-  VAIQMatrixBufferJPEGBaseline iq_matrix;
-  FillIQMatrix(parse_result.q_table, &iq_matrix);
-  if (!vaapi_wrapper->SubmitBuffer(VAIQMatrixBufferType, sizeof(iq_matrix),
-                                   &iq_matrix))
-    return false;
-
-  // Set huffman table.
-  VAHuffmanTableBufferJPEGBaseline huffman_table;
-  FillHuffmanTable(parse_result.dc_table, parse_result.ac_table,
-                   &huffman_table);
-  if (!vaapi_wrapper->SubmitBuffer(VAHuffmanTableBufferType,
-                                   sizeof(huffman_table), &huffman_table))
-    return false;
-
-  // Set slice parameters.
-  VASliceParameterBufferJPEGBaseline slice_param;
-  FillSliceParameters(parse_result, &slice_param);
-  if (!vaapi_wrapper->SubmitBuffer(VASliceParameterBufferType,
-                                   sizeof(slice_param), &slice_param))
-    return false;
-
-  // Set scan data.
-  if (!vaapi_wrapper->SubmitBuffer(VASliceDataBufferType,
-                                   parse_result.data_size,
-                                   const_cast<char*>(parse_result.data)))
-    return false;
-
-  if (!vaapi_wrapper->ExecuteAndDestroyPendingBuffers(va_surface))
-    return false;
-
-  return true;
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_jpeg_decoder.h
+++ /dev/null
@@ -1,43 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef MEDIA_GPU_VAAPI_JPEG_DECODER_H_
-#define MEDIA_GPU_VAAPI_JPEG_DECODER_H_
-
-#include "base/macros.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/vaapi_wrapper.h"
-
-namespace media {
-
-struct JpegParseResult;
-
-// A JPEG decoder that utilizes VA-API hardware video decode acceleration on
-// Intel systems. Provides functionality to allow plugging VAAPI HW
-// acceleration into the JpegDecodeAccelerator framework.
-//
-// Clients of this class are expected to manage VA surfaces created via
-// VaapiWrapper, parse JPEG picture via ParseJpegPicture, and then pass
-// them to this class.
-class MEDIA_GPU_EXPORT VaapiJpegDecoder {
- public:
-  // Decode a JPEG picture. It will fill VA-API parameters and call
-  // corresponding VA-API methods according to parsed JPEG result
-  // |parse_result|. Decoded data will be outputted to the given |va_surface|.
-  // Return false on failure.
-  // |vaapi_wrapper| should be initialized in kDecode mode with
-  // VAProfileJPEGBaseline profile.
-  // |va_surface| should be created with size at least as large as the picture
-  // size.
-  static bool Decode(VaapiWrapper* vaapi_wrapper,
-                     const JpegParseResult& parse_result,
-                     VASurfaceID va_surface);
-
- private:
-  DISALLOW_IMPLICIT_CONSTRUCTORS(VaapiJpegDecoder);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_JPEG_DECODER_H_
--- a/media/gpu/vaapi_jpeg_decoder_unittest.cc
+++ /dev/null
@@ -1,139 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include <stdint.h>
-#include <string.h>
-
-#include <string>
-
-// This has to be included first.
-// See http://code.google.com/p/googletest/issues/detail?id=371
-#include "testing/gtest/include/gtest/gtest.h"
-
-#include "base/at_exit.h"
-#include "base/bind.h"
-#include "base/files/file_util.h"
-#include "base/logging.h"
-#include "base/md5.h"
-#include "base/path_service.h"
-#include "base/strings/string_piece.h"
-#include "media/base/test_data_util.h"
-#include "media/base/video_frame.h"
-#include "media/filters/jpeg_parser.h"
-#include "media/gpu/vaapi_jpeg_decoder.h"
-
-namespace media {
-namespace {
-
-const char* kTestFilename = "pixel-1280x720.jpg";
-const char* kExpectedMd5Sum = "6e9e1716073c9a9a1282e3f0e0dab743";
-
-void LogOnError() {
-  LOG(FATAL) << "Oh noes! Decoder failed";
-}
-
-class VaapiJpegDecoderTest : public ::testing::Test {
- protected:
-  VaapiJpegDecoderTest() {}
-
-  void SetUp() override {
-    base::Closure report_error_cb = base::Bind(&LogOnError);
-    wrapper_ = VaapiWrapper::Create(VaapiWrapper::kDecode,
-                                    VAProfileJPEGBaseline, report_error_cb);
-    ASSERT_TRUE(wrapper_);
-
-    base::FilePath input_file = GetTestDataFilePath(kTestFilename);
-
-    ASSERT_TRUE(base::ReadFileToString(input_file, &jpeg_data_))
-        << "failed to read input data from " << input_file.value();
-  }
-
-  void TearDown() override { wrapper_ = nullptr; }
-
-  bool VerifyDecode(const JpegParseResult& parse_result,
-                    const std::string& md5sum);
-
- protected:
-  scoped_refptr<VaapiWrapper> wrapper_;
-  std::string jpeg_data_;
-};
-
-bool VaapiJpegDecoderTest::VerifyDecode(const JpegParseResult& parse_result,
-                                        const std::string& expected_md5sum) {
-  gfx::Size size(parse_result.frame_header.coded_width,
-                 parse_result.frame_header.coded_height);
-
-  std::vector<VASurfaceID> va_surfaces;
-  if (!wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, size, 1, &va_surfaces))
-    return false;
-
-  if (!VaapiJpegDecoder::Decode(wrapper_.get(), parse_result, va_surfaces[0])) {
-    LOG(ERROR) << "Decode failed";
-    return false;
-  }
-
-  VAImage image;
-  VAImageFormat format;
-  const uint32_t kI420Fourcc = VA_FOURCC('I', '4', '2', '0');
-  memset(&image, 0, sizeof(image));
-  memset(&format, 0, sizeof(format));
-  format.fourcc = kI420Fourcc;
-  format.byte_order = VA_LSB_FIRST;
-  format.bits_per_pixel = 12;  // 12 for I420
-
-  void* mem;
-  if (!wrapper_->GetVaImage(va_surfaces[0], &format, size, &image, &mem)) {
-    LOG(ERROR) << "Cannot get VAImage";
-    return false;
-  }
-  EXPECT_EQ(kI420Fourcc, image.format.fourcc);
-
-  base::StringPiece result(reinterpret_cast<const char*>(mem),
-                           VideoFrame::AllocationSize(PIXEL_FORMAT_I420, size));
-  EXPECT_EQ(expected_md5sum, base::MD5String(result));
-
-  wrapper_->ReturnVaImage(&image);
-
-  return true;
-}
-
-TEST_F(VaapiJpegDecoderTest, DecodeSuccess) {
-  JpegParseResult parse_result;
-  ASSERT_TRUE(
-      ParseJpegPicture(reinterpret_cast<const uint8_t*>(jpeg_data_.data()),
-                       jpeg_data_.size(), &parse_result));
-
-  EXPECT_TRUE(VerifyDecode(parse_result, kExpectedMd5Sum));
-}
-
-TEST_F(VaapiJpegDecoderTest, DecodeFail) {
-  JpegParseResult parse_result;
-  ASSERT_TRUE(
-      ParseJpegPicture(reinterpret_cast<const uint8_t*>(jpeg_data_.data()),
-                       jpeg_data_.size(), &parse_result));
-
-  // Not supported by VAAPI.
-  parse_result.frame_header.num_components = 1;
-  parse_result.scan.num_components = 1;
-
-  gfx::Size size(parse_result.frame_header.coded_width,
-                 parse_result.frame_header.coded_height);
-
-  std::vector<VASurfaceID> va_surfaces;
-  ASSERT_TRUE(
-      wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, size, 1, &va_surfaces));
-
-  EXPECT_FALSE(
-      VaapiJpegDecoder::Decode(wrapper_.get(), parse_result, va_surfaces[0]));
-}
-
-}  // namespace
-}  // namespace media
-
-int main(int argc, char** argv) {
-  testing::InitGoogleTest(&argc, argv);
-  base::AtExitManager exit_manager;
-  media::VaapiWrapper::PreSandboxInitialization();
-  return RUN_ALL_TESTS();
-}
--- a/media/gpu/vaapi_jpeg_encode_accelerator.cc
+++ /dev/null
@@ -1,268 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_jpeg_encode_accelerator.h"
-
-#include <stddef.h>
-
-#include <memory>
-#include <utility>
-
-#include "base/bind.h"
-#include "base/logging.h"
-#include "base/metrics/histogram_macros.h"
-#include "base/sequence_checker.h"
-#include "base/task_scheduler/post_task.h"
-#include "base/threading/thread_task_runner_handle.h"
-#include "base/trace_event/trace_event.h"
-#include "media/base/bind_to_current_loop.h"
-#include "media/base/video_frame.h"
-#include "media/gpu/vaapi_jpeg_encoder.h"
-
-namespace media {
-
-namespace {
-
-// UMA results that the VaapiJpegEncodeAccelerator class reports.
-// These values are persisted to logs, and should therefore never be renumbered
-// nor reused.
-enum VAJEAEncoderResult {
-  VAAPI_SUCCESS = 0,
-  VAAPI_ERROR,
-  VAJEA_ENCODER_RESULT_MAX = VAAPI_ERROR,
-};
-
-static void ReportToUMA(VAJEAEncoderResult result) {
-  UMA_HISTOGRAM_ENUMERATION("Media.VAJEA.EncoderResult", result,
-                            VAJEAEncoderResult::VAJEA_ENCODER_RESULT_MAX + 1);
-}
-}  // namespace
-
-VaapiJpegEncodeAccelerator::EncodeRequest::EncodeRequest(
-    scoped_refptr<media::VideoFrame> video_frame,
-    std::unique_ptr<SharedMemoryRegion> shm,
-    int quality)
-    : video_frame(std::move(video_frame)),
-      shm(std::move(shm)),
-      quality(quality) {}
-
-VaapiJpegEncodeAccelerator::EncodeRequest::~EncodeRequest() {}
-
-class VaapiJpegEncodeAccelerator::Encoder {
- public:
-  Encoder(scoped_refptr<VaapiWrapper> vaapi_wrapper,
-          base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb,
-          base::RepeatingCallback<void(int, Status)> notify_error_cb);
-  ~Encoder();
-
-  // Processes one encode |request|.
-  void EncodeTask(std::unique_ptr<EncodeRequest> request);
-
- private:
-  // |cached_output_buffer_id_| is the last allocated VABuffer during
-  // EncodeTask() and |cached_output_buffer_size_| is the size of it.
-  // If the next call to EncodeTask() does not require a buffer bigger than
-  // |cached_output_buffer_size_|, |cached_output_buffer_id_| will be reused.
-  size_t cached_output_buffer_size_;
-  VABufferID cached_output_buffer_id_;
-
-  std::unique_ptr<VaapiJpegEncoder> jpeg_encoder_;
-  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
-
-  base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb_;
-  base::RepeatingCallback<void(int, Status)> notify_error_cb_;
-
-  SEQUENCE_CHECKER(sequence_checker_);
-
-  DISALLOW_COPY_AND_ASSIGN(Encoder);
-};
-
-VaapiJpegEncodeAccelerator::Encoder::Encoder(
-    scoped_refptr<VaapiWrapper> vaapi_wrapper,
-    base::RepeatingCallback<void(int, size_t)> video_frame_ready_cb,
-    base::RepeatingCallback<void(int, Status)> notify_error_cb)
-    : cached_output_buffer_size_(0),
-      jpeg_encoder_(new VaapiJpegEncoder(vaapi_wrapper)),
-      vaapi_wrapper_(std::move(vaapi_wrapper)),
-      video_frame_ready_cb_(std::move(video_frame_ready_cb)),
-      notify_error_cb_(std::move(notify_error_cb)) {
-  DETACH_FROM_SEQUENCE(sequence_checker_);
-}
-
-VaapiJpegEncodeAccelerator::Encoder::~Encoder() {
-  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
-}
-
-void VaapiJpegEncodeAccelerator::Encoder::EncodeTask(
-    std::unique_ptr<EncodeRequest> request) {
-  TRACE_EVENT0("jpeg", "EncodeTask");
-  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
-
-  const int video_frame_id = request->video_frame->unique_id();
-  gfx::Size input_size = request->video_frame->coded_size();
-  std::vector<VASurfaceID> va_surfaces;
-  if (!vaapi_wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, input_size, 1,
-                                      &va_surfaces)) {
-    VLOG(1) << "Failed to create VA surface";
-    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
-    return;
-  }
-  VASurfaceID va_surface_id = va_surfaces[0];
-
-  if (!vaapi_wrapper_->UploadVideoFrameToSurface(request->video_frame,
-                                                 va_surface_id)) {
-    VLOG(1) << "Failed to upload video frame to VA surface";
-    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
-    return;
-  }
-
-  // Create output buffer for encoding result.
-  size_t max_coded_buffer_size =
-      VaapiJpegEncoder::GetMaxCodedBufferSize(input_size);
-  if (max_coded_buffer_size > cached_output_buffer_size_) {
-    vaapi_wrapper_->DestroyCodedBuffers();
-    cached_output_buffer_size_ = 0;
-
-    VABufferID output_buffer_id;
-    if (!vaapi_wrapper_->CreateCodedBuffer(max_coded_buffer_size,
-                                           &output_buffer_id)) {
-      VLOG(1) << "Failed to create VA buffer for encoding output";
-      notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
-      return;
-    }
-    cached_output_buffer_size_ = max_coded_buffer_size;
-    cached_output_buffer_id_ = output_buffer_id;
-  }
-
-  if (!jpeg_encoder_->Encode(input_size, request->quality, va_surface_id,
-                             cached_output_buffer_id_)) {
-    VLOG(1) << "Encode JPEG failed";
-    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
-    return;
-  }
-
-  // Get the encoded output. DownloadFromCodedBuffer() is a blocking call. It
-  // would wait until encoding is finished.
-  size_t encoded_size = 0;
-  if (!vaapi_wrapper_->DownloadFromCodedBuffer(
-          cached_output_buffer_id_, va_surface_id,
-          static_cast<uint8_t*>(request->shm->memory()), request->shm->size(),
-          &encoded_size)) {
-    VLOG(1) << "Failed to retrieve output image from VA coded buffer";
-    notify_error_cb_.Run(video_frame_id, PLATFORM_FAILURE);
-  }
-
-  video_frame_ready_cb_.Run(request->video_frame->unique_id(), encoded_size);
-}
-
-VaapiJpegEncodeAccelerator::VaapiJpegEncodeAccelerator(
-    scoped_refptr<base::SingleThreadTaskRunner> io_task_runner)
-    : task_runner_(base::ThreadTaskRunnerHandle::Get()),
-      io_task_runner_(std::move(io_task_runner)),
-      weak_this_factory_(this) {
-  weak_this_ = weak_this_factory_.GetWeakPtr();
-}
-
-VaapiJpegEncodeAccelerator::~VaapiJpegEncodeAccelerator() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  DVLOG(1) << "Destroying VaapiJpegEncodeAccelerator";
-
-  weak_this_factory_.InvalidateWeakPtrs();
-  encoder_task_runner_->DeleteSoon(FROM_HERE, std::move(encoder_));
-}
-
-void VaapiJpegEncodeAccelerator::NotifyError(int video_frame_id,
-                                             Status status) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  DLOG(ERROR) << "Notifying error: " << status;
-  DCHECK(client_);
-  client_->NotifyError(video_frame_id, status);
-}
-
-void VaapiJpegEncodeAccelerator::VideoFrameReady(int video_frame_id,
-                                                 size_t encoded_picture_size) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  ReportToUMA(VAJEAEncoderResult::VAAPI_SUCCESS);
-
-  client_->VideoFrameReady(video_frame_id, encoded_picture_size);
-}
-
-JpegEncodeAccelerator::Status VaapiJpegEncodeAccelerator::Initialize(
-    JpegEncodeAccelerator::Client* client) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  if (!VaapiWrapper::IsJpegEncodeSupported()) {
-    return HW_JPEG_ENCODE_NOT_SUPPORTED;
-  }
-
-  client_ = client;
-  scoped_refptr<VaapiWrapper> vaapi_wrapper = VaapiWrapper::Create(
-      VaapiWrapper::kEncode, VAProfileJPEGBaseline,
-      base::Bind(&ReportToUMA, VAJEAEncoderResult::VAAPI_ERROR));
-
-  if (!vaapi_wrapper) {
-    VLOG(1) << "Failed initializing VAAPI";
-    return PLATFORM_FAILURE;
-  }
-
-  encoder_task_runner_ = base::CreateSingleThreadTaskRunnerWithTraits(
-      {base::MayBlock(), base::TaskPriority::USER_BLOCKING});
-  if (!encoder_task_runner_) {
-    VLOG(1) << "Failed to create encoder task runner.";
-    return THREAD_CREATION_FAILED;
-  }
-
-  encoder_ = std::make_unique<Encoder>(
-      std::move(vaapi_wrapper),
-      BindToCurrentLoop(base::BindRepeating(
-          &VaapiJpegEncodeAccelerator::VideoFrameReady, weak_this_)),
-      BindToCurrentLoop(base::BindRepeating(
-          &VaapiJpegEncodeAccelerator::NotifyError, weak_this_)));
-
-  return ENCODE_OK;
-}
-
-size_t VaapiJpegEncodeAccelerator::GetMaxCodedBufferSize(
-    const gfx::Size& picture_size) {
-  return VaapiJpegEncoder::GetMaxCodedBufferSize(picture_size);
-}
-
-void VaapiJpegEncodeAccelerator::Encode(
-    scoped_refptr<media::VideoFrame> video_frame,
-    int quality,
-    const BitstreamBuffer& bitstream_buffer) {
-  DCHECK(io_task_runner_->BelongsToCurrentThread());
-
-  int video_frame_id = video_frame->unique_id();
-  TRACE_EVENT1("jpeg", "Encode", "input_id", video_frame_id);
-
-  // TODO(shenghao): support other YUV formats.
-  if (video_frame->format() != VideoPixelFormat::PIXEL_FORMAT_I420) {
-    VLOG(1) << "Unsupported input format: " << video_frame->format();
-    task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiJpegEncodeAccelerator::NotifyError,
-                              weak_this_, video_frame_id, INVALID_ARGUMENT));
-    return;
-  }
-
-  // SharedMemoryRegion will take ownership of the |bitstream_buffer.handle()|.
-  auto shm = std::make_unique<SharedMemoryRegion>(bitstream_buffer, false);
-  if (!shm->Map()) {
-    VLOG(1) << "Failed to map output buffer";
-    task_runner_->PostTask(
-        FROM_HERE,
-        base::Bind(&VaapiJpegEncodeAccelerator::NotifyError, weak_this_,
-                   video_frame_id, INACCESSIBLE_OUTPUT_BUFFER));
-    return;
-  }
-
-  auto request = std::make_unique<EncodeRequest>(std::move(video_frame),
-                                                 std::move(shm), quality);
-  encoder_task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(&VaapiJpegEncodeAccelerator::Encoder::EncodeTask,
-                 base::Unretained(encoder_.get()), base::Passed(&request)));
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_jpeg_encode_accelerator.h
+++ /dev/null
@@ -1,96 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef MEDIA_GPU_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
-#define MEDIA_GPU_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
-
-#include <memory>
-
-#include "base/macros.h"
-#include "base/memory/weak_ptr.h"
-#include "base/single_thread_task_runner.h"
-#include "media/base/bitstream_buffer.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/shared_memory_region.h"
-#include "media/gpu/vaapi_wrapper.h"
-#include "media/video/jpeg_encode_accelerator.h"
-
-namespace media {
-
-// Class to provide JPEG encode acceleration for Intel systems with hardware
-// support for it, and on which libva is available.
-// Encoding tasks are performed in a separate encoding thread.
-//
-// Threading/life-cycle: this object is created & destroyed on the GPU
-// ChildThread.  Methods in nested class Encoder are called on the encoder
-// thread which is stopped during destructor, so the callbacks bound with
-// a weak this can be run on the encoder thread because it can assume
-// VaapiJpegEncodeAccelerator is still alive.
-class MEDIA_GPU_EXPORT VaapiJpegEncodeAccelerator
-    : public JpegEncodeAccelerator {
- public:
-  explicit VaapiJpegEncodeAccelerator(
-      scoped_refptr<base::SingleThreadTaskRunner> io_task_runner);
-  ~VaapiJpegEncodeAccelerator() override;
-
-  // JpegEncodeAccelerator implementation.
-  Status Initialize(JpegEncodeAccelerator::Client* client) override;
-  size_t GetMaxCodedBufferSize(const gfx::Size& picture_size) override;
-
-  // Currently only I420 format is supported for |video_frame|.
-  void Encode(scoped_refptr<media::VideoFrame> video_frame,
-              int quality,
-              const BitstreamBuffer& bitstream_buffer) override;
-
- private:
-  // An input video frame and the corresponding output buffer awaiting
-  // consumption, provided by the client.
-  struct EncodeRequest {
-    EncodeRequest(scoped_refptr<media::VideoFrame> video_frame,
-                  std::unique_ptr<SharedMemoryRegion> shm,
-                  int quality);
-    ~EncodeRequest();
-
-    scoped_refptr<media::VideoFrame> video_frame;
-    std::unique_ptr<SharedMemoryRegion> shm;
-    int quality;
-
-    DISALLOW_COPY_AND_ASSIGN(EncodeRequest);
-  };
-
-  // The Encoder class is a collection of methods that run on
-  // |encoder_task_runner_|.
-  class Encoder;
-
-  // Notifies the client that an error has occurred and encoding cannot
-  // continue.
-  void NotifyError(int video_frame_id, Status status);
-
-  void VideoFrameReady(int video_frame_id, size_t encoded_picture_size);
-
-  // ChildThread's task runner.
-  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
-
-  // GPU IO task runner.
-  scoped_refptr<base::SingleThreadTaskRunner> io_task_runner_;
-
-  // The client of this class.
-  Client* client_;
-
-  // Use this to post tasks to encoder thread.
-  scoped_refptr<base::SingleThreadTaskRunner> encoder_task_runner_;
-
-  std::unique_ptr<Encoder> encoder_;
-
-  // |weak_this_| is used to post tasks from |encoder_task_runner_| to
-  // |task_runner_|.
-  base::WeakPtr<VaapiJpegEncodeAccelerator> weak_this_;
-  base::WeakPtrFactory<VaapiJpegEncodeAccelerator> weak_this_factory_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiJpegEncodeAccelerator);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_JPEG_ENCODE_ACCELERATOR_H_
--- a/media/gpu/vaapi_jpeg_encoder.cc
+++ /dev/null
@@ -1,427 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_jpeg_encoder.h"
-
-#include <stddef.h>
-#include <string.h>
-#include <array>
-
-#include "base/logging.h"
-#include "base/macros.h"
-#include "base/numerics/safe_conversions.h"
-#include "media/filters/jpeg_parser.h"
-#include "media/gpu/vaapi_wrapper.h"
-
-#define ARRAY_MEMCPY_CHECKED(to, from)                               \
-  do {                                                               \
-    static_assert(sizeof(to) == sizeof(from),                        \
-                  #from " and " #to " arrays must be of same size"); \
-    memcpy(to, from, sizeof(to));                                    \
-  } while (0)
-
-namespace media {
-
-namespace {
-
-// JPEG header only uses 2 bytes to represent width and height.
-const int kMaxDimension = 65535;
-const size_t kDctSize2 = 64;
-const size_t kNumDcRunSizeBits = 16;
-const size_t kNumAcRunSizeBits = 16;
-const size_t kNumDcCodeWordsHuffVal = 12;
-const size_t kNumAcCodeWordsHuffVal = 162;
-const size_t kJpegHeaderSize = 83 + (kDctSize2 * 2) + (kNumDcRunSizeBits * 2) +
-                               (kNumDcCodeWordsHuffVal * 2) +
-                               (kNumAcRunSizeBits * 2) +
-                               (kNumAcCodeWordsHuffVal * 2);
-
-const uint8_t kZigZag8x8[64] = {
-    0,  1,  8,  16, 9,  2,  3,  10, 17, 24, 32, 25, 18, 11, 4,  5,
-    12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6,  7,  14, 21, 28,
-    35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,
-    58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63};
-
-const JpegQuantizationTable kDefaultQuantTable[2] = {
-    // Table K.1 Luminance quantization table values.
-    {
-        true,
-        {16, 11, 10, 16, 24,  40,  51,  61,  12, 12, 14, 19, 26,  58,  60,  55,
-         14, 13, 16, 24, 40,  57,  69,  56,  14, 17, 22, 29, 51,  87,  80,  62,
-         18, 22, 37, 56, 68,  109, 103, 77,  24, 35, 55, 64, 81,  104, 113, 92,
-         49, 64, 78, 87, 103, 121, 120, 101, 72, 92, 95, 98, 112, 100, 103, 99},
-    },
-    // Table K.2 Chrominance quantization table values.
-    {
-        true,
-        {17, 18, 24, 47, 99, 99, 99, 99, 18, 21, 26, 66, 99, 99, 99, 99,
-         24, 26, 56, 99, 99, 99, 99, 99, 47, 66, 99, 99, 99, 99, 99, 99,
-         99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99,
-         99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99},
-    },
-};
-
-using JPEGHeader = uint8_t[kJpegHeaderSize];
-
-void FillPictureParameters(const gfx::Size& input_size,
-                           int quality,
-                           VABufferID output_buffer_id,
-                           VAEncPictureParameterBufferJPEG* pic_param) {
-  pic_param->picture_width = input_size.width();
-  pic_param->picture_height = input_size.height();
-  pic_param->num_components = 3;
-
-  // Output buffer.
-  pic_param->coded_buf = output_buffer_id;
-  pic_param->quality = quality;
-  // Profile = Baseline.
-  pic_param->pic_flags.bits.profile = 0;
-  // Sequential encoding.
-  pic_param->pic_flags.bits.progressive = 0;
-  // Uses Huffman coding.
-  pic_param->pic_flags.bits.huffman = 1;
-  // Input format is interleaved (YUV).
-  pic_param->pic_flags.bits.interleaved = 0;
-  // Non-differential Encoding.
-  pic_param->pic_flags.bits.differential = 0;
-  // Only 8 bit sample depth is currently supported.
-  pic_param->sample_bit_depth = 8;
-  pic_param->num_scan = 1;
-}
-
-void FillQMatrix(VAQMatrixBufferJPEG* q_matrix) {
-  // Fill the raw, unscaled quantization tables for libva. The VAAPI driver is
-  // responsible for scaling the quantization tables based on picture
-  // parameter quality.
-  const JpegQuantizationTable& luminance = kDefaultQuantTable[0];
-  static_assert(
-      arraysize(luminance.value) == arraysize(q_matrix->lum_quantiser_matrix),
-      "Luminance quantization table size mismatch.");
-  static_assert(arraysize(kZigZag8x8) == arraysize(luminance.value),
-                "Luminance quantization table size mismatch.");
-  q_matrix->load_lum_quantiser_matrix = 1;
-  for (size_t i = 0; i < arraysize(kZigZag8x8); i++) {
-    q_matrix->lum_quantiser_matrix[i] = luminance.value[kZigZag8x8[i]];
-  }
-
-  const JpegQuantizationTable& chrominance = kDefaultQuantTable[1];
-  static_assert(arraysize(chrominance.value) ==
-                    arraysize(q_matrix->chroma_quantiser_matrix),
-                "Chrominance quantization table size mismatch.");
-  static_assert(arraysize(kZigZag8x8) == arraysize(chrominance.value),
-                "Chrominance quantization table size mismatch.");
-  q_matrix->load_chroma_quantiser_matrix = 1;
-  for (size_t i = 0; i < arraysize(kZigZag8x8); i++) {
-    q_matrix->chroma_quantiser_matrix[i] = chrominance.value[kZigZag8x8[i]];
-  }
-}
-
-void FillHuffmanTableParameters(
-    VAHuffmanTableBufferJPEGBaseline* huff_table_param) {
-  static_assert(arraysize(kDefaultDcTable) == arraysize(kDefaultAcTable),
-                "DC table and AC table size mismatch.");
-  static_assert(
-      arraysize(kDefaultDcTable) == arraysize(huff_table_param->huffman_table),
-      "DC table and destination table size mismatch.");
-
-  for (size_t i = 0; i < arraysize(kDefaultDcTable); ++i) {
-    const JpegHuffmanTable& dcTable = kDefaultDcTable[i];
-    const JpegHuffmanTable& acTable = kDefaultAcTable[i];
-    huff_table_param->load_huffman_table[i] = true;
-
-    // Load DC Table.
-    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].num_dc_codes,
-                         dcTable.code_length);
-    // |code_values| of JpegHuffmanTable needs to hold DC and AC code values
-    // so it has different size than
-    // |huff_table_param->huffman_table[i].dc_values|. Therefore we can't use
-    // ARRAY_MEMCPY_CHECKED() here.
-    static_assert(arraysize(huff_table_param->huffman_table[i].dc_values) <=
-                      arraysize(dcTable.code_value),
-                  "DC table code value array too small.");
-    memcpy(huff_table_param->huffman_table[i].dc_values, &dcTable.code_value[0],
-           sizeof(huff_table_param->huffman_table[i].dc_values));
-
-    // Load AC Table.
-    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].num_ac_codes,
-                         acTable.code_length);
-    ARRAY_MEMCPY_CHECKED(huff_table_param->huffman_table[i].ac_values,
-                         acTable.code_value);
-
-    memset(huff_table_param->huffman_table[i].pad, 0,
-           sizeof(huff_table_param->huffman_table[i].pad));
-  }
-}
-
-void FillSliceParameters(VAEncSliceParameterBufferJPEG* slice_param) {
-  slice_param->restart_interval = 0;
-  slice_param->num_components = 3;
-
-  slice_param->components[0].component_selector = 1;
-  slice_param->components[0].dc_table_selector = 0;
-  slice_param->components[0].ac_table_selector = 0;
-
-  slice_param->components[1].component_selector = 2;
-  slice_param->components[1].dc_table_selector = 1;
-  slice_param->components[1].ac_table_selector = 1;
-
-  slice_param->components[2].component_selector = 3;
-  slice_param->components[2].dc_table_selector = 1;
-  slice_param->components[2].ac_table_selector = 1;
-}
-
-size_t FillJpegHeader(const gfx::Size& input_size,
-                      int quality,
-                      JPEGHeader& header) {
-  unsigned int width = input_size.width();
-  unsigned int height = input_size.height();
-
-  size_t idx = 0;
-
-  // Start Of Input.
-  static const uint8_t kSOI[] = {0xFF, JPEG_SOI};
-  memcpy(header, kSOI, sizeof(kSOI));
-  idx += sizeof(kSOI);
-
-  // Application Segment - JFIF standard 1.01.
-  // TODO(shenghao): Use Exif (JPEG_APP1) instead.
-  static const uint8_t kAppSegment[] = {
-      0xFF, JPEG_APP0, 0x00,
-      0x10,  // Segment length:16 (2-byte).
-      0x4A,  // J
-      0x46,  // F
-      0x49,  // I
-      0x46,  // F
-      0x00,  // 0
-      0x01,  // Major version.
-      0x01,  // Minor version.
-      0x01,  // Density units 0:no units, 1:pixels per inch,
-             // 2: pixels per cm.
-      0x00,
-      0x48,  // X density (2-byte).
-      0x00,
-      0x48,  // Y density (2-byte).
-      0x00,  // Thumbnail width.
-      0x00   // Thumbnail height.
-  };
-  memcpy(header + idx, kAppSegment, sizeof(kAppSegment));
-  idx += sizeof(kAppSegment);
-
-  if (quality <= 0) {
-    quality = 1;
-  }
-
-  // Normalize quality factor.
-  // Unlike VAQMatrixBufferJPEG, we have to scale quantization table in JPEG
-  // header by ourselves.
-  uint32_t quality_normalized = base::saturated_cast<uint32_t>(
-      (quality < 50) ? (5000 / quality) : (200 - (quality * 2)));
-
-  // Quantization Tables.
-  for (size_t i = 0; i < 2; ++i) {
-    const uint8_t kQuantSegment[] = {
-        0xFF, JPEG_DQT, 0x00,
-        0x03 + kDctSize2,        // Segment length:67 (2-byte).
-        static_cast<uint8_t>(i)  // Precision (4-bit high) = 0,
-                                 // Index (4-bit low) = i.
-    };
-    memcpy(header + idx, kQuantSegment, sizeof(kQuantSegment));
-    idx += sizeof(kQuantSegment);
-
-    const JpegQuantizationTable& quant_table = kDefaultQuantTable[i];
-    for (size_t j = 0; j < kDctSize2; ++j) {
-      uint32_t scaled_quant_value =
-          (quant_table.value[kZigZag8x8[j]] * quality_normalized) / 100;
-      scaled_quant_value = std::min(255u, std::max(1u, scaled_quant_value));
-      header[idx++] = static_cast<uint8_t>(scaled_quant_value);
-    }
-  }
-
-  // Start of Frame - Baseline.
-  const uint8_t kStartOfFrame[] = {
-      0xFF,
-      JPEG_SOF0,  // Baseline.
-      0x00,
-      0x11,  // Segment length:17 (2-byte).
-      8,     // Data precision.
-      static_cast<uint8_t>((height >> 8) & 0xFF),
-      static_cast<uint8_t>(height & 0xFF),
-      static_cast<uint8_t>((width >> 8) & 0xFF),
-      static_cast<uint8_t>(width & 0xFF),
-      0x03,  // Number of Components.
-  };
-  memcpy(header + idx, kStartOfFrame, sizeof(kStartOfFrame));
-  idx += sizeof(kStartOfFrame);
-  for (uint8_t i = 0; i < 3; ++i) {
-    // These are the values for U and V planes.
-    uint8_t h_sample_factor = 1;
-    uint8_t v_sample_factor = 1;
-    uint8_t quant_table_number = 1;
-    if (!i) {
-      // These are the values for Y plane.
-      h_sample_factor = 2;
-      v_sample_factor = 2;
-      quant_table_number = 0;
-    }
-
-    header[idx++] = i + 1;
-    // Horizontal Sample Factor (4-bit high),
-    // Vertical Sample Factor (4-bit low).
-    header[idx++] = (h_sample_factor << 4) | v_sample_factor;
-    header[idx++] = quant_table_number;
-  }
-
-  static const uint8_t kDcSegment[] = {
-      0xFF, JPEG_DHT, 0x00,
-      0x1F,  // Segment length:31 (2-byte).
-  };
-  static const uint8_t kAcSegment[] = {
-      0xFF, JPEG_DHT, 0x00,
-      0xB5,  // Segment length:181 (2-byte).
-  };
-
-  // Huffman Tables.
-  for (size_t i = 0; i < 2; ++i) {
-    // DC Table.
-    memcpy(header + idx, kDcSegment, sizeof(kDcSegment));
-    idx += sizeof(kDcSegment);
-
-    // Type (4-bit high) = 0:DC, Index (4-bit low).
-    header[idx++] = static_cast<uint8_t>(i);
-
-    const JpegHuffmanTable& dcTable = kDefaultDcTable[i];
-    for (size_t j = 0; j < kNumDcRunSizeBits; ++j)
-      header[idx++] = dcTable.code_length[j];
-    for (size_t j = 0; j < kNumDcCodeWordsHuffVal; ++j)
-      header[idx++] = dcTable.code_value[j];
-
-    // AC Table.
-    memcpy(header + idx, kAcSegment, sizeof(kAcSegment));
-    idx += sizeof(kAcSegment);
-
-    // Type (4-bit high) = 1:AC, Index (4-bit low).
-    header[idx++] = 0x10 | static_cast<uint8_t>(i);
-
-    const JpegHuffmanTable& acTable = kDefaultAcTable[i];
-    for (size_t j = 0; j < kNumAcRunSizeBits; ++j)
-      header[idx++] = acTable.code_length[j];
-    for (size_t j = 0; j < kNumAcCodeWordsHuffVal; ++j)
-      header[idx++] = acTable.code_value[j];
-  }
-
-  // Start of Scan.
-  static const uint8_t kStartOfScan[] = {
-      0xFF, JPEG_SOS, 0x00,
-      0x0C,  // Segment Length:12 (2-byte).
-      0x03   // Number of components in scan.
-  };
-  memcpy(header + idx, kStartOfScan, sizeof(kStartOfScan));
-  idx += sizeof(kStartOfScan);
-
-  for (uint8_t i = 0; i < 3; ++i) {
-    uint8_t dc_table_number = 1;
-    uint8_t ac_table_number = 1;
-    if (!i) {
-      dc_table_number = 0;
-      ac_table_number = 0;
-    }
-
-    header[idx++] = i + 1;
-    // DC Table Selector (4-bit high), AC Table Selector (4-bit low).
-    header[idx++] = (dc_table_number << 4) | ac_table_number;
-  }
-  header[idx++] = 0x00;  // 0 for Baseline.
-  header[idx++] = 0x3F;  // 63 for Baseline.
-  header[idx++] = 0x00;  // 0 for Baseline.
-
-  return idx << 3;
-}
-
-}  // namespace
-
-VaapiJpegEncoder::VaapiJpegEncoder(scoped_refptr<VaapiWrapper> vaapi_wrapper)
-    : vaapi_wrapper_(vaapi_wrapper),
-      q_matrix_cached_(nullptr),
-      huff_table_param_cached_(nullptr),
-      slice_param_cached_(nullptr) {}
-
-VaapiJpegEncoder::~VaapiJpegEncoder() {}
-
-size_t VaapiJpegEncoder::GetMaxCodedBufferSize(const gfx::Size& size) {
-  return size.GetArea() * 3 / 2 + kJpegHeaderSize;
-}
-
-bool VaapiJpegEncoder::Encode(const gfx::Size& input_size,
-                              int quality,
-                              VASurfaceID surface_id,
-                              VABufferID output_buffer_id) {
-  DCHECK_NE(surface_id, VA_INVALID_SURFACE);
-
-  if (input_size.width() > kMaxDimension ||
-      input_size.height() > kMaxDimension) {
-    return false;
-  }
-
-  // Set picture parameters.
-  VAEncPictureParameterBufferJPEG pic_param;
-  FillPictureParameters(input_size, quality, output_buffer_id, &pic_param);
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPictureParameterBufferType,
-                                    sizeof(pic_param), &pic_param)) {
-    return false;
-  }
-
-  if (!q_matrix_cached_) {
-    q_matrix_cached_.reset(new VAQMatrixBufferJPEG());
-    FillQMatrix(q_matrix_cached_.get());
-  }
-  if (!vaapi_wrapper_->SubmitBuffer(VAQMatrixBufferType,
-                                    sizeof(*q_matrix_cached_),
-                                    q_matrix_cached_.get())) {
-    return false;
-  }
-
-  if (!huff_table_param_cached_) {
-    huff_table_param_cached_.reset(new VAHuffmanTableBufferJPEGBaseline());
-    FillHuffmanTableParameters(huff_table_param_cached_.get());
-  }
-  if (!vaapi_wrapper_->SubmitBuffer(VAHuffmanTableBufferType,
-                                    sizeof(*huff_table_param_cached_),
-                                    huff_table_param_cached_.get())) {
-    return false;
-  }
-
-  // Set slice parameters.
-  if (!slice_param_cached_) {
-    slice_param_cached_.reset(new VAEncSliceParameterBufferJPEG());
-    FillSliceParameters(slice_param_cached_.get());
-  }
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncSliceParameterBufferType,
-                                    sizeof(*slice_param_cached_),
-                                    slice_param_cached_.get())) {
-    return false;
-  }
-
-  JPEGHeader header_data;
-  size_t length_in_bits = FillJpegHeader(input_size, quality, header_data);
-
-  VAEncPackedHeaderParameterBuffer header_param;
-  memset(&header_param, 0, sizeof(header_param));
-  header_param.type = VAEncPackedHeaderRawData;
-  header_param.bit_length = length_in_bits;
-  header_param.has_emulation_bytes = 0;
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
-                                    sizeof(header_param), &header_param)) {
-    return false;
-  }
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
-                                    (length_in_bits + 7) / 8, header_data)) {
-    return false;
-  }
-
-  // Submit the |surface_id| which contains input YUV frame and begin encoding.
-  return vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(surface_id);
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_jpeg_encoder.h
+++ /dev/null
@@ -1,65 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef MEDIA_GPU_VAAPI_JPEG_ENCODER_H_
-#define MEDIA_GPU_VAAPI_JPEG_ENCODER_H_
-
-#include <va/va.h>
-#include <memory>
-
-#include "base/macros.h"
-#include "base/memory/scoped_refptr.h"
-#include "media/gpu/media_gpu_export.h"
-#include "ui/gfx/geometry/size.h"
-
-namespace media {
-
-class VaapiWrapper;
-
-// A collection of methods that utilize VA-API hardware video encode
-// acceleration on Intel systems. Provides functionality to allow plugging VAAPI
-// HW acceleration into the JpegEncodeAccelerator framework.
-//
-// Clients are expected to manage VA surfaces and VA buffers created via
-// VaapiWrapper, and pass them to this class.
-class MEDIA_GPU_EXPORT VaapiJpegEncoder {
- public:
-  // |vaapi_wrapper| should be initialized in VaapiWrapper::kEncode
-  // mode with VAProfileJPEGBaseline profile.
-  explicit VaapiJpegEncoder(scoped_refptr<VaapiWrapper> vaapi_wrapper);
-  ~VaapiJpegEncoder();
-
-  // Encode a JPEG picture. It will fill VA-API parameters and call
-  // corresponding VA-API methods according to |input_size|.
-  // |quality| is the JPEG image quality
-  // |surface_id| is the VA surface that contains input image.
-  // |output_buffer_id| is the ID of VA buffer that encoded image will be
-  // stored. The size of it should be at least as large as
-  // GetMaxCodedBufferSize().
-  // Return false on failure.
-  bool Encode(const gfx::Size& input_size,
-              int quality,
-              VASurfaceID surface_id,
-              VABufferID output_buffer_id);
-
-  // Gets the maximum possible encoded result size.
-  // |size| is the dimension of the YUV image to be encoded.
-  static size_t GetMaxCodedBufferSize(const gfx::Size& size);
-
- private:
-  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
-
-  // |q_matrix_cached_|, |huff_table_param_cached_| and |slice_param_cached_|
-  // are created when Encode() is called the first time. After that, they will
-  // directly be used for all the subsequent Encode() calls.
-  std::unique_ptr<VAQMatrixBufferJPEG> q_matrix_cached_;
-  std::unique_ptr<VAHuffmanTableBufferJPEGBaseline> huff_table_param_cached_;
-  std::unique_ptr<VAEncSliceParameterBufferJPEG> slice_param_cached_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiJpegEncoder);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_JPEG_ENCODER_H_
--- a/media/gpu/vaapi_video_decode_accelerator.cc
+++ /dev/null
@@ -1,1871 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_video_decode_accelerator.h"
-
-#include <string.h>
-
-#include <memory>
-
-#include <va/va.h>
-
-#include "base/bind.h"
-#include "base/files/scoped_file.h"
-#include "base/logging.h"
-#include "base/macros.h"
-#include "base/metrics/histogram_macros.h"
-#include "base/stl_util.h"
-#include "base/strings/string_util.h"
-#include "base/synchronization/waitable_event.h"
-#include "base/threading/thread_task_runner_handle.h"
-#include "base/trace_event/trace_event.h"
-#include "gpu/ipc/service/gpu_channel.h"
-#include "media/base/bind_to_current_loop.h"
-#include "media/gpu/accelerated_video_decoder.h"
-#include "media/gpu/format_utils.h"
-#include "media/gpu/h264_decoder.h"
-#include "media/gpu/vaapi/vaapi_picture.h"
-#include "media/gpu/vp8_decoder.h"
-#include "media/gpu/vp9_decoder.h"
-#include "media/video/picture.h"
-#include "ui/gl/gl_image.h"
-
-#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
-#define VLOGF(level) VLOG(level) << __func__ << "(): "
-
-namespace media {
-
-namespace {
-// UMA errors that the VaapiVideoDecodeAccelerator class reports.
-enum VAVDADecoderFailure {
-  VAAPI_ERROR = 0,
-  VAVDA_DECODER_FAILURES_MAX,
-};
-// from ITU-T REC H.264 spec
-// section 8.5.6
-// "Inverse scanning process for 4x4 transform coefficients and scaling lists"
-static const int kZigzagScan4x4[16] = {0, 1,  4,  8,  5, 2,  3,  6,
-                                       9, 12, 13, 10, 7, 11, 14, 15};
-
-// section 8.5.7
-// "Inverse scanning process for 8x8 transform coefficients and scaling lists"
-static const uint8_t kZigzagScan8x8[64] = {
-    0,  1,  8,  16, 9,  2,  3,  10, 17, 24, 32, 25, 18, 11, 4,  5,
-    12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6,  7,  14, 21, 28,
-    35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,
-    58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63};
-
-// Returns the preferred VA_RT_FORMAT for the given |profile|.
-unsigned int GetVaFormatForVideoCodecProfile(VideoCodecProfile profile) {
-  if (profile == VP9PROFILE_PROFILE2 || profile == VP9PROFILE_PROFILE3)
-    return VA_RT_FORMAT_YUV420_10BPP;
-  return VA_RT_FORMAT_YUV420;
-}
-
-}  // namespace
-
-static void ReportToUMA(VAVDADecoderFailure failure) {
-  UMA_HISTOGRAM_ENUMERATION("Media.VAVDA.DecoderFailure", failure,
-                            VAVDA_DECODER_FAILURES_MAX + 1);
-}
-
-#define RETURN_AND_NOTIFY_ON_FAILURE(result, log, error_code, ret) \
-  do {                                                             \
-    if (!(result)) {                                               \
-      VLOGF(1) << log;                                             \
-      NotifyError(error_code);                                     \
-      return ret;                                                  \
-    }                                                              \
-  } while (0)
-
-class VaapiVideoDecodeAccelerator::VaapiDecodeSurface
-    : public base::RefCountedThreadSafe<VaapiDecodeSurface> {
- public:
-  VaapiDecodeSurface(int32_t bitstream_id,
-                     const scoped_refptr<VASurface>& va_surface);
-
-  int32_t bitstream_id() const { return bitstream_id_; }
-  scoped_refptr<VASurface> va_surface() { return va_surface_; }
-  gfx::Rect visible_rect() const { return visible_rect_; }
-
-  void set_visible_rect(const gfx::Rect& visible_rect) {
-    visible_rect_ = visible_rect;
-  }
-
- private:
-  friend class base::RefCountedThreadSafe<VaapiDecodeSurface>;
-  ~VaapiDecodeSurface();
-
-  const int32_t bitstream_id_;
-  const scoped_refptr<VASurface> va_surface_;
-  gfx::Rect visible_rect_;
-};
-
-VaapiVideoDecodeAccelerator::VaapiDecodeSurface::VaapiDecodeSurface(
-    int32_t bitstream_id,
-    const scoped_refptr<VASurface>& va_surface)
-    : bitstream_id_(bitstream_id), va_surface_(va_surface) {}
-
-VaapiVideoDecodeAccelerator::VaapiDecodeSurface::~VaapiDecodeSurface() {}
-
-class VaapiH264Picture : public H264Picture {
- public:
-  explicit VaapiH264Picture(
-      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
-      : dec_surface_(surface) {}
-
-  VaapiH264Picture* AsVaapiH264Picture() override { return this; }
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
-    return dec_surface_;
-  }
-
- private:
-  ~VaapiH264Picture() override {}
-
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiH264Picture);
-};
-
-class VaapiVideoDecodeAccelerator::VaapiH264Accelerator
-    : public H264Decoder::H264Accelerator {
- public:
-  VaapiH264Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
-                       VaapiWrapper* vaapi_wrapper);
-  ~VaapiH264Accelerator() override;
-
-  // H264Decoder::H264Accelerator implementation.
-  scoped_refptr<H264Picture> CreateH264Picture() override;
-
-  bool SubmitFrameMetadata(const H264SPS* sps,
-                           const H264PPS* pps,
-                           const H264DPB& dpb,
-                           const H264Picture::Vector& ref_pic_listp0,
-                           const H264Picture::Vector& ref_pic_listb0,
-                           const H264Picture::Vector& ref_pic_listb1,
-                           const scoped_refptr<H264Picture>& pic) override;
-
-  bool SubmitSlice(const H264PPS* pps,
-                   const H264SliceHeader* slice_hdr,
-                   const H264Picture::Vector& ref_pic_list0,
-                   const H264Picture::Vector& ref_pic_list1,
-                   const scoped_refptr<H264Picture>& pic,
-                   const uint8_t* data,
-                   size_t size) override;
-
-  bool SubmitDecode(const scoped_refptr<H264Picture>& pic) override;
-  bool OutputPicture(const scoped_refptr<H264Picture>& pic) override;
-
-  void Reset() override;
-
- private:
-  scoped_refptr<VaapiDecodeSurface> H264PictureToVaapiDecodeSurface(
-      const scoped_refptr<H264Picture>& pic);
-
-  void FillVAPicture(VAPictureH264* va_pic, scoped_refptr<H264Picture> pic);
-  int FillVARefFramesFromDPB(const H264DPB& dpb,
-                             VAPictureH264* va_pics,
-                             int num_pics);
-
-  VaapiWrapper* vaapi_wrapper_;
-  VaapiVideoDecodeAccelerator* vaapi_dec_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiH264Accelerator);
-};
-
-class VaapiVP8Picture : public VP8Picture {
- public:
-  explicit VaapiVP8Picture(
-      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
-      : dec_surface_(surface) {}
-
-  VaapiVP8Picture* AsVaapiVP8Picture() override { return this; }
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
-    return dec_surface_;
-  }
-
- private:
-  ~VaapiVP8Picture() override {}
-
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVP8Picture);
-};
-
-class VaapiVideoDecodeAccelerator::VaapiVP8Accelerator
-    : public VP8Decoder::VP8Accelerator {
- public:
-  VaapiVP8Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
-                      VaapiWrapper* vaapi_wrapper);
-  ~VaapiVP8Accelerator() override;
-
-  // VP8Decoder::VP8Accelerator implementation.
-  scoped_refptr<VP8Picture> CreateVP8Picture() override;
-
-  bool SubmitDecode(const scoped_refptr<VP8Picture>& pic,
-                    const Vp8FrameHeader* frame_hdr,
-                    const scoped_refptr<VP8Picture>& last_frame,
-                    const scoped_refptr<VP8Picture>& golden_frame,
-                    const scoped_refptr<VP8Picture>& alt_frame) override;
-
-  bool OutputPicture(const scoped_refptr<VP8Picture>& pic) override;
-
- private:
-  scoped_refptr<VaapiDecodeSurface> VP8PictureToVaapiDecodeSurface(
-      const scoped_refptr<VP8Picture>& pic);
-
-  VaapiWrapper* vaapi_wrapper_;
-  VaapiVideoDecodeAccelerator* vaapi_dec_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVP8Accelerator);
-};
-
-class VaapiVP9Picture : public VP9Picture {
- public:
-  explicit VaapiVP9Picture(
-      scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> surface)
-      : dec_surface_(surface) {}
-
-  VaapiVP9Picture* AsVaapiVP9Picture() override { return this; }
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface() {
-    return dec_surface_;
-  }
-
- private:
-  ~VaapiVP9Picture() override {}
-
-  scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface> dec_surface_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVP9Picture);
-};
-
-class VaapiVideoDecodeAccelerator::VaapiVP9Accelerator
-    : public VP9Decoder::VP9Accelerator {
- public:
-  VaapiVP9Accelerator(VaapiVideoDecodeAccelerator* vaapi_dec,
-                      VaapiWrapper* vaapi_wrapper);
-  ~VaapiVP9Accelerator() override;
-
-  // VP9Decoder::VP9Accelerator implementation.
-  scoped_refptr<VP9Picture> CreateVP9Picture() override;
-
-  bool SubmitDecode(const scoped_refptr<VP9Picture>& pic,
-                    const Vp9SegmentationParams& seg,
-                    const Vp9LoopFilterParams& lf,
-                    const std::vector<scoped_refptr<VP9Picture>>& ref_pictures,
-                    const base::Closure& done_cb) override;
-
-  bool OutputPicture(const scoped_refptr<VP9Picture>& pic) override;
-
-  bool IsFrameContextRequired() const override { return false; }
-
-  bool GetFrameContext(const scoped_refptr<VP9Picture>& pic,
-                       Vp9FrameContext* frame_ctx) override;
-
- private:
-  scoped_refptr<VaapiDecodeSurface> VP9PictureToVaapiDecodeSurface(
-      const scoped_refptr<VP9Picture>& pic);
-
-  VaapiWrapper* vaapi_wrapper_;
-  VaapiVideoDecodeAccelerator* vaapi_dec_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVP9Accelerator);
-};
-
-class VaapiVideoDecodeAccelerator::InputBuffer {
- public:
-  InputBuffer() = default;
-  InputBuffer(uint32_t id,
-              std::unique_ptr<SharedMemoryRegion> shm,
-              base::OnceCallback<void(int32_t id)> release_cb)
-      : id_(id), shm_(std::move(shm)), release_cb_(std::move(release_cb)) {}
-  ~InputBuffer() {
-    VLOGF(4) << "id = " << id_;
-    if (release_cb_)
-      std::move(release_cb_).Run(id_);
-  }
-
-  // Indicates this is a dummy buffer for flush request.
-  bool IsFlushRequest() const { return shm_ == nullptr; }
-  int32_t id() const { return id_; }
-  SharedMemoryRegion* shm() const { return shm_.get(); }
-
- private:
-  const int32_t id_ = -1;
-  const std::unique_ptr<SharedMemoryRegion> shm_;
-  base::OnceCallback<void(int32_t id)> release_cb_;
-
-  DISALLOW_COPY_AND_ASSIGN(InputBuffer);
-};
-
-void VaapiVideoDecodeAccelerator::NotifyError(Error error) {
-  if (!task_runner_->BelongsToCurrentThread()) {
-    DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-    task_runner_->PostTask(FROM_HERE,
-                           base::Bind(&VaapiVideoDecodeAccelerator::NotifyError,
-                                      weak_this_, error));
-    return;
-  }
-
-  // Post Cleanup() as a task so we don't recursively acquire lock_.
-  task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::Cleanup, weak_this_));
-
-  VLOGF(1) << "Notifying of error " << error;
-  if (client_) {
-    client_->NotifyError(error);
-    client_ptr_factory_.reset();
-  }
-}
-
-VaapiPicture* VaapiVideoDecodeAccelerator::PictureById(
-    int32_t picture_buffer_id) {
-  Pictures::iterator it = pictures_.find(picture_buffer_id);
-  if (it == pictures_.end()) {
-    VLOGF(4) << "Picture id " << picture_buffer_id << " does not exist";
-    return NULL;
-  }
-
-  return it->second.get();
-}
-
-VaapiVideoDecodeAccelerator::VaapiVideoDecodeAccelerator(
-    const MakeGLContextCurrentCallback& make_context_current_cb,
-    const BindGLImageCallback& bind_image_cb)
-    : state_(kUninitialized),
-      input_ready_(&lock_),
-      vaapi_picture_factory_(new VaapiPictureFactory()),
-      surfaces_available_(&lock_),
-      task_runner_(base::ThreadTaskRunnerHandle::Get()),
-      decoder_thread_("VaapiDecoderThread"),
-      num_frames_at_client_(0),
-      finish_flush_pending_(false),
-      awaiting_va_surfaces_recycle_(false),
-      requested_num_pics_(0),
-      output_format_(gfx::BufferFormat::BGRX_8888),
-      profile_(VIDEO_CODEC_PROFILE_UNKNOWN),
-      make_context_current_cb_(make_context_current_cb),
-      bind_image_cb_(bind_image_cb),
-      weak_this_factory_(this) {
-  weak_this_ = weak_this_factory_.GetWeakPtr();
-  va_surface_release_cb_ = BindToCurrentLoop(
-      base::Bind(&VaapiVideoDecodeAccelerator::RecycleVASurfaceID, weak_this_));
-}
-
-VaapiVideoDecodeAccelerator::~VaapiVideoDecodeAccelerator() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-}
-
-bool VaapiVideoDecodeAccelerator::Initialize(const Config& config,
-                                             Client* client) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  if (config.is_encrypted()) {
-    NOTREACHED() << "Encrypted streams are not supported for this VDA";
-    return false;
-  }
-
-  switch (config.output_mode) {
-    case Config::OutputMode::ALLOCATE:
-      output_format_ = vaapi_picture_factory_->GetBufferFormatForAllocateMode();
-      break;
-
-    case Config::OutputMode::IMPORT:
-      output_format_ = vaapi_picture_factory_->GetBufferFormatForImportMode();
-      break;
-
-    default:
-      NOTREACHED() << "Only ALLOCATE and IMPORT OutputModes are supported";
-      return false;
-  }
-
-  client_ptr_factory_.reset(new base::WeakPtrFactory<Client>(client));
-  client_ = client_ptr_factory_->GetWeakPtr();
-
-  VideoCodecProfile profile = config.profile;
-
-  base::AutoLock auto_lock(lock_);
-  DCHECK_EQ(state_, kUninitialized);
-  VLOGF(2) << "Initializing VAVDA, profile: " << GetProfileName(profile);
-
-  vaapi_wrapper_ = VaapiWrapper::CreateForVideoCodec(
-      VaapiWrapper::kDecode, profile, base::Bind(&ReportToUMA, VAAPI_ERROR));
-
-  if (!vaapi_wrapper_.get()) {
-    VLOGF(1) << "Failed initializing VAAPI for profile "
-             << GetProfileName(profile);
-    return false;
-  }
-
-  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
-    h264_accelerator_.reset(
-        new VaapiH264Accelerator(this, vaapi_wrapper_.get()));
-    decoder_.reset(new H264Decoder(h264_accelerator_.get()));
-  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
-    vp8_accelerator_.reset(new VaapiVP8Accelerator(this, vaapi_wrapper_.get()));
-    decoder_.reset(new VP8Decoder(vp8_accelerator_.get()));
-  } else if (profile >= VP9PROFILE_MIN && profile <= VP9PROFILE_MAX) {
-    vp9_accelerator_.reset(new VaapiVP9Accelerator(this, vaapi_wrapper_.get()));
-    decoder_.reset(new VP9Decoder(vp9_accelerator_.get()));
-  } else {
-    VLOGF(1) << "Unsupported profile " << GetProfileName(profile);
-    return false;
-  }
-  profile_ = profile;
-
-  CHECK(decoder_thread_.Start());
-  decoder_thread_task_runner_ = decoder_thread_.task_runner();
-
-  state_ = kIdle;
-  output_mode_ = config.output_mode;
-  return true;
-}
-
-void VaapiVideoDecodeAccelerator::OutputPicture(
-    const scoped_refptr<VASurface>& va_surface,
-    int32_t input_id,
-    gfx::Rect visible_rect,
-    VaapiPicture* picture) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  int32_t output_id = picture->picture_buffer_id();
-
-  VLOGF(4) << "Outputting VASurface " << va_surface->id()
-           << " into pixmap bound to picture buffer id " << output_id;
-  {
-    TRACE_EVENT2("Video Decoder", "VAVDA::DownloadFromSurface", "input_id",
-                 input_id, "output_id", output_id);
-    RETURN_AND_NOTIFY_ON_FAILURE(picture->DownloadFromSurface(va_surface),
-                                 "Failed putting surface into pixmap",
-                                 PLATFORM_FAILURE, );
-  }
-  // Notify the client a picture is ready to be displayed.
-  ++num_frames_at_client_;
-  TRACE_COUNTER1("Video Decoder", "Textures at client", num_frames_at_client_);
-  VLOGF(4) << "Notifying output picture id " << output_id << " for input "
-           << input_id
-           << " is ready. visible rect: " << visible_rect.ToString();
-  if (client_) {
-    // TODO(hubbe): Use the correct color space.  http://crbug.com/647725
-    client_->PictureReady(Picture(output_id, input_id, visible_rect,
-                                  gfx::ColorSpace(), picture->AllowOverlay()));
-  }
-}
-
-void VaapiVideoDecodeAccelerator::TryOutputSurface() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  // Handle Destroy() arriving while pictures are queued for output.
-  if (!client_)
-    return;
-
-  if (pending_output_cbs_.empty() || output_buffers_.empty())
-    return;
-
-  OutputCB output_cb = pending_output_cbs_.front();
-  pending_output_cbs_.pop();
-
-  VaapiPicture* picture = PictureById(output_buffers_.front());
-  DCHECK(picture);
-  output_buffers_.pop();
-
-  output_cb.Run(picture);
-
-  if (finish_flush_pending_ && pending_output_cbs_.empty())
-    FinishFlush();
-}
-
-void VaapiVideoDecodeAccelerator::QueueInputBuffer(
-    const BitstreamBuffer& bitstream_buffer) {
-  VLOGF(4) << "Queueing new input buffer id: " << bitstream_buffer.id()
-           << " size: " << (int)bitstream_buffer.size();
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  TRACE_EVENT1("Video Decoder", "QueueInputBuffer", "input_id",
-               bitstream_buffer.id());
-
-  base::AutoLock auto_lock(lock_);
-  if (bitstream_buffer.size() == 0) {
-    DCHECK(!base::SharedMemory::IsHandleValid(bitstream_buffer.handle()));
-    // Dummy buffer for flush.
-    auto flush_buffer = base::MakeUnique<InputBuffer>();
-    DCHECK(flush_buffer->IsFlushRequest());
-    input_buffers_.push(std::move(flush_buffer));
-  } else {
-    std::unique_ptr<SharedMemoryRegion> shm(
-        new SharedMemoryRegion(bitstream_buffer, true));
-    RETURN_AND_NOTIFY_ON_FAILURE(shm->Map(), "Failed to map input buffer",
-                                 UNREADABLE_INPUT, );
-
-    auto input_buffer = base::MakeUnique<InputBuffer>(
-        bitstream_buffer.id(), std::move(shm),
-        BindToCurrentLoop(
-            base::Bind(&Client::NotifyEndOfBitstreamBuffer, client_)));
-    input_buffers_.push(std::move(input_buffer));
-
-    TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
-  }
-
-  input_ready_.Signal();
-
-  switch (state_) {
-    case kIdle:
-      state_ = kDecoding;
-      decoder_thread_task_runner_->PostTask(
-          FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
-                                base::Unretained(this)));
-      break;
-
-    case kDecoding:
-      // Decoder already running.
-      break;
-
-    case kResetting:
-      // When resetting, allow accumulating bitstream buffers, so that
-      // the client can queue after-seek-buffers while we are finishing with
-      // the before-seek one.
-      break;
-
-    default:
-      VLOGF(1) << "Decode/Flush request from client in invalid state: "
-               << state_;
-      NotifyError(PLATFORM_FAILURE);
-      break;
-  }
-}
-
-bool VaapiVideoDecodeAccelerator::GetInputBuffer_Locked() {
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  lock_.AssertAcquired();
-
-  if (curr_input_buffer_.get())
-    return true;
-
-  // Will only wait if it is expected that in current state new buffers will
-  // be queued from the client via Decode(). The state can change during wait.
-  while (input_buffers_.empty() && (state_ == kDecoding || state_ == kIdle)) {
-    input_ready_.Wait();
-  }
-
-  // We could have got woken up in a different state or never got to sleep
-  // due to current state.
-  if (state_ != kDecoding && state_ != kIdle)
-    return false;
-
-  DCHECK(!input_buffers_.empty());
-  curr_input_buffer_ = std::move(input_buffers_.front());
-  input_buffers_.pop();
-
-  if (curr_input_buffer_->IsFlushRequest()) {
-    VLOGF(4) << "New flush buffer";
-    return true;
-  }
-
-  VLOGF(4) << "New current input buffer, id: " << curr_input_buffer_->id()
-           << " size: " << curr_input_buffer_->shm()->size() << "B";
-  decoder_->SetStream(
-      static_cast<uint8_t*>(curr_input_buffer_->shm()->memory()),
-      curr_input_buffer_->shm()->size());
-
-  return true;
-}
-
-void VaapiVideoDecodeAccelerator::ReturnCurrInputBuffer_Locked() {
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  lock_.AssertAcquired();
-  DCHECK(curr_input_buffer_.get());
-  curr_input_buffer_.reset();
-
-  TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
-}
-
-// TODO(posciak): refactor the whole class to remove sleeping in wait for
-// surfaces, and reschedule DecodeTask instead.
-bool VaapiVideoDecodeAccelerator::WaitForSurfaces_Locked() {
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  lock_.AssertAcquired();
-
-  while (available_va_surfaces_.empty() &&
-         (state_ == kDecoding || state_ == kIdle)) {
-    surfaces_available_.Wait();
-  }
-
-  return state_ == kDecoding || state_ == kIdle;
-}
-
-void VaapiVideoDecodeAccelerator::DecodeTask() {
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  base::AutoLock auto_lock(lock_);
-
-  if (state_ != kDecoding)
-    return;
-
-  // Main decode task.
-  VLOGF(4) << "Decode task";
-
-  // Try to decode what stream data is (still) in the decoder until we run out
-  // of it.
-  while (GetInputBuffer_Locked()) {
-    DCHECK(curr_input_buffer_.get());
-
-    if (curr_input_buffer_->IsFlushRequest()) {
-      FlushTask();
-      break;
-    }
-
-    AcceleratedVideoDecoder::DecodeResult res;
-    {
-      // We are OK releasing the lock here, as decoder never calls our methods
-      // directly and we will reacquire the lock before looking at state again.
-      // This is the main decode function of the decoder and while keeping
-      // the lock for its duration would be fine, it would defeat the purpose
-      // of having a separate decoder thread.
-      base::AutoUnlock auto_unlock(lock_);
-      TRACE_EVENT0("Video Decoder", "VAVDA::Decode");
-      res = decoder_->Decode();
-    }
-
-    switch (res) {
-      case AcceleratedVideoDecoder::kAllocateNewSurfaces:
-        VLOGF(2) << "Decoder requesting a new set of surfaces";
-        task_runner_->PostTask(
-            FROM_HERE,
-            base::Bind(&VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange,
-                       weak_this_, decoder_->GetRequiredNumOfPictures(),
-                       decoder_->GetPicSize()));
-        // We'll get rescheduled once ProvidePictureBuffers() finishes.
-        return;
-
-      case AcceleratedVideoDecoder::kRanOutOfStreamData:
-        ReturnCurrInputBuffer_Locked();
-        break;
-
-      case AcceleratedVideoDecoder::kRanOutOfSurfaces:
-        // No more output buffers in the decoder, try getting more or go to
-        // sleep waiting for them.
-        if (!WaitForSurfaces_Locked())
-          return;
-
-        break;
-
-      case AcceleratedVideoDecoder::kNeedContextUpdate:
-        // This should not happen as we return false from
-        // IsFrameContextRequired().
-        NOTREACHED() << "Context updates not supported";
-        return;
-
-      case AcceleratedVideoDecoder::kDecodeError:
-        RETURN_AND_NOTIFY_ON_FAILURE(false, "Error decoding stream",
-                                     PLATFORM_FAILURE, );
-        return;
-    }
-  }
-}
-
-void VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange(size_t num_pics,
-                                                           gfx::Size size) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  DCHECK(!awaiting_va_surfaces_recycle_);
-
-  // At this point decoder has stopped running and has already posted onto our
-  // loop any remaining output request callbacks, which executed before we got
-  // here. Some of them might have been pended though, because we might not
-  // have had enough TFPictures to output surfaces to. Initiate a wait cycle,
-  // which will wait for client to return enough PictureBuffers to us, so that
-  // we can finish all pending output callbacks, releasing associated surfaces.
-  VLOGF(2) << "Initiating surface set change";
-  awaiting_va_surfaces_recycle_ = true;
-
-  requested_num_pics_ = num_pics;
-  requested_pic_size_ = size;
-
-  TryFinishSurfaceSetChange();
-}
-
-void VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  if (!awaiting_va_surfaces_recycle_)
-    return;
-
-  if (!pending_output_cbs_.empty() ||
-      pictures_.size() != available_va_surfaces_.size()) {
-    // Either:
-    // 1. Not all pending pending output callbacks have been executed yet.
-    // Wait for the client to return enough pictures and retry later.
-    // 2. The above happened and all surface release callbacks have been posted
-    // as the result, but not all have executed yet. Post ourselves after them
-    // to let them release surfaces.
-    DVLOGF(2) << "Awaiting pending output/surface release callbacks to finish";
-    task_runner_->PostTask(
-        FROM_HERE,
-        base::Bind(&VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange,
-                   weak_this_));
-    return;
-  }
-
-  // All surfaces released, destroy them and dismiss all PictureBuffers.
-  awaiting_va_surfaces_recycle_ = false;
-  available_va_surfaces_.clear();
-  vaapi_wrapper_->DestroySurfaces();
-
-  for (Pictures::iterator iter = pictures_.begin(); iter != pictures_.end();
-       ++iter) {
-    VLOGF(2) << "Dismissing picture id: " << iter->first;
-    if (client_)
-      client_->DismissPictureBuffer(iter->first);
-  }
-  pictures_.clear();
-
-  // And ask for a new set as requested.
-  VLOGF(2) << "Requesting " << requested_num_pics_
-           << " pictures of size: " << requested_pic_size_.ToString();
-
-  VideoPixelFormat format = GfxBufferFormatToVideoPixelFormat(output_format_);
-  task_runner_->PostTask(
-      FROM_HERE, base::Bind(&Client::ProvidePictureBuffers, client_,
-                            requested_num_pics_, format, 1, requested_pic_size_,
-                            vaapi_picture_factory_->GetGLTextureTarget()));
-}
-
-void VaapiVideoDecodeAccelerator::Decode(
-    const BitstreamBuffer& bitstream_buffer) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  TRACE_EVENT1("Video Decoder", "VAVDA::Decode", "Buffer id",
-               bitstream_buffer.id());
-
-  if (bitstream_buffer.id() < 0) {
-    if (base::SharedMemory::IsHandleValid(bitstream_buffer.handle()))
-      base::SharedMemory::CloseHandle(bitstream_buffer.handle());
-    VLOGF(1) << "Invalid bitstream_buffer, id: " << bitstream_buffer.id();
-    NotifyError(INVALID_ARGUMENT);
-    return;
-  }
-
-  // Skip empty buffers. VaapiVDA uses empty buffer as dummy buffer for flush
-  // internally.
-  if (bitstream_buffer.size() == 0) {
-    if (base::SharedMemory::IsHandleValid(bitstream_buffer.handle()))
-      base::SharedMemory::CloseHandle(bitstream_buffer.handle());
-    if (client_)
-      client_->NotifyEndOfBitstreamBuffer(bitstream_buffer.id());
-    return;
-  }
-
-  QueueInputBuffer(bitstream_buffer);
-}
-
-void VaapiVideoDecodeAccelerator::RecycleVASurfaceID(
-    VASurfaceID va_surface_id) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  base::AutoLock auto_lock(lock_);
-
-  available_va_surfaces_.push_back(va_surface_id);
-  surfaces_available_.Signal();
-}
-
-void VaapiVideoDecodeAccelerator::AssignPictureBuffers(
-    const std::vector<PictureBuffer>& buffers) {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  base::AutoLock auto_lock(lock_);
-  DCHECK(pictures_.empty());
-
-  while (!output_buffers_.empty())
-    output_buffers_.pop();
-
-  RETURN_AND_NOTIFY_ON_FAILURE(
-      buffers.size() >= requested_num_pics_,
-      "Got an invalid number of picture buffers. (Got " << buffers.size()
-      << ", requested " << requested_num_pics_ << ")", INVALID_ARGUMENT, );
-  DCHECK(requested_pic_size_ == buffers[0].size());
-
-  const unsigned int va_format = GetVaFormatForVideoCodecProfile(profile_);
-  std::vector<VASurfaceID> va_surface_ids;
-  RETURN_AND_NOTIFY_ON_FAILURE(
-      vaapi_wrapper_->CreateSurfaces(va_format, requested_pic_size_,
-                                     buffers.size(), &va_surface_ids),
-      "Failed creating VA Surfaces", PLATFORM_FAILURE, );
-  DCHECK_EQ(va_surface_ids.size(), buffers.size());
-
-  for (size_t i = 0; i < buffers.size(); ++i) {
-    uint32_t client_id = !buffers[i].client_texture_ids().empty()
-                             ? buffers[i].client_texture_ids()[0]
-                             : 0;
-    uint32_t service_id = !buffers[i].service_texture_ids().empty()
-                              ? buffers[i].service_texture_ids()[0]
-                              : 0;
-
-    std::unique_ptr<VaapiPicture> picture(vaapi_picture_factory_->Create(
-        vaapi_wrapper_, make_context_current_cb_, bind_image_cb_,
-        buffers[i].id(), requested_pic_size_, service_id, client_id));
-    RETURN_AND_NOTIFY_ON_FAILURE(
-        picture.get(), "Failed creating a VaapiPicture", PLATFORM_FAILURE, );
-
-    if (output_mode_ == Config::OutputMode::ALLOCATE) {
-      RETURN_AND_NOTIFY_ON_FAILURE(
-          picture->Allocate(output_format_),
-          "Failed to allocate memory for a VaapiPicture", PLATFORM_FAILURE, );
-      output_buffers_.push(buffers[i].id());
-    }
-    bool inserted =
-        pictures_.insert(std::make_pair(buffers[i].id(), std::move(picture)))
-            .second;
-    DCHECK(inserted);
-
-    available_va_surfaces_.push_back(va_surface_ids[i]);
-    surfaces_available_.Signal();
-  }
-
-  // Resume DecodeTask if it is still in decoding state.
-  if (state_ == kDecoding) {
-    decoder_thread_task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
-                              base::Unretained(this)));
-  }
-}
-
-#if defined(USE_OZONE)
-static void CloseGpuMemoryBufferHandle(
-    const gfx::GpuMemoryBufferHandle& handle) {
-  for (const auto& fd : handle.native_pixmap_handle.fds) {
-    // Close the fd by wrapping it in a ScopedFD and letting
-    // it fall out of scope.
-    base::ScopedFD scoped_fd(fd.fd);
-  }
-}
-
-void VaapiVideoDecodeAccelerator::ImportBufferForPicture(
-    int32_t picture_buffer_id,
-    const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) {
-  VLOGF(2) << "Importing picture id: " << picture_buffer_id;
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  if (output_mode_ != Config::OutputMode::IMPORT) {
-    CloseGpuMemoryBufferHandle(gpu_memory_buffer_handle);
-    VLOGF(1) << "Cannot import in non-import mode";
-    NotifyError(INVALID_ARGUMENT);
-    return;
-  }
-
-  VaapiPicture* picture = PictureById(picture_buffer_id);
-  if (!picture) {
-    CloseGpuMemoryBufferHandle(gpu_memory_buffer_handle);
-
-    // It's possible that we've already posted a DismissPictureBuffer for this
-    // picture, but it has not yet executed when this ImportBufferForPicture
-    // was posted to us by the client. In that case just ignore this (we've
-    // already dismissed it and accounted for that).
-    VLOGF(3) << "got picture id=" << picture_buffer_id
-             << " not in use (anymore?).";
-    return;
-  }
-
-  if (!picture->ImportGpuMemoryBufferHandle(output_format_,
-                                            gpu_memory_buffer_handle)) {
-    // ImportGpuMemoryBufferHandle will close the handles even on failure, so
-    // we don't need to do this ourselves.
-    VLOGF(1) << "Failed to import GpuMemoryBufferHandle";
-    NotifyError(PLATFORM_FAILURE);
-    return;
-  }
-
-  ReusePictureBuffer(picture_buffer_id);
-}
-#endif
-
-void VaapiVideoDecodeAccelerator::ReusePictureBuffer(
-    int32_t picture_buffer_id) {
-  VLOGF(4) << "picture id=" << picture_buffer_id;
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  TRACE_EVENT1("Video Decoder", "VAVDA::ReusePictureBuffer", "Picture id",
-               picture_buffer_id);
-
-  if (!PictureById(picture_buffer_id)) {
-    // It's possible that we've already posted a DismissPictureBuffer for this
-    // picture, but it has not yet executed when this ReusePictureBuffer
-    // was posted to us by the client. In that case just ignore this (we've
-    // already dismissed it and accounted for that).
-    VLOGF(3) << "got picture id=" << picture_buffer_id
-             << " not in use (anymore?).";
-    return;
-  }
-
-  --num_frames_at_client_;
-  TRACE_COUNTER1("Video Decoder", "Textures at client", num_frames_at_client_);
-
-  output_buffers_.push(picture_buffer_id);
-  TryOutputSurface();
-}
-
-void VaapiVideoDecodeAccelerator::FlushTask() {
-  VLOGF(2);
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK(curr_input_buffer_.get() && curr_input_buffer_->IsFlushRequest());
-
-  curr_input_buffer_.reset();
-
-  // First flush all the pictures that haven't been outputted, notifying the
-  // client to output them.
-  bool res = decoder_->Flush();
-  RETURN_AND_NOTIFY_ON_FAILURE(res, "Failed flushing the decoder.",
-                               PLATFORM_FAILURE, );
-
-  // Put the decoder in idle state, ready to resume.
-  decoder_->Reset();
-
-  task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(&VaapiVideoDecodeAccelerator::FinishFlush, weak_this_));
-}
-
-void VaapiVideoDecodeAccelerator::Flush() {
-  VLOGF(2) << "Got flush request";
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  // Queue a dummy buffer, which means flush.
-  QueueInputBuffer(media::BitstreamBuffer());
-}
-
-void VaapiVideoDecodeAccelerator::FinishFlush() {
-  VLOGF(2);
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  finish_flush_pending_ = false;
-
-  base::AutoLock auto_lock(lock_);
-  if (state_ != kDecoding) {
-    DCHECK(state_ == kDestroying || state_ == kResetting) << state_;
-    return;
-  }
-
-  // Still waiting for textures from client to finish outputting all pending
-  // frames. Try again later.
-  if (!pending_output_cbs_.empty()) {
-    finish_flush_pending_ = true;
-    return;
-  }
-
-  // Resume decoding if necessary.
-  if (input_buffers_.empty()) {
-    state_ = kIdle;
-  } else {
-    decoder_thread_task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
-                              base::Unretained(this)));
-  }
-
-  task_runner_->PostTask(FROM_HERE,
-                         base::Bind(&Client::NotifyFlushDone, client_));
-}
-
-void VaapiVideoDecodeAccelerator::ResetTask() {
-  VLOGF(2);
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-
-  // All the decoding tasks from before the reset request from client are done
-  // by now, as this task was scheduled after them and client is expected not
-  // to call Decode() after Reset() and before NotifyResetDone.
-  decoder_->Reset();
-
-  base::AutoLock auto_lock(lock_);
-
-  // Return current input buffer, if present.
-  if (curr_input_buffer_.get())
-    ReturnCurrInputBuffer_Locked();
-
-  // And let client know that we are done with reset.
-  task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
-}
-
-void VaapiVideoDecodeAccelerator::Reset() {
-  VLOGF(2) << "Got reset request";
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  // This will make any new decode tasks exit early.
-  base::AutoLock auto_lock(lock_);
-  state_ = kResetting;
-  finish_flush_pending_ = false;
-
-  // Drop all remaining input buffers, if present.
-  while (!input_buffers_.empty())
-    input_buffers_.pop();
-  TRACE_COUNTER1("Video Decoder", "Input buffers", input_buffers_.size());
-
-  decoder_thread_task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::ResetTask,
-                            base::Unretained(this)));
-
-  input_ready_.Signal();
-  surfaces_available_.Signal();
-}
-
-void VaapiVideoDecodeAccelerator::FinishReset() {
-  VLOGF(2);
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  base::AutoLock auto_lock(lock_);
-
-  if (state_ != kResetting) {
-    DCHECK(state_ == kDestroying || state_ == kUninitialized) << state_;
-    return;  // We could've gotten destroyed already.
-  }
-
-  // Drop pending outputs.
-  while (!pending_output_cbs_.empty())
-    pending_output_cbs_.pop();
-
-  if (awaiting_va_surfaces_recycle_) {
-    // Decoder requested a new surface set while we were waiting for it to
-    // finish the last DecodeTask, running at the time of Reset().
-    // Let the surface set change finish first before resetting.
-    task_runner_->PostTask(
-        FROM_HERE,
-        base::Bind(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
-    return;
-  }
-
-  state_ = kIdle;
-
-  task_runner_->PostTask(FROM_HERE,
-                         base::Bind(&Client::NotifyResetDone, client_));
-
-  // The client might have given us new buffers via Decode() while we were
-  // resetting and might be waiting for our move, and not call Decode() anymore
-  // until we return something. Post a DecodeTask() so that we won't
-  // sleep forever waiting for Decode() in that case. Having two of them
-  // in the pipe is harmless, the additional one will return as soon as it sees
-  // that we are back in kDecoding state.
-  if (!input_buffers_.empty()) {
-    state_ = kDecoding;
-    decoder_thread_task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::DecodeTask,
-                              base::Unretained(this)));
-  }
-}
-
-void VaapiVideoDecodeAccelerator::Cleanup() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-
-  base::AutoLock auto_lock(lock_);
-  if (state_ == kUninitialized || state_ == kDestroying)
-    return;
-
-  VLOGF(2) << "Destroying VAVDA";
-  state_ = kDestroying;
-
-  client_ptr_factory_.reset();
-  weak_this_factory_.InvalidateWeakPtrs();
-
-  // Signal all potential waiters on the decoder_thread_, let them early-exit,
-  // as we've just moved to the kDestroying state, and wait for all tasks
-  // to finish.
-  input_ready_.Signal();
-  surfaces_available_.Signal();
-  {
-    base::AutoUnlock auto_unlock(lock_);
-    decoder_thread_.Stop();
-  }
-
-  state_ = kUninitialized;
-}
-
-void VaapiVideoDecodeAccelerator::Destroy() {
-  DCHECK(task_runner_->BelongsToCurrentThread());
-  Cleanup();
-  delete this;
-}
-
-bool VaapiVideoDecodeAccelerator::TryToSetupDecodeOnSeparateThread(
-    const base::WeakPtr<Client>& decode_client,
-    const scoped_refptr<base::SingleThreadTaskRunner>& decode_task_runner) {
-  return false;
-}
-
-bool VaapiVideoDecodeAccelerator::DecodeSurface(
-    const scoped_refptr<VaapiDecodeSurface>& dec_surface) {
-  const bool result = vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(
-      dec_surface->va_surface()->id());
-  if (!result)
-    VLOGF(1) << "Failed decoding picture";
-  return result;
-}
-
-void VaapiVideoDecodeAccelerator::SurfaceReady(
-    const scoped_refptr<VaapiDecodeSurface>& dec_surface) {
-  if (!task_runner_->BelongsToCurrentThread()) {
-    task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoDecodeAccelerator::SurfaceReady,
-                              weak_this_, dec_surface));
-    return;
-  }
-
-  DCHECK(!awaiting_va_surfaces_recycle_);
-
-  {
-    base::AutoLock auto_lock(lock_);
-    // Drop any requests to output if we are resetting or being destroyed.
-    if (state_ == kResetting || state_ == kDestroying)
-      return;
-  }
-
-  pending_output_cbs_.push(
-      base::Bind(&VaapiVideoDecodeAccelerator::OutputPicture, weak_this_,
-                 dec_surface->va_surface(), dec_surface->bitstream_id(),
-                 dec_surface->visible_rect()));
-
-  TryOutputSurface();
-}
-
-scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
-VaapiVideoDecodeAccelerator::CreateSurface() {
-  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
-  base::AutoLock auto_lock(lock_);
-
-  if (available_va_surfaces_.empty())
-    return nullptr;
-
-  DCHECK(!awaiting_va_surfaces_recycle_);
-  scoped_refptr<VASurface> va_surface(new VASurface(
-      available_va_surfaces_.front(), requested_pic_size_,
-      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_));
-  available_va_surfaces_.pop_front();
-
-  return new VaapiDecodeSurface(curr_input_buffer_->id(), va_surface);
-}
-
-VaapiVideoDecodeAccelerator::VaapiH264Accelerator::VaapiH264Accelerator(
-    VaapiVideoDecodeAccelerator* vaapi_dec,
-    VaapiWrapper* vaapi_wrapper)
-    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
-  DCHECK(vaapi_wrapper_);
-  DCHECK(vaapi_dec_);
-}
-
-VaapiVideoDecodeAccelerator::VaapiH264Accelerator::~VaapiH264Accelerator() {}
-
-scoped_refptr<H264Picture>
-VaapiVideoDecodeAccelerator::VaapiH264Accelerator::CreateH264Picture() {
-  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
-  if (!va_surface)
-    return nullptr;
-
-  return new VaapiH264Picture(std::move(va_surface));
-}
-
-// Fill |va_pic| with default/neutral values.
-static void InitVAPicture(VAPictureH264* va_pic) {
-  memset(va_pic, 0, sizeof(*va_pic));
-  va_pic->picture_id = VA_INVALID_ID;
-  va_pic->flags = VA_PICTURE_H264_INVALID;
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitFrameMetadata(
-    const H264SPS* sps,
-    const H264PPS* pps,
-    const H264DPB& dpb,
-    const H264Picture::Vector& ref_pic_listp0,
-    const H264Picture::Vector& ref_pic_listb0,
-    const H264Picture::Vector& ref_pic_listb1,
-    const scoped_refptr<H264Picture>& pic) {
-  VAPictureParameterBufferH264 pic_param;
-  memset(&pic_param, 0, sizeof(pic_param));
-
-#define FROM_SPS_TO_PP(a) pic_param.a = sps->a
-#define FROM_SPS_TO_PP2(a, b) pic_param.b = sps->a
-  FROM_SPS_TO_PP2(pic_width_in_mbs_minus1, picture_width_in_mbs_minus1);
-  // This assumes non-interlaced video
-  FROM_SPS_TO_PP2(pic_height_in_map_units_minus1, picture_height_in_mbs_minus1);
-  FROM_SPS_TO_PP(bit_depth_luma_minus8);
-  FROM_SPS_TO_PP(bit_depth_chroma_minus8);
-#undef FROM_SPS_TO_PP
-#undef FROM_SPS_TO_PP2
-
-#define FROM_SPS_TO_PP_SF(a) pic_param.seq_fields.bits.a = sps->a
-#define FROM_SPS_TO_PP_SF2(a, b) pic_param.seq_fields.bits.b = sps->a
-  FROM_SPS_TO_PP_SF(chroma_format_idc);
-  FROM_SPS_TO_PP_SF2(separate_colour_plane_flag,
-                     residual_colour_transform_flag);
-  FROM_SPS_TO_PP_SF(gaps_in_frame_num_value_allowed_flag);
-  FROM_SPS_TO_PP_SF(frame_mbs_only_flag);
-  FROM_SPS_TO_PP_SF(mb_adaptive_frame_field_flag);
-  FROM_SPS_TO_PP_SF(direct_8x8_inference_flag);
-  pic_param.seq_fields.bits.MinLumaBiPredSize8x8 = (sps->level_idc >= 31);
-  FROM_SPS_TO_PP_SF(log2_max_frame_num_minus4);
-  FROM_SPS_TO_PP_SF(pic_order_cnt_type);
-  FROM_SPS_TO_PP_SF(log2_max_pic_order_cnt_lsb_minus4);
-  FROM_SPS_TO_PP_SF(delta_pic_order_always_zero_flag);
-#undef FROM_SPS_TO_PP_SF
-#undef FROM_SPS_TO_PP_SF2
-
-#define FROM_PPS_TO_PP(a) pic_param.a = pps->a
-  FROM_PPS_TO_PP(pic_init_qp_minus26);
-  FROM_PPS_TO_PP(pic_init_qs_minus26);
-  FROM_PPS_TO_PP(chroma_qp_index_offset);
-  FROM_PPS_TO_PP(second_chroma_qp_index_offset);
-#undef FROM_PPS_TO_PP
-
-#define FROM_PPS_TO_PP_PF(a) pic_param.pic_fields.bits.a = pps->a
-#define FROM_PPS_TO_PP_PF2(a, b) pic_param.pic_fields.bits.b = pps->a
-  FROM_PPS_TO_PP_PF(entropy_coding_mode_flag);
-  FROM_PPS_TO_PP_PF(weighted_pred_flag);
-  FROM_PPS_TO_PP_PF(weighted_bipred_idc);
-  FROM_PPS_TO_PP_PF(transform_8x8_mode_flag);
-
-  pic_param.pic_fields.bits.field_pic_flag = 0;
-  FROM_PPS_TO_PP_PF(constrained_intra_pred_flag);
-  FROM_PPS_TO_PP_PF2(bottom_field_pic_order_in_frame_present_flag,
-                     pic_order_present_flag);
-  FROM_PPS_TO_PP_PF(deblocking_filter_control_present_flag);
-  FROM_PPS_TO_PP_PF(redundant_pic_cnt_present_flag);
-  pic_param.pic_fields.bits.reference_pic_flag = pic->ref;
-#undef FROM_PPS_TO_PP_PF
-#undef FROM_PPS_TO_PP_PF2
-
-  pic_param.frame_num = pic->frame_num;
-
-  InitVAPicture(&pic_param.CurrPic);
-  FillVAPicture(&pic_param.CurrPic, pic);
-
-  // Init reference pictures' array.
-  for (int i = 0; i < 16; ++i)
-    InitVAPicture(&pic_param.ReferenceFrames[i]);
-
-  // And fill it with picture info from DPB.
-  FillVARefFramesFromDPB(dpb, pic_param.ReferenceFrames,
-                         arraysize(pic_param.ReferenceFrames));
-
-  pic_param.num_ref_frames = sps->max_num_ref_frames;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
-                                    sizeof(pic_param), &pic_param))
-    return false;
-
-  VAIQMatrixBufferH264 iq_matrix_buf;
-  memset(&iq_matrix_buf, 0, sizeof(iq_matrix_buf));
-
-  if (pps->pic_scaling_matrix_present_flag) {
-    for (int i = 0; i < 6; ++i) {
-      for (int j = 0; j < 16; ++j)
-        iq_matrix_buf.ScalingList4x4[i][kZigzagScan4x4[j]] =
-            pps->scaling_list4x4[i][j];
-    }
-
-    for (int i = 0; i < 2; ++i) {
-      for (int j = 0; j < 64; ++j)
-        iq_matrix_buf.ScalingList8x8[i][kZigzagScan8x8[j]] =
-            pps->scaling_list8x8[i][j];
-    }
-  } else {
-    for (int i = 0; i < 6; ++i) {
-      for (int j = 0; j < 16; ++j)
-        iq_matrix_buf.ScalingList4x4[i][kZigzagScan4x4[j]] =
-            sps->scaling_list4x4[i][j];
-    }
-
-    for (int i = 0; i < 2; ++i) {
-      for (int j = 0; j < 64; ++j)
-        iq_matrix_buf.ScalingList8x8[i][kZigzagScan8x8[j]] =
-            sps->scaling_list8x8[i][j];
-    }
-  }
-
-  return vaapi_wrapper_->SubmitBuffer(VAIQMatrixBufferType,
-                                      sizeof(iq_matrix_buf), &iq_matrix_buf);
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitSlice(
-    const H264PPS* pps,
-    const H264SliceHeader* slice_hdr,
-    const H264Picture::Vector& ref_pic_list0,
-    const H264Picture::Vector& ref_pic_list1,
-    const scoped_refptr<H264Picture>& pic,
-    const uint8_t* data,
-    size_t size) {
-  VASliceParameterBufferH264 slice_param;
-  memset(&slice_param, 0, sizeof(slice_param));
-
-  slice_param.slice_data_size = slice_hdr->nalu_size;
-  slice_param.slice_data_offset = 0;
-  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
-  slice_param.slice_data_bit_offset = slice_hdr->header_bit_size;
-
-#define SHDRToSP(a) slice_param.a = slice_hdr->a
-  SHDRToSP(first_mb_in_slice);
-  slice_param.slice_type = slice_hdr->slice_type % 5;
-  SHDRToSP(direct_spatial_mv_pred_flag);
-
-  // TODO posciak: make sure parser sets those even when override flags
-  // in slice header is off.
-  SHDRToSP(num_ref_idx_l0_active_minus1);
-  SHDRToSP(num_ref_idx_l1_active_minus1);
-  SHDRToSP(cabac_init_idc);
-  SHDRToSP(slice_qp_delta);
-  SHDRToSP(disable_deblocking_filter_idc);
-  SHDRToSP(slice_alpha_c0_offset_div2);
-  SHDRToSP(slice_beta_offset_div2);
-
-  if (((slice_hdr->IsPSlice() || slice_hdr->IsSPSlice()) &&
-       pps->weighted_pred_flag) ||
-      (slice_hdr->IsBSlice() && pps->weighted_bipred_idc == 1)) {
-    SHDRToSP(luma_log2_weight_denom);
-    SHDRToSP(chroma_log2_weight_denom);
-
-    SHDRToSP(luma_weight_l0_flag);
-    SHDRToSP(luma_weight_l1_flag);
-
-    SHDRToSP(chroma_weight_l0_flag);
-    SHDRToSP(chroma_weight_l1_flag);
-
-    for (int i = 0; i <= slice_param.num_ref_idx_l0_active_minus1; ++i) {
-      slice_param.luma_weight_l0[i] =
-          slice_hdr->pred_weight_table_l0.luma_weight[i];
-      slice_param.luma_offset_l0[i] =
-          slice_hdr->pred_weight_table_l0.luma_offset[i];
-
-      for (int j = 0; j < 2; ++j) {
-        slice_param.chroma_weight_l0[i][j] =
-            slice_hdr->pred_weight_table_l0.chroma_weight[i][j];
-        slice_param.chroma_offset_l0[i][j] =
-            slice_hdr->pred_weight_table_l0.chroma_offset[i][j];
-      }
-    }
-
-    if (slice_hdr->IsBSlice()) {
-      for (int i = 0; i <= slice_param.num_ref_idx_l1_active_minus1; ++i) {
-        slice_param.luma_weight_l1[i] =
-            slice_hdr->pred_weight_table_l1.luma_weight[i];
-        slice_param.luma_offset_l1[i] =
-            slice_hdr->pred_weight_table_l1.luma_offset[i];
-
-        for (int j = 0; j < 2; ++j) {
-          slice_param.chroma_weight_l1[i][j] =
-              slice_hdr->pred_weight_table_l1.chroma_weight[i][j];
-          slice_param.chroma_offset_l1[i][j] =
-              slice_hdr->pred_weight_table_l1.chroma_offset[i][j];
-        }
-      }
-    }
-  }
-
-  static_assert(
-      arraysize(slice_param.RefPicList0) == arraysize(slice_param.RefPicList1),
-      "Invalid RefPicList sizes");
-
-  for (size_t i = 0; i < arraysize(slice_param.RefPicList0); ++i) {
-    InitVAPicture(&slice_param.RefPicList0[i]);
-    InitVAPicture(&slice_param.RefPicList1[i]);
-  }
-
-  for (size_t i = 0;
-       i < ref_pic_list0.size() && i < arraysize(slice_param.RefPicList0);
-       ++i) {
-    if (ref_pic_list0[i])
-      FillVAPicture(&slice_param.RefPicList0[i], ref_pic_list0[i]);
-  }
-  for (size_t i = 0;
-       i < ref_pic_list1.size() && i < arraysize(slice_param.RefPicList1);
-       ++i) {
-    if (ref_pic_list1[i])
-      FillVAPicture(&slice_param.RefPicList1[i], ref_pic_list1[i]);
-  }
-
-  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
-                                    sizeof(slice_param), &slice_param))
-    return false;
-
-  // Can't help it, blame libva...
-  void* non_const_ptr = const_cast<uint8_t*>(data);
-  return vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType, size,
-                                      non_const_ptr);
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::SubmitDecode(
-    const scoped_refptr<H264Picture>& pic) {
-  VLOGF(4) << "Decoding POC " << pic->pic_order_cnt;
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      H264PictureToVaapiDecodeSurface(pic);
-
-  return vaapi_dec_->DecodeSurface(dec_surface);
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiH264Accelerator::OutputPicture(
-    const scoped_refptr<H264Picture>& pic) {
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      H264PictureToVaapiDecodeSurface(pic);
-  dec_surface->set_visible_rect(pic->visible_rect);
-  vaapi_dec_->SurfaceReady(dec_surface);
-
-  return true;
-}
-
-void VaapiVideoDecodeAccelerator::VaapiH264Accelerator::Reset() {
-  vaapi_wrapper_->DestroyPendingBuffers();
-}
-
-scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
-VaapiVideoDecodeAccelerator::VaapiH264Accelerator::
-    H264PictureToVaapiDecodeSurface(const scoped_refptr<H264Picture>& pic) {
-  VaapiH264Picture* vaapi_pic = pic->AsVaapiH264Picture();
-  CHECK(vaapi_pic);
-  return vaapi_pic->dec_surface();
-}
-
-void VaapiVideoDecodeAccelerator::VaapiH264Accelerator::FillVAPicture(
-    VAPictureH264* va_pic,
-    scoped_refptr<H264Picture> pic) {
-  VASurfaceID va_surface_id = VA_INVALID_SURFACE;
-
-  if (!pic->nonexisting) {
-    scoped_refptr<VaapiDecodeSurface> dec_surface =
-        H264PictureToVaapiDecodeSurface(pic);
-    va_surface_id = dec_surface->va_surface()->id();
-  }
-
-  va_pic->picture_id = va_surface_id;
-  va_pic->frame_idx = pic->frame_num;
-  va_pic->flags = 0;
-
-  switch (pic->field) {
-    case H264Picture::FIELD_NONE:
-      break;
-    case H264Picture::FIELD_TOP:
-      va_pic->flags |= VA_PICTURE_H264_TOP_FIELD;
-      break;
-    case H264Picture::FIELD_BOTTOM:
-      va_pic->flags |= VA_PICTURE_H264_BOTTOM_FIELD;
-      break;
-  }
-
-  if (pic->ref) {
-    va_pic->flags |= pic->long_term ? VA_PICTURE_H264_LONG_TERM_REFERENCE
-                                    : VA_PICTURE_H264_SHORT_TERM_REFERENCE;
-  }
-
-  va_pic->TopFieldOrderCnt = pic->top_field_order_cnt;
-  va_pic->BottomFieldOrderCnt = pic->bottom_field_order_cnt;
-}
-
-int VaapiVideoDecodeAccelerator::VaapiH264Accelerator::FillVARefFramesFromDPB(
-    const H264DPB& dpb,
-    VAPictureH264* va_pics,
-    int num_pics) {
-  H264Picture::Vector::const_reverse_iterator rit;
-  int i;
-
-  // Return reference frames in reverse order of insertion.
-  // Libva does not document this, but other implementations (e.g. mplayer)
-  // do it this way as well.
-  for (rit = dpb.rbegin(), i = 0; rit != dpb.rend() && i < num_pics; ++rit) {
-    if ((*rit)->ref)
-      FillVAPicture(&va_pics[i++], *rit);
-  }
-
-  return i;
-}
-
-VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::VaapiVP8Accelerator(
-    VaapiVideoDecodeAccelerator* vaapi_dec,
-    VaapiWrapper* vaapi_wrapper)
-    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
-  DCHECK(vaapi_wrapper_);
-  DCHECK(vaapi_dec_);
-}
-
-VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::~VaapiVP8Accelerator() {}
-
-scoped_refptr<VP8Picture>
-VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::CreateVP8Picture() {
-  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
-  if (!va_surface)
-    return nullptr;
-
-  return new VaapiVP8Picture(std::move(va_surface));
-}
-
-#define ARRAY_MEMCPY_CHECKED(to, from)                               \
-  do {                                                               \
-    static_assert(sizeof(to) == sizeof(from),                        \
-                  #from " and " #to " arrays must be of same size"); \
-    memcpy(to, from, sizeof(to));                                    \
-  } while (0)
-
-bool VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::SubmitDecode(
-    const scoped_refptr<VP8Picture>& pic,
-    const Vp8FrameHeader* frame_hdr,
-    const scoped_refptr<VP8Picture>& last_frame,
-    const scoped_refptr<VP8Picture>& golden_frame,
-    const scoped_refptr<VP8Picture>& alt_frame) {
-  VAIQMatrixBufferVP8 iq_matrix_buf;
-  memset(&iq_matrix_buf, 0, sizeof(VAIQMatrixBufferVP8));
-
-  const Vp8SegmentationHeader& sgmnt_hdr = frame_hdr->segmentation_hdr;
-  const Vp8QuantizationHeader& quant_hdr = frame_hdr->quantization_hdr;
-  static_assert(arraysize(iq_matrix_buf.quantization_index) == kMaxMBSegments,
-                "incorrect quantization matrix size");
-  for (size_t i = 0; i < kMaxMBSegments; ++i) {
-    int q = quant_hdr.y_ac_qi;
-
-    if (sgmnt_hdr.segmentation_enabled) {
-      if (sgmnt_hdr.segment_feature_mode ==
-          Vp8SegmentationHeader::FEATURE_MODE_ABSOLUTE)
-        q = sgmnt_hdr.quantizer_update_value[i];
-      else
-        q += sgmnt_hdr.quantizer_update_value[i];
-    }
-
-#define CLAMP_Q(q) std::min(std::max(q, 0), 127)
-    static_assert(arraysize(iq_matrix_buf.quantization_index[i]) == 6,
-                  "incorrect quantization matrix size");
-    iq_matrix_buf.quantization_index[i][0] = CLAMP_Q(q);
-    iq_matrix_buf.quantization_index[i][1] = CLAMP_Q(q + quant_hdr.y_dc_delta);
-    iq_matrix_buf.quantization_index[i][2] = CLAMP_Q(q + quant_hdr.y2_dc_delta);
-    iq_matrix_buf.quantization_index[i][3] = CLAMP_Q(q + quant_hdr.y2_ac_delta);
-    iq_matrix_buf.quantization_index[i][4] = CLAMP_Q(q + quant_hdr.uv_dc_delta);
-    iq_matrix_buf.quantization_index[i][5] = CLAMP_Q(q + quant_hdr.uv_ac_delta);
-#undef CLAMP_Q
-  }
-
-  if (!vaapi_wrapper_->SubmitBuffer(
-          VAIQMatrixBufferType, sizeof(VAIQMatrixBufferVP8), &iq_matrix_buf))
-    return false;
-
-  VAProbabilityDataBufferVP8 prob_buf;
-  memset(&prob_buf, 0, sizeof(VAProbabilityDataBufferVP8));
-
-  const Vp8EntropyHeader& entr_hdr = frame_hdr->entropy_hdr;
-  ARRAY_MEMCPY_CHECKED(prob_buf.dct_coeff_probs, entr_hdr.coeff_probs);
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAProbabilityBufferType,
-                                    sizeof(VAProbabilityDataBufferVP8),
-                                    &prob_buf))
-    return false;
-
-  VAPictureParameterBufferVP8 pic_param;
-  memset(&pic_param, 0, sizeof(VAPictureParameterBufferVP8));
-  pic_param.frame_width = frame_hdr->width;
-  pic_param.frame_height = frame_hdr->height;
-
-  if (last_frame) {
-    scoped_refptr<VaapiDecodeSurface> last_frame_surface =
-        VP8PictureToVaapiDecodeSurface(last_frame);
-    pic_param.last_ref_frame = last_frame_surface->va_surface()->id();
-  } else {
-    pic_param.last_ref_frame = VA_INVALID_SURFACE;
-  }
-
-  if (golden_frame) {
-    scoped_refptr<VaapiDecodeSurface> golden_frame_surface =
-        VP8PictureToVaapiDecodeSurface(golden_frame);
-    pic_param.golden_ref_frame = golden_frame_surface->va_surface()->id();
-  } else {
-    pic_param.golden_ref_frame = VA_INVALID_SURFACE;
-  }
-
-  if (alt_frame) {
-    scoped_refptr<VaapiDecodeSurface> alt_frame_surface =
-        VP8PictureToVaapiDecodeSurface(alt_frame);
-    pic_param.alt_ref_frame = alt_frame_surface->va_surface()->id();
-  } else {
-    pic_param.alt_ref_frame = VA_INVALID_SURFACE;
-  }
-
-  pic_param.out_of_loop_frame = VA_INVALID_SURFACE;
-
-  const Vp8LoopFilterHeader& lf_hdr = frame_hdr->loopfilter_hdr;
-
-#define FHDR_TO_PP_PF(a, b) pic_param.pic_fields.bits.a = (b)
-  FHDR_TO_PP_PF(key_frame, frame_hdr->IsKeyframe() ? 0 : 1);
-  FHDR_TO_PP_PF(version, frame_hdr->version);
-  FHDR_TO_PP_PF(segmentation_enabled, sgmnt_hdr.segmentation_enabled);
-  FHDR_TO_PP_PF(update_mb_segmentation_map,
-                sgmnt_hdr.update_mb_segmentation_map);
-  FHDR_TO_PP_PF(update_segment_feature_data,
-                sgmnt_hdr.update_segment_feature_data);
-  FHDR_TO_PP_PF(filter_type, lf_hdr.type);
-  FHDR_TO_PP_PF(sharpness_level, lf_hdr.sharpness_level);
-  FHDR_TO_PP_PF(loop_filter_adj_enable, lf_hdr.loop_filter_adj_enable);
-  FHDR_TO_PP_PF(mode_ref_lf_delta_update, lf_hdr.mode_ref_lf_delta_update);
-  FHDR_TO_PP_PF(sign_bias_golden, frame_hdr->sign_bias_golden);
-  FHDR_TO_PP_PF(sign_bias_alternate, frame_hdr->sign_bias_alternate);
-  FHDR_TO_PP_PF(mb_no_coeff_skip, frame_hdr->mb_no_skip_coeff);
-  FHDR_TO_PP_PF(loop_filter_disable, lf_hdr.level == 0);
-#undef FHDR_TO_PP_PF
-
-  ARRAY_MEMCPY_CHECKED(pic_param.mb_segment_tree_probs, sgmnt_hdr.segment_prob);
-
-  static_assert(arraysize(sgmnt_hdr.lf_update_value) ==
-                    arraysize(pic_param.loop_filter_level),
-                "loop filter level arrays mismatch");
-  for (size_t i = 0; i < arraysize(sgmnt_hdr.lf_update_value); ++i) {
-    int lf_level = lf_hdr.level;
-    if (sgmnt_hdr.segmentation_enabled) {
-      if (sgmnt_hdr.segment_feature_mode ==
-          Vp8SegmentationHeader::FEATURE_MODE_ABSOLUTE)
-        lf_level = sgmnt_hdr.lf_update_value[i];
-      else
-        lf_level += sgmnt_hdr.lf_update_value[i];
-    }
-
-    // Clamp to [0..63] range.
-    lf_level = std::min(std::max(lf_level, 0), 63);
-    pic_param.loop_filter_level[i] = lf_level;
-  }
-
-  static_assert(
-      arraysize(lf_hdr.ref_frame_delta) ==
-              arraysize(pic_param.loop_filter_deltas_ref_frame) &&
-          arraysize(lf_hdr.mb_mode_delta) ==
-              arraysize(pic_param.loop_filter_deltas_mode) &&
-          arraysize(lf_hdr.ref_frame_delta) == arraysize(lf_hdr.mb_mode_delta),
-      "loop filter deltas arrays size mismatch");
-  for (size_t i = 0; i < arraysize(lf_hdr.ref_frame_delta); ++i) {
-    pic_param.loop_filter_deltas_ref_frame[i] = lf_hdr.ref_frame_delta[i];
-    pic_param.loop_filter_deltas_mode[i] = lf_hdr.mb_mode_delta[i];
-  }
-
-#define FHDR_TO_PP(a) pic_param.a = frame_hdr->a
-  FHDR_TO_PP(prob_skip_false);
-  FHDR_TO_PP(prob_intra);
-  FHDR_TO_PP(prob_last);
-  FHDR_TO_PP(prob_gf);
-#undef FHDR_TO_PP
-
-  ARRAY_MEMCPY_CHECKED(pic_param.y_mode_probs, entr_hdr.y_mode_probs);
-  ARRAY_MEMCPY_CHECKED(pic_param.uv_mode_probs, entr_hdr.uv_mode_probs);
-  ARRAY_MEMCPY_CHECKED(pic_param.mv_probs, entr_hdr.mv_probs);
-
-  pic_param.bool_coder_ctx.range = frame_hdr->bool_dec_range;
-  pic_param.bool_coder_ctx.value = frame_hdr->bool_dec_value;
-  pic_param.bool_coder_ctx.count = frame_hdr->bool_dec_count;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
-                                    sizeof(pic_param), &pic_param))
-    return false;
-
-  VASliceParameterBufferVP8 slice_param;
-  memset(&slice_param, 0, sizeof(slice_param));
-  slice_param.slice_data_size = frame_hdr->frame_size;
-  slice_param.slice_data_offset = frame_hdr->first_part_offset;
-  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
-  slice_param.macroblock_offset = frame_hdr->macroblock_bit_offset;
-  // Number of DCT partitions plus control partition.
-  slice_param.num_of_partitions = frame_hdr->num_of_dct_partitions + 1;
-
-  // Per VAAPI, this size only includes the size of the macroblock data in
-  // the first partition (in bytes), so we have to subtract the header size.
-  slice_param.partition_size[0] =
-      frame_hdr->first_part_size - ((frame_hdr->macroblock_bit_offset + 7) / 8);
-
-  for (size_t i = 0; i < frame_hdr->num_of_dct_partitions; ++i)
-    slice_param.partition_size[i + 1] = frame_hdr->dct_partition_sizes[i];
-
-  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
-                                    sizeof(VASliceParameterBufferVP8),
-                                    &slice_param))
-    return false;
-
-  void* non_const_ptr = const_cast<uint8_t*>(frame_hdr->data);
-  if (!vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType,
-                                    frame_hdr->frame_size, non_const_ptr))
-    return false;
-
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      VP8PictureToVaapiDecodeSurface(pic);
-
-  return vaapi_dec_->DecodeSurface(dec_surface);
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::OutputPicture(
-    const scoped_refptr<VP8Picture>& pic) {
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      VP8PictureToVaapiDecodeSurface(pic);
-  dec_surface->set_visible_rect(pic->visible_rect);
-  vaapi_dec_->SurfaceReady(dec_surface);
-  return true;
-}
-
-scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
-VaapiVideoDecodeAccelerator::VaapiVP8Accelerator::
-    VP8PictureToVaapiDecodeSurface(const scoped_refptr<VP8Picture>& pic) {
-  VaapiVP8Picture* vaapi_pic = pic->AsVaapiVP8Picture();
-  CHECK(vaapi_pic);
-  return vaapi_pic->dec_surface();
-}
-
-VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::VaapiVP9Accelerator(
-    VaapiVideoDecodeAccelerator* vaapi_dec,
-    VaapiWrapper* vaapi_wrapper)
-    : vaapi_wrapper_(vaapi_wrapper), vaapi_dec_(vaapi_dec) {
-  DCHECK(vaapi_wrapper_);
-  DCHECK(vaapi_dec_);
-}
-
-VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::~VaapiVP9Accelerator() {}
-
-scoped_refptr<VP9Picture>
-VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::CreateVP9Picture() {
-  scoped_refptr<VaapiDecodeSurface> va_surface = vaapi_dec_->CreateSurface();
-  if (!va_surface)
-    return nullptr;
-
-  return new VaapiVP9Picture(std::move(va_surface));
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::SubmitDecode(
-    const scoped_refptr<VP9Picture>& pic,
-    const Vp9SegmentationParams& seg,
-    const Vp9LoopFilterParams& lf,
-    const std::vector<scoped_refptr<VP9Picture>>& ref_pictures,
-    const base::Closure& done_cb) {
-  // |done_cb| should be null as we return false from IsFrameContextRequired().
-  DCHECK(done_cb.is_null());
-
-  VADecPictureParameterBufferVP9 pic_param;
-  memset(&pic_param, 0, sizeof(pic_param));
-
-  const Vp9FrameHeader* frame_hdr = pic->frame_hdr.get();
-  DCHECK(frame_hdr);
-
-  pic_param.frame_width = base::checked_cast<uint16_t>(frame_hdr->frame_width);
-  pic_param.frame_height =
-      base::checked_cast<uint16_t>(frame_hdr->frame_height);
-
-  CHECK_EQ(ref_pictures.size(), arraysize(pic_param.reference_frames));
-  for (size_t i = 0; i < arraysize(pic_param.reference_frames); ++i) {
-    VASurfaceID va_surface_id;
-    if (ref_pictures[i]) {
-      scoped_refptr<VaapiDecodeSurface> surface =
-          VP9PictureToVaapiDecodeSurface(ref_pictures[i]);
-      va_surface_id = surface->va_surface()->id();
-    } else {
-      va_surface_id = VA_INVALID_SURFACE;
-    }
-
-    pic_param.reference_frames[i] = va_surface_id;
-  }
-
-#define FHDR_TO_PP_PF1(a) pic_param.pic_fields.bits.a = frame_hdr->a
-#define FHDR_TO_PP_PF2(a, b) pic_param.pic_fields.bits.a = b
-  FHDR_TO_PP_PF2(subsampling_x, frame_hdr->subsampling_x == 1);
-  FHDR_TO_PP_PF2(subsampling_y, frame_hdr->subsampling_y == 1);
-  FHDR_TO_PP_PF2(frame_type, frame_hdr->IsKeyframe() ? 0 : 1);
-  FHDR_TO_PP_PF1(show_frame);
-  FHDR_TO_PP_PF1(error_resilient_mode);
-  FHDR_TO_PP_PF1(intra_only);
-  FHDR_TO_PP_PF1(allow_high_precision_mv);
-  FHDR_TO_PP_PF2(mcomp_filter_type, frame_hdr->interpolation_filter);
-  FHDR_TO_PP_PF1(frame_parallel_decoding_mode);
-  FHDR_TO_PP_PF1(reset_frame_context);
-  FHDR_TO_PP_PF1(refresh_frame_context);
-  FHDR_TO_PP_PF2(frame_context_idx, frame_hdr->frame_context_idx_to_save_probs);
-  FHDR_TO_PP_PF2(segmentation_enabled, seg.enabled);
-  FHDR_TO_PP_PF2(segmentation_temporal_update, seg.temporal_update);
-  FHDR_TO_PP_PF2(segmentation_update_map, seg.update_map);
-  FHDR_TO_PP_PF2(last_ref_frame, frame_hdr->ref_frame_idx[0]);
-  FHDR_TO_PP_PF2(last_ref_frame_sign_bias,
-                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_LAST]);
-  FHDR_TO_PP_PF2(golden_ref_frame, frame_hdr->ref_frame_idx[1]);
-  FHDR_TO_PP_PF2(golden_ref_frame_sign_bias,
-                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_GOLDEN]);
-  FHDR_TO_PP_PF2(alt_ref_frame, frame_hdr->ref_frame_idx[2]);
-  FHDR_TO_PP_PF2(alt_ref_frame_sign_bias,
-                 frame_hdr->ref_frame_sign_bias[Vp9RefType::VP9_FRAME_ALTREF]);
-  FHDR_TO_PP_PF2(lossless_flag, frame_hdr->quant_params.IsLossless());
-#undef FHDR_TO_PP_PF2
-#undef FHDR_TO_PP_PF1
-
-  pic_param.filter_level = lf.level;
-  pic_param.sharpness_level = lf.sharpness;
-  pic_param.log2_tile_rows = frame_hdr->tile_rows_log2;
-  pic_param.log2_tile_columns = frame_hdr->tile_cols_log2;
-  pic_param.frame_header_length_in_bytes = frame_hdr->uncompressed_header_size;
-  pic_param.first_partition_size = frame_hdr->header_size_in_bytes;
-
-  ARRAY_MEMCPY_CHECKED(pic_param.mb_segment_tree_probs, seg.tree_probs);
-  ARRAY_MEMCPY_CHECKED(pic_param.segment_pred_probs, seg.pred_probs);
-
-  pic_param.profile = frame_hdr->profile;
-  pic_param.bit_depth = frame_hdr->bit_depth;
-  DCHECK((pic_param.profile == 0 && pic_param.bit_depth == 8) ||
-         (pic_param.profile == 2 && pic_param.bit_depth == 10));
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAPictureParameterBufferType,
-                                    sizeof(pic_param), &pic_param))
-    return false;
-
-  VASliceParameterBufferVP9 slice_param;
-  memset(&slice_param, 0, sizeof(slice_param));
-  slice_param.slice_data_size = frame_hdr->frame_size;
-  slice_param.slice_data_offset = 0;
-  slice_param.slice_data_flag = VA_SLICE_DATA_FLAG_ALL;
-
-  static_assert(arraysize(Vp9SegmentationParams::feature_enabled) ==
-                    arraysize(slice_param.seg_param),
-                "seg_param array of incorrect size");
-  for (size_t i = 0; i < arraysize(slice_param.seg_param); ++i) {
-    VASegmentParameterVP9& seg_param = slice_param.seg_param[i];
-#define SEG_TO_SP_SF(a, b) seg_param.segment_flags.fields.a = b
-    SEG_TO_SP_SF(
-        segment_reference_enabled,
-        seg.FeatureEnabled(i, Vp9SegmentationParams::SEG_LVL_REF_FRAME));
-    SEG_TO_SP_SF(segment_reference,
-                 seg.FeatureData(i, Vp9SegmentationParams::SEG_LVL_REF_FRAME));
-    SEG_TO_SP_SF(segment_reference_skipped,
-                 seg.FeatureEnabled(i, Vp9SegmentationParams::SEG_LVL_SKIP));
-#undef SEG_TO_SP_SF
-
-    ARRAY_MEMCPY_CHECKED(seg_param.filter_level, lf.lvl[i]);
-
-    seg_param.luma_dc_quant_scale = seg.y_dequant[i][0];
-    seg_param.luma_ac_quant_scale = seg.y_dequant[i][1];
-    seg_param.chroma_dc_quant_scale = seg.uv_dequant[i][0];
-    seg_param.chroma_ac_quant_scale = seg.uv_dequant[i][1];
-  }
-
-  if (!vaapi_wrapper_->SubmitBuffer(VASliceParameterBufferType,
-                                    sizeof(slice_param), &slice_param))
-    return false;
-
-  void* non_const_ptr = const_cast<uint8_t*>(frame_hdr->data);
-  if (!vaapi_wrapper_->SubmitBuffer(VASliceDataBufferType,
-                                    frame_hdr->frame_size, non_const_ptr))
-    return false;
-
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      VP9PictureToVaapiDecodeSurface(pic);
-
-  return vaapi_dec_->DecodeSurface(dec_surface);
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::OutputPicture(
-    const scoped_refptr<VP9Picture>& pic) {
-  scoped_refptr<VaapiDecodeSurface> dec_surface =
-      VP9PictureToVaapiDecodeSurface(pic);
-  dec_surface->set_visible_rect(pic->visible_rect);
-  vaapi_dec_->SurfaceReady(dec_surface);
-  return true;
-}
-
-bool VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::GetFrameContext(
-    const scoped_refptr<VP9Picture>& pic,
-    Vp9FrameContext* frame_ctx) {
-  NOTIMPLEMENTED() << "Frame context update not supported";
-  return false;
-}
-
-scoped_refptr<VaapiVideoDecodeAccelerator::VaapiDecodeSurface>
-VaapiVideoDecodeAccelerator::VaapiVP9Accelerator::
-    VP9PictureToVaapiDecodeSurface(const scoped_refptr<VP9Picture>& pic) {
-  VaapiVP9Picture* vaapi_pic = pic->AsVaapiVP9Picture();
-  CHECK(vaapi_pic);
-  return vaapi_pic->dec_surface();
-}
-
-// static
-VideoDecodeAccelerator::SupportedProfiles
-VaapiVideoDecodeAccelerator::GetSupportedProfiles() {
-  return VaapiWrapper::GetSupportedDecodeProfiles();
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_video_decode_accelerator.h
+++ /dev/null
@@ -1,325 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// This file contains an implementation of VideoDecoderAccelerator
-// that utilizes hardware video decoder present on Intel CPUs.
-
-#ifndef MEDIA_GPU_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
-#define MEDIA_GPU_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
-
-#include <stddef.h>
-#include <stdint.h>
-
-#include <list>
-#include <map>
-#include <memory>
-#include <utility>
-#include <vector>
-
-#include "base/containers/queue.h"
-#include "base/logging.h"
-#include "base/macros.h"
-#include "base/memory/linked_ptr.h"
-#include "base/memory/ref_counted.h"
-#include "base/memory/weak_ptr.h"
-#include "base/single_thread_task_runner.h"
-#include "base/synchronization/condition_variable.h"
-#include "base/synchronization/lock.h"
-#include "base/threading/thread.h"
-#include "media/base/bitstream_buffer.h"
-#include "media/gpu/gpu_video_decode_accelerator_helpers.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/shared_memory_region.h"
-#include "media/gpu/vaapi/vaapi_picture_factory.h"
-#include "media/gpu/vaapi_wrapper.h"
-#include "media/video/picture.h"
-#include "media/video/video_decode_accelerator.h"
-
-namespace gl {
-class GLImage;
-}
-
-namespace media {
-
-class AcceleratedVideoDecoder;
-class VaapiPicture;
-
-// Class to provide video decode acceleration for Intel systems with hardware
-// support for it, and on which libva is available.
-// Decoding tasks are performed in a separate decoding thread.
-//
-// Threading/life-cycle: this object is created & destroyed on the GPU
-// ChildThread.  A few methods on it are called on the decoder thread which is
-// stopped during |this->Destroy()|, so any tasks posted to the decoder thread
-// can assume |*this| is still alive.  See |weak_this_| below for more details.
-class MEDIA_GPU_EXPORT VaapiVideoDecodeAccelerator
-    : public VideoDecodeAccelerator {
- public:
-  // Wrapper of a VASurface with id and visible area.
-  class VaapiDecodeSurface;
-
-  VaapiVideoDecodeAccelerator(
-      const MakeGLContextCurrentCallback& make_context_current_cb,
-      const BindGLImageCallback& bind_image_cb);
-
-  ~VaapiVideoDecodeAccelerator() override;
-
-  // VideoDecodeAccelerator implementation.
-  bool Initialize(const Config& config, Client* client) override;
-  void Decode(const BitstreamBuffer& bitstream_buffer) override;
-  void AssignPictureBuffers(const std::vector<PictureBuffer>& buffers) override;
-#if defined(USE_OZONE)
-  void ImportBufferForPicture(
-      int32_t picture_buffer_id,
-      const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) override;
-#endif
-  void ReusePictureBuffer(int32_t picture_buffer_id) override;
-  void Flush() override;
-  void Reset() override;
-  void Destroy() override;
-  bool TryToSetupDecodeOnSeparateThread(
-      const base::WeakPtr<Client>& decode_client,
-      const scoped_refptr<base::SingleThreadTaskRunner>& decode_task_runner)
-      override;
-
-  static VideoDecodeAccelerator::SupportedProfiles GetSupportedProfiles();
-
- private:
-  friend class VaapiVideoDecodeAcceleratorTest;
-  class VaapiH264Accelerator;
-  class VaapiVP8Accelerator;
-  class VaapiVP9Accelerator;
-
-  // An input buffer with id provided by the client and awaiting consumption.
-  class InputBuffer;
-
-  // Notify the client that an error has occurred and decoding cannot continue.
-  void NotifyError(Error error);
-
-  // Queue a input buffer for decode.
-  void QueueInputBuffer(const BitstreamBuffer& bitstream_buffer);
-
-  // Get a new input buffer from the queue and set it up in decoder. This will
-  // sleep if no input buffers are available. Return true if a new buffer has
-  // been set up, false if an early exit has been requested (due to initiated
-  // reset/flush/destroy).
-  bool GetInputBuffer_Locked();
-
-  // Signal the client that the current buffer has been read and can be
-  // returned. Will also release the mapping.
-  void ReturnCurrInputBuffer_Locked();
-
-  // Wait for more surfaces to become available. Return true once they do or
-  // false if an early exit has been requested (due to an initiated
-  // reset/flush/destroy).
-  bool WaitForSurfaces_Locked();
-
-  // Continue decoding given input buffers and sleep waiting for input/output
-  // as needed. Will exit if a new set of surfaces or reset/flush/destroy
-  // is requested.
-  void DecodeTask();
-
-  // Scheduled after receiving a flush request and executed after the current
-  // decoding task finishes decoding pending inputs. Makes the decoder return
-  // all remaining output pictures and puts it in an idle state, ready
-  // to resume if needed and schedules a FinishFlush.
-  void FlushTask();
-
-  // Scheduled by the FlushTask after decoder is flushed to put VAVDA into idle
-  // state and notify the client that flushing has been finished.
-  void FinishFlush();
-
-  // Scheduled after receiving a reset request and executed after the current
-  // decoding task finishes decoding the current frame. Puts the decoder into
-  // an idle state, ready to resume if needed, discarding decoded but not yet
-  // outputted pictures (decoder keeps ownership of their associated picture
-  // buffers). Schedules a FinishReset afterwards.
-  void ResetTask();
-
-  // Scheduled by ResetTask after it's done putting VAVDA into an idle state.
-  // Drops remaining input buffers and notifies the client that reset has been
-  // finished.
-  void FinishReset();
-
-  // Helper for Destroy(), doing all the actual work except for deleting self.
-  void Cleanup();
-
-  // Get a usable framebuffer configuration for use in binding textures
-  // or return false on failure.
-  bool InitializeFBConfig();
-
-  // Callback to be executed once we have a |va_surface| to be output and
-  // an available |picture| to use for output.
-  // Puts contents of |va_surface| into given |picture|, releases the surface
-  // and passes the resulting picture to client to output the given
-  // |visible_rect| part of it.
-  void OutputPicture(const scoped_refptr<VASurface>& va_surface,
-                     int32_t input_id,
-                     gfx::Rect visible_rect,
-                     VaapiPicture* picture);
-
-  // Try to OutputPicture() if we have both a ready surface and picture.
-  void TryOutputSurface();
-
-  // Called when a VASurface is no longer in use by the decoder or is not being
-  // synced/waiting to be synced to a picture. Returns it to available surfaces
-  // pool.
-  void RecycleVASurfaceID(VASurfaceID va_surface_id);
-
-  // Initiate wait cycle for surfaces to be released before we release them
-  // and allocate new ones, as requested by the decoder.
-  void InitiateSurfaceSetChange(size_t num_pics, gfx::Size size);
-
-  // Check if the surfaces have been released or post ourselves for later.
-  void TryFinishSurfaceSetChange();
-
-  //
-  // Below methods are used by accelerator implementations.
-  //
-  // Decode of |dec_surface| is ready to be submitted and all codec-specific
-  // settings are set in hardware.
-  bool DecodeSurface(const scoped_refptr<VaapiDecodeSurface>& dec_surface);
-
-  // |dec_surface| is ready to be outputted once decode is finished.
-  // This can be called before decode is actually done in hardware, and this
-  // method is responsible for maintaining the ordering, i.e. the surfaces have
-  // to be outputted in the same order as SurfaceReady is called.
-  // On Intel, we don't have to explicitly maintain the ordering however, as the
-  // driver will maintain ordering, as well as dependencies, and will process
-  // each submitted command in order, and run each command only if its
-  // dependencies are ready.
-  void SurfaceReady(const scoped_refptr<VaapiDecodeSurface>& dec_surface);
-
-  // Return a new VaapiDecodeSurface for decoding into, or nullptr if not
-  // available.
-  scoped_refptr<VaapiDecodeSurface> CreateSurface();
-
-  // VAVDA state.
-  enum State {
-    // Initialize() not called yet or failed.
-    kUninitialized,
-    // DecodeTask running.
-    kDecoding,
-    // Resetting, waiting for decoder to finish current task and cleanup.
-    kResetting,
-    // Idle, decoder in state ready to start/resume decoding.
-    kIdle,
-    // Destroying, waiting for the decoder to finish current task.
-    kDestroying,
-  };
-
-  // Protects input buffer and surface queues and state_.
-  base::Lock lock_;
-  State state_;
-  Config::OutputMode output_mode_;
-
-  // Queue of available InputBuffers (picture_buffer_ids).
-  base::queue<std::unique_ptr<InputBuffer>> input_buffers_;
-  // Signalled when input buffers are queued onto |input_buffers_| queue.
-  base::ConditionVariable input_ready_;
-
-  // Current input buffer at decoder.
-  std::unique_ptr<InputBuffer> curr_input_buffer_;
-
-  // Queue for incoming output buffers (texture ids).
-  using OutputBuffers = base::queue<int32_t>;
-  OutputBuffers output_buffers_;
-
-  std::unique_ptr<VaapiPictureFactory> vaapi_picture_factory_;
-
-  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
-
-  // All allocated Pictures, regardless of their current state. Pictures are
-  // allocated once using |create_vaapi_picture_callback_| and destroyed at the
-  // end of decode. Comes after |vaapi_wrapper_| to ensure all pictures are
-  // destroyed before said |vaapi_wrapper_| is destroyed.
-  using Pictures = std::map<int32_t, std::unique_ptr<VaapiPicture>>;
-  Pictures pictures_;
-
-  // Return a VaapiPicture associated with given client-provided id.
-  VaapiPicture* PictureById(int32_t picture_buffer_id);
-
-  // VA Surfaces no longer in use that can be passed back to the decoder for
-  // reuse, once it requests them.
-  std::list<VASurfaceID> available_va_surfaces_;
-  // Signalled when output surfaces are queued onto the available_va_surfaces_
-  // queue.
-  base::ConditionVariable surfaces_available_;
-
-  // Pending output requests from the decoder. When it indicates that we should
-  // output a surface and we have an available Picture (i.e. texture) ready
-  // to use, we'll execute the callback passing the Picture. The callback
-  // will put the contents of the surface into the picture and return it to
-  // the client, releasing the surface as well.
-  // If we don't have any available Pictures at the time when the decoder
-  // requests output, we'll store the request on pending_output_cbs_ queue for
-  // later and run it once the client gives us more textures
-  // via ReusePictureBuffer().
-  using OutputCB = base::Callback<void(VaapiPicture*)>;
-  base::queue<OutputCB> pending_output_cbs_;
-
-  // ChildThread's task runner.
-  scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
-
-  // WeakPtr<> pointing to |this| for use in posting tasks from the decoder
-  // thread back to the ChildThread.  Because the decoder thread is a member of
-  // this class, any task running on the decoder thread is guaranteed that this
-  // object is still alive.  As a result, tasks posted from ChildThread to
-  // decoder thread should use base::Unretained(this), and tasks posted from the
-  // decoder thread to the ChildThread should use |weak_this_|.
-  base::WeakPtr<VaapiVideoDecodeAccelerator> weak_this_;
-
-  // Callback used when creating VASurface objects.
-  VASurface::ReleaseCB va_surface_release_cb_;
-
-  // To expose client callbacks from VideoDecodeAccelerator.
-  // NOTE: all calls to these objects *MUST* be executed on task_runner_.
-  std::unique_ptr<base::WeakPtrFactory<Client>> client_ptr_factory_;
-  base::WeakPtr<Client> client_;
-
-  // Accelerators come after vaapi_wrapper_ to ensure they are destroyed first.
-  std::unique_ptr<VaapiH264Accelerator> h264_accelerator_;
-  std::unique_ptr<VaapiVP8Accelerator> vp8_accelerator_;
-  std::unique_ptr<VaapiVP9Accelerator> vp9_accelerator_;
-  // After *_accelerator_ to ensure correct destruction order.
-  std::unique_ptr<AcceleratedVideoDecoder> decoder_;
-
-  base::Thread decoder_thread_;
-  // Use this to post tasks to |decoder_thread_| instead of
-  // |decoder_thread_.message_loop()| because the latter will be NULL once
-  // |decoder_thread_.Stop()| returns.
-  scoped_refptr<base::SingleThreadTaskRunner> decoder_thread_task_runner_;
-
-  int num_frames_at_client_;
-
-  // Whether we are waiting for any pending_output_cbs_ to be run before
-  // NotifyingFlushDone.
-  bool finish_flush_pending_;
-
-  // Decoder requested a new surface set and we are waiting for all the surfaces
-  // to be returned before we can free them.
-  bool awaiting_va_surfaces_recycle_;
-
-  // Last requested number/resolution of output picture buffers and their
-  // format.
-  size_t requested_num_pics_;
-  gfx::Size requested_pic_size_;
-  gfx::BufferFormat output_format_;
-  VideoCodecProfile profile_;
-
-  // Callback to make GL context current.
-  MakeGLContextCurrentCallback make_context_current_cb_;
-
-  // Callback to bind a GLImage to a given texture.
-  BindGLImageCallback bind_image_cb_;
-
-  // The WeakPtrFactory for |weak_this_|.
-  base::WeakPtrFactory<VaapiVideoDecodeAccelerator> weak_this_factory_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVideoDecodeAccelerator);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
--- a/media/gpu/vaapi_video_decode_accelerator_unittest.cc
+++ /dev/null
@@ -1,367 +0,0 @@
-// Copyright 2017 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_video_decode_accelerator.h"
-
-#include "base/bind.h"
-#include "base/memory/ptr_util.h"
-#include "base/run_loop.h"
-#include "base/test/scoped_task_environment.h"
-#include "media/gpu/accelerated_video_decoder.h"
-#include "media/gpu/format_utils.h"
-#include "media/gpu/vaapi/vaapi_picture.h"
-#include "media/gpu/vaapi/vaapi_picture_factory.h"
-#include "media/gpu/vaapi_wrapper.h"
-#include "testing/gmock/include/gmock/gmock.h"
-#include "testing/gtest/include/gtest/gtest.h"
-
-using ::testing::_;
-using ::testing::DoAll;
-using ::testing::Invoke;
-using ::testing::Return;
-using ::testing::TestWithParam;
-using ::testing::ValuesIn;
-using ::testing::WithArgs;
-
-namespace media {
-
-namespace {
-
-ACTION_P(RunClosure, closure) {
-  closure.Run();
-}
-
-constexpr VideoCodecProfile kCodecProfiles[] = {H264PROFILE_MIN, VP8PROFILE_MIN,
-                                                VP9PROFILE_MIN};
-constexpr int kBitstreamId = 123;
-constexpr size_t kInputSize = 256;
-
-}  // namespace
-
-class MockAcceleratedVideoDecoder : public AcceleratedVideoDecoder {
- public:
-  MockAcceleratedVideoDecoder() = default;
-  ~MockAcceleratedVideoDecoder() override = default;
-
-  MOCK_METHOD2(SetStream, void(const uint8_t* ptr, size_t size));
-  MOCK_METHOD0(Flush, bool());
-  MOCK_METHOD0(Reset, void());
-  MOCK_METHOD0(Decode, DecodeResult());
-  MOCK_CONST_METHOD0(GetPicSize, gfx::Size());
-  MOCK_CONST_METHOD0(GetRequiredNumOfPictures, size_t());
-};
-
-class MockVaapiWrapper : public VaapiWrapper {
- public:
-  MockVaapiWrapper() = default;
-  MOCK_METHOD4(
-      CreateSurfaces,
-      bool(unsigned int, const gfx::Size&, size_t, std::vector<VASurfaceID>*));
-  MOCK_METHOD0(DestroySurfaces, void());
-
- private:
-  ~MockVaapiWrapper() override = default;
-};
-
-class MockVaapiPicture : public VaapiPicture {
- public:
-  MockVaapiPicture(const scoped_refptr<VaapiWrapper>& vaapi_wrapper,
-                   const MakeGLContextCurrentCallback& make_context_current_cb,
-                   const BindGLImageCallback& bind_image_cb,
-                   int32_t picture_buffer_id,
-                   const gfx::Size& size,
-                   uint32_t texture_id,
-                   uint32_t client_texture_id)
-      : VaapiPicture(vaapi_wrapper,
-                     make_context_current_cb,
-                     bind_image_cb,
-                     picture_buffer_id,
-                     size,
-                     texture_id,
-                     client_texture_id) {}
-  ~MockVaapiPicture() override = default;
-
-  // VaapiPicture implementation.
-  bool Allocate(gfx::BufferFormat format) override { return true; }
-  bool ImportGpuMemoryBufferHandle(
-      gfx::BufferFormat format,
-      const gfx::GpuMemoryBufferHandle& gpu_memory_buffer_handle) override {
-    return true;
-  }
-  bool DownloadFromSurface(
-      const scoped_refptr<VASurface>& va_surface) override {
-    return true;
-  }
-  bool AllowOverlay() const override { return false; }
-};
-
-class MockVaapiPictureFactory : public VaapiPictureFactory {
- public:
-  MockVaapiPictureFactory() = default;
-  ~MockVaapiPictureFactory() override = default;
-
-  MOCK_METHOD2(MockCreateVaapiPicture, void(VaapiWrapper*, const gfx::Size&));
-  std::unique_ptr<VaapiPicture> Create(
-      const scoped_refptr<VaapiWrapper>& vaapi_wrapper,
-      const MakeGLContextCurrentCallback& make_context_current_cb,
-      const BindGLImageCallback& bind_image_cb,
-      int32_t picture_buffer_id,
-      const gfx::Size& size,
-      uint32_t texture_id,
-      uint32_t client_texture_id) override {
-    MockCreateVaapiPicture(vaapi_wrapper.get(), size);
-    return std::make_unique<MockVaapiPicture>(
-        vaapi_wrapper, make_context_current_cb, bind_image_cb,
-        picture_buffer_id, size, texture_id, client_texture_id);
-  }
-};
-
-class VaapiVideoDecodeAcceleratorTest : public TestWithParam<VideoCodecProfile>,
-                                        public VideoDecodeAccelerator::Client {
- public:
-  VaapiVideoDecodeAcceleratorTest()
-      : vda_(base::Bind([] { return true; }),
-             base::Bind([](uint32_t client_texture_id,
-                           uint32_t texture_target,
-                           const scoped_refptr<gl::GLImage>& image,
-                           bool can_bind_to_sampler) { return true; })),
-        decoder_thread_("VaapiVideoDecodeAcceleratorTestThread"),
-        mock_decoder_(new MockAcceleratedVideoDecoder),
-        mock_vaapi_picture_factory_(new MockVaapiPictureFactory()),
-        mock_vaapi_wrapper_(new MockVaapiWrapper()),
-        weak_ptr_factory_(this) {
-    decoder_thread_.Start();
-
-    // Don't want to go through a vda_->Initialize() because it binds too many
-    // items of the environment. Instead, just start the decoder thread.
-    vda_.decoder_thread_task_runner_ = decoder_thread_.task_runner();
-
-    // Plug in all the mocks and ourselves as the |client_|.
-    vda_.decoder_.reset(mock_decoder_);
-    vda_.client_ = weak_ptr_factory_.GetWeakPtr();
-    vda_.vaapi_wrapper_ = mock_vaapi_wrapper_;
-    vda_.vaapi_picture_factory_.reset(mock_vaapi_picture_factory_);
-
-    vda_.state_ = VaapiVideoDecodeAccelerator::kIdle;
-  }
-  ~VaapiVideoDecodeAcceleratorTest() {}
-
-  void SetUp() override {
-    in_shm_.reset(new base::SharedMemory);
-    ASSERT_TRUE(in_shm_->CreateAndMapAnonymous(kInputSize));
-  }
-
-  void SetVdaStateToUnitialized() {
-    vda_.state_ = VaapiVideoDecodeAccelerator::kUninitialized;
-  }
-
-  void QueueInputBuffer(const BitstreamBuffer& bitstream_buffer) {
-    vda_.QueueInputBuffer(bitstream_buffer);
-  }
-
-  void AssignPictureBuffers(const std::vector<PictureBuffer>& picture_buffers) {
-    vda_.AssignPictureBuffers(picture_buffers);
-  }
-
-  // Reset epilogue, needed to get |vda_| worker thread out of its Wait().
-  void ResetSequence() {
-    base::RunLoop run_loop;
-    base::Closure quit_closure = run_loop.QuitClosure();
-    EXPECT_CALL(*mock_decoder_, Reset());
-    EXPECT_CALL(*this, NotifyResetDone()).WillOnce(RunClosure(quit_closure));
-    vda_.Reset();
-    run_loop.Run();
-  }
-
-  // VideoDecodeAccelerator::Client methods.
-  MOCK_METHOD1(NotifyInitializationComplete, void(bool));
-  MOCK_METHOD5(
-      ProvidePictureBuffers,
-      void(uint32_t, VideoPixelFormat, uint32_t, const gfx::Size&, uint32_t));
-  MOCK_METHOD1(DismissPictureBuffer, void(int32_t));
-  MOCK_METHOD1(PictureReady, void(const Picture&));
-  MOCK_METHOD1(NotifyEndOfBitstreamBuffer, void(int32_t));
-  MOCK_METHOD0(NotifyFlushDone, void());
-  MOCK_METHOD0(NotifyResetDone, void());
-  MOCK_METHOD1(NotifyError, void(VideoDecodeAccelerator::Error));
-
-  base::test::ScopedTaskEnvironment scoped_task_environment_;
-
-  // The class under test and a worker thread for it.
-  VaapiVideoDecodeAccelerator vda_;
-  base::Thread decoder_thread_;
-
-  // Ownership passed to |vda_|, but we retain a pointer to it for MOCK checks.
-  MockAcceleratedVideoDecoder* mock_decoder_;
-  MockVaapiPictureFactory* mock_vaapi_picture_factory_;
-
-  scoped_refptr<MockVaapiWrapper> mock_vaapi_wrapper_;
-
-  std::unique_ptr<base::SharedMemory> in_shm_;
-
- private:
-  base::WeakPtrFactory<VaapiVideoDecodeAcceleratorTest> weak_ptr_factory_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVideoDecodeAcceleratorTest);
-};
-
-// This test checks that QueueInputBuffer() fails when state is kUnitialized.
-TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndError) {
-  SetVdaStateToUnitialized();
-
-  base::SharedMemoryHandle handle;
-  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
-  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
-
-  EXPECT_CALL(*this,
-              NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE));
-  QueueInputBuffer(bitstream_buffer);
-}
-
-// Verifies that Decode() returning kDecodeError ends up pinging NotifyError().
-TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndDecodeError) {
-  base::SharedMemoryHandle handle;
-  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
-  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
-
-  base::RunLoop run_loop;
-  base::Closure quit_closure = run_loop.QuitClosure();
-  EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
-  EXPECT_CALL(*mock_decoder_, Decode())
-      .WillOnce(Return(AcceleratedVideoDecoder::kDecodeError));
-  EXPECT_CALL(*this, NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE))
-      .WillOnce(RunClosure(quit_closure));
-
-  QueueInputBuffer(bitstream_buffer);
-  run_loop.Run();
-}
-
-// Tests usual startup sequence: a BitstreamBuffer is enqueued for decode,
-// |vda_| asks for PictureBuffers, that we provide, and then the same Decode()
-// is tried again.
-TEST_P(VaapiVideoDecodeAcceleratorTest,
-       QueueInputBufferAndAssignPictureBuffersAndDecode) {
-  // Try and QueueInputBuffer(), |vda_| will ping us to ProvidePictureBuffers().
-  const uint32_t kNumPictures = 2;
-  const gfx::Size kPictureSize(64, 48);
-  {
-    base::SharedMemoryHandle handle;
-    handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
-    BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
-
-    base::RunLoop run_loop;
-    base::Closure quit_closure = run_loop.QuitClosure();
-    EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
-    EXPECT_CALL(*mock_decoder_, Decode())
-        .WillOnce(Return(AcceleratedVideoDecoder::kAllocateNewSurfaces));
-
-    EXPECT_CALL(*mock_decoder_, GetRequiredNumOfPictures())
-        .WillOnce(Return(kNumPictures));
-    EXPECT_CALL(*mock_decoder_, GetPicSize()).WillOnce(Return(kPictureSize));
-    EXPECT_CALL(*mock_vaapi_wrapper_, DestroySurfaces());
-
-    EXPECT_CALL(*this,
-                ProvidePictureBuffers(kNumPictures, _, 1, kPictureSize, _))
-        .WillOnce(RunClosure(quit_closure));
-
-    QueueInputBuffer(bitstream_buffer);
-    run_loop.Run();
-  }
-  // AssignPictureBuffers() accordingly and expect another go at Decode().
-  {
-    base::RunLoop run_loop;
-    base::Closure quit_closure = run_loop.QuitClosure();
-
-    const std::vector<PictureBuffer> kPictureBuffers(
-        {{2, kPictureSize}, {3, kPictureSize}});
-    EXPECT_EQ(kPictureBuffers.size(), kNumPictures);
-
-    EXPECT_CALL(*mock_vaapi_wrapper_,
-                CreateSurfaces(_, kPictureSize, kNumPictures, _))
-        .WillOnce(DoAll(
-            WithArgs<3>(Invoke([](std::vector<VASurfaceID>* va_surface_ids) {
-              va_surface_ids->resize(kNumPictures);
-            })),
-            Return(true)));
-    EXPECT_CALL(*mock_vaapi_picture_factory_,
-                MockCreateVaapiPicture(mock_vaapi_wrapper_.get(), kPictureSize))
-        .Times(2);
-
-    EXPECT_CALL(*mock_decoder_, Decode())
-        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
-    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(kBitstreamId))
-        .WillOnce(RunClosure(quit_closure));
-
-    AssignPictureBuffers(kPictureBuffers);
-    run_loop.Run();
-  }
-
-  ResetSequence();
-}
-
-// Verifies that Decode() replying kRanOutOfStreamData (to signal it's finished)
-// rolls to a NotifyEndOfBitstreamBuffer().
-TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndDecodeFinished) {
-  base::SharedMemoryHandle handle;
-  handle = base::SharedMemory::DuplicateHandle(in_shm_->handle());
-  BitstreamBuffer bitstream_buffer(kBitstreamId, handle, kInputSize);
-
-  {
-    base::RunLoop run_loop;
-    base::Closure quit_closure = run_loop.QuitClosure();
-    EXPECT_CALL(*mock_decoder_, SetStream(_, kInputSize));
-    EXPECT_CALL(*mock_decoder_, Decode())
-        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
-    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(kBitstreamId))
-        .WillOnce(RunClosure(quit_closure));
-
-    QueueInputBuffer(bitstream_buffer);
-    run_loop.Run();
-  }
-
-  ResetSequence();
-}
-
-// Verify that it is possible to select DRM(egl) and TFP(glx) at runtime.
-TEST_P(VaapiVideoDecodeAcceleratorTest, SupportedPlatforms) {
-  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationNone,
-            mock_vaapi_picture_factory_->GetVaapiImplementation(
-                gl::kGLImplementationNone));
-  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationDrm,
-            mock_vaapi_picture_factory_->GetVaapiImplementation(
-                gl::kGLImplementationEGLGLES2));
-
-#if defined(USE_X11)
-  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationX11,
-            mock_vaapi_picture_factory_->GetVaapiImplementation(
-                gl::kGLImplementationDesktopGL));
-#endif
-}
-
-// Verifies the expected buffer format for each output mode.
-TEST_P(VaapiVideoDecodeAcceleratorTest, PictureBufferFormat) {
-  gfx::BufferFormat allocate_format =
-      mock_vaapi_picture_factory_->GetBufferFormatForAllocateMode();
-  gfx::BufferFormat import_format =
-      mock_vaapi_picture_factory_->GetBufferFormatForImportMode();
-
-#if defined(USE_OZONE)
-  EXPECT_EQ(gfx::BufferFormat::BGRX_8888, allocate_format);
-#else
-  EXPECT_EQ(gfx::BufferFormat::RGBX_8888, allocate_format);
-#endif  // USE_OZONE
-
-  EXPECT_EQ(gfx::BufferFormat::YVU_420, import_format);
-
-  EXPECT_EQ(PIXEL_FORMAT_XRGB,
-            GfxBufferFormatToVideoPixelFormat(allocate_format));
-  EXPECT_EQ(PIXEL_FORMAT_YV12,
-            GfxBufferFormatToVideoPixelFormat(import_format));
-}
-
-INSTANTIATE_TEST_CASE_P(/* No prefix. */,
-                        VaapiVideoDecodeAcceleratorTest,
-                        ValuesIn(kCodecProfiles));
-
-}  // namespace media
--- a/media/gpu/vaapi_video_encode_accelerator.cc
+++ /dev/null
@@ -1,1102 +0,0 @@
-// Copyright 2014 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_video_encode_accelerator.h"
-
-#include <string.h>
-
-#include <memory>
-#include <utility>
-
-#include <va/va.h>
-
-#include "base/bind.h"
-#include "base/callback.h"
-#include "base/macros.h"
-#include "base/metrics/histogram_macros.h"
-#include "base/numerics/safe_conversions.h"
-#include "base/single_thread_task_runner.h"
-#include "base/threading/thread_task_runner_handle.h"
-#include "media/base/bind_to_current_loop.h"
-#include "media/gpu/h264_dpb.h"
-#include "media/gpu/shared_memory_region.h"
-
-#define VLOGF(level) VLOG(level) << __func__ << "(): "
-#define DVLOGF(level) DVLOG(level) << __func__ << "(): "
-
-#define NOTIFY_ERROR(error, msg)                        \
-  do {                                                  \
-    SetState(kError);                                   \
-    VLOGF(1) << msg;                                    \
-    VLOGF(1) << "Calling NotifyError(" << error << ")"; \
-    NotifyError(error);                                 \
-  } while (0)
-
-namespace media {
-
-namespace {
-// Need 2 surfaces for each frame: one for input data and one for
-// reconstructed picture, which is later used for reference.
-const size_t kMinSurfacesToEncode = 2;
-
-// Subjectively chosen.
-const size_t kNumInputBuffers = 4;
-const size_t kMaxNumReferenceFrames = 4;
-
-// TODO(owenlin): Adjust the value after b/71367113 is fixed.
-const size_t kExtraOutputBufferSize = 32768;  // bytes
-
-// We need up to kMaxNumReferenceFrames surfaces for reference, plus one
-// for input and one for encode (which will be added to the set of reference
-// frames for subsequent frames). Actual execution of HW encode is done
-// in parallel, and we want to process more frames in the meantime.
-// To have kNumInputBuffers in flight, we need a full set of reference +
-// encode surfaces (i.e. kMaxNumReferenceFrames + kMinSurfacesToEncode), and
-// (kNumInputBuffers - 1) of kMinSurfacesToEncode for the remaining frames
-// in flight.
-const size_t kNumSurfaces = kMaxNumReferenceFrames + kMinSurfacesToEncode +
-                            kMinSurfacesToEncode * (kNumInputBuffers - 1);
-
-// An IDR every 2048 frames, an I frame every 256 and no B frames.
-// We choose IDR period to equal MaxFrameNum so it must be a power of 2.
-const int kIDRPeriod = 2048;
-const int kIPeriod = 256;
-const int kIPPeriod = 1;
-
-const int kDefaultFramerate = 30;
-
-// HRD parameters (ch. E.2.2 in spec).
-const int kBitRateScale = 0;  // bit_rate_scale for SPS HRD parameters.
-const int kCPBSizeScale = 0;  // cpb_size_scale for SPS HRD parameters.
-
-const int kDefaultQP = 26;
-// All Intel codecs can do at least 4.1.
-const int kDefaultLevelIDC = 41;
-const int kChromaFormatIDC = 1;  // 4:2:0
-
-// Arbitrarily chosen bitrate window size for rate control, in ms.
-const int kCPBWindowSizeMs = 1500;
-
-// UMA errors that the VaapiVideoEncodeAccelerator class reports.
-enum VAVEAEncoderFailure {
-  VAAPI_ERROR = 0,
-  VAVEA_ENCODER_FAILURES_MAX,
-};
-}
-
-// Round |value| up to |alignment|, which must be a power of 2.
-static inline size_t RoundUpToPowerOf2(size_t value, size_t alignment) {
-  // Check that |alignment| is a power of 2.
-  DCHECK((alignment + (alignment - 1)) == (alignment | (alignment - 1)));
-  return ((value + (alignment - 1)) & ~(alignment - 1));
-}
-
-static void ReportToUMA(VAVEAEncoderFailure failure) {
-  UMA_HISTOGRAM_ENUMERATION("Media.VAVEA.EncoderFailure", failure,
-                            VAVEA_ENCODER_FAILURES_MAX + 1);
-}
-
-struct VaapiVideoEncodeAccelerator::InputFrameRef {
-  InputFrameRef(const scoped_refptr<VideoFrame>& frame, bool force_keyframe)
-      : frame(frame), force_keyframe(force_keyframe) {}
-  const scoped_refptr<VideoFrame> frame;
-  const bool force_keyframe;
-};
-
-struct VaapiVideoEncodeAccelerator::BitstreamBufferRef {
-  BitstreamBufferRef(int32_t id, std::unique_ptr<SharedMemoryRegion> shm)
-      : id(id), shm(std::move(shm)) {}
-  const int32_t id;
-  const std::unique_ptr<SharedMemoryRegion> shm;
-};
-
-VideoEncodeAccelerator::SupportedProfiles
-VaapiVideoEncodeAccelerator::GetSupportedProfiles() {
-  return VaapiWrapper::GetSupportedEncodeProfiles();
-}
-
-static unsigned int Log2OfPowerOf2(unsigned int x) {
-  CHECK_GT(x, 0u);
-  DCHECK_EQ(x & (x - 1), 0u);
-
-  int log = 0;
-  while (x > 1) {
-    x >>= 1;
-    ++log;
-  }
-  return log;
-}
-
-VaapiVideoEncodeAccelerator::VaapiVideoEncodeAccelerator()
-    : profile_(VIDEO_CODEC_PROFILE_UNKNOWN),
-      mb_width_(0),
-      mb_height_(0),
-      output_buffer_byte_size_(0),
-      state_(kUninitialized),
-      frame_num_(0),
-      idr_pic_id_(0),
-      bitrate_(0),
-      framerate_(0),
-      cpb_size_(0),
-      encoding_parameters_changed_(false),
-      encoder_thread_("VAVEAEncoderThread"),
-      child_task_runner_(base::ThreadTaskRunnerHandle::Get()),
-      weak_this_ptr_factory_(this) {
-  VLOGF(2);
-  weak_this_ = weak_this_ptr_factory_.GetWeakPtr();
-  max_ref_idx_l0_size_ = kMaxNumReferenceFrames;
-  qp_ = kDefaultQP;
-  idr_period_ = kIDRPeriod;
-  i_period_ = kIPeriod;
-  ip_period_ = kIPPeriod;
-}
-
-VaapiVideoEncodeAccelerator::~VaapiVideoEncodeAccelerator() {
-  VLOGF(2);
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-  DCHECK(!encoder_thread_.IsRunning());
-}
-
-bool VaapiVideoEncodeAccelerator::Initialize(
-    VideoPixelFormat format,
-    const gfx::Size& input_visible_size,
-    VideoCodecProfile output_profile,
-    uint32_t initial_bitrate,
-    Client* client) {
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-  DCHECK(!encoder_thread_.IsRunning());
-  DCHECK_EQ(state_, kUninitialized);
-
-  VLOGF(2) << "Initializing VAVEA, input_format: "
-           << VideoPixelFormatToString(format)
-           << ", input_visible_size: " << input_visible_size.ToString()
-           << ", output_profile: " << GetProfileName(output_profile)
-           << ", initial_bitrate: " << initial_bitrate;
-
-  client_ptr_factory_.reset(new base::WeakPtrFactory<Client>(client));
-  client_ = client_ptr_factory_->GetWeakPtr();
-
-  const SupportedProfiles& profiles = GetSupportedProfiles();
-  auto profile = find_if(profiles.begin(), profiles.end(),
-                         [output_profile](const SupportedProfile& profile) {
-                           return profile.profile == output_profile;
-                         });
-  if (profile == profiles.end()) {
-    VLOGF(1) << "Unsupported output profile " << GetProfileName(output_profile);
-    return false;
-  }
-  if (input_visible_size.width() > profile->max_resolution.width() ||
-      input_visible_size.height() > profile->max_resolution.height()) {
-    VLOGF(1) << "Input size too big: " << input_visible_size.ToString()
-             << ", max supported size: " << profile->max_resolution.ToString();
-    return false;
-  }
-
-  if (format != PIXEL_FORMAT_I420) {
-    VLOGF(1) << "Unsupported input format: "
-             << VideoPixelFormatToString(format);
-    return false;
-  }
-
-  profile_ = output_profile;
-  visible_size_ = input_visible_size;
-  // 4:2:0 format has to be 2-aligned.
-  DCHECK_EQ(visible_size_.width() % 2, 0);
-  DCHECK_EQ(visible_size_.height() % 2, 0);
-  coded_size_ = gfx::Size(RoundUpToPowerOf2(visible_size_.width(), 16),
-                          RoundUpToPowerOf2(visible_size_.height(), 16));
-  mb_width_ = coded_size_.width() / 16;
-  mb_height_ = coded_size_.height() / 16;
-  output_buffer_byte_size_ = coded_size_.GetArea() + kExtraOutputBufferSize;
-
-  UpdateRates(initial_bitrate, kDefaultFramerate);
-
-  vaapi_wrapper_ =
-      VaapiWrapper::CreateForVideoCodec(VaapiWrapper::kEncode, output_profile,
-                                        base::Bind(&ReportToUMA, VAAPI_ERROR));
-  if (!vaapi_wrapper_.get()) {
-    VLOGF(1) << "Failed initializing VAAPI for profile "
-             << GetProfileName(output_profile);
-    return false;
-  }
-
-  if (!encoder_thread_.Start()) {
-    VLOGF(1) << "Failed to start encoder thread";
-    return false;
-  }
-  encoder_thread_task_runner_ = encoder_thread_.task_runner();
-
-  // Finish the remaining initialization on the encoder thread.
-  encoder_thread_task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::InitializeTask,
-                            base::Unretained(this)));
-
-  return true;
-}
-
-void VaapiVideoEncodeAccelerator::InitializeTask() {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK_EQ(state_, kUninitialized);
-  VLOGF(2);
-
-  va_surface_release_cb_ = BindToCurrentLoop(
-      base::Bind(&VaapiVideoEncodeAccelerator::RecycleVASurfaceID,
-                 base::Unretained(this)));
-
-  if (!vaapi_wrapper_->CreateSurfaces(VA_RT_FORMAT_YUV420, coded_size_,
-                                      kNumSurfaces,
-                                      &available_va_surface_ids_)) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed creating VASurfaces");
-    return;
-  }
-
-  UpdateSPS();
-  GeneratePackedSPS();
-
-  UpdatePPS();
-  GeneratePackedPPS();
-
-  child_task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(&Client::RequireBitstreamBuffers, client_, kNumInputBuffers,
-                 coded_size_, output_buffer_byte_size_));
-
-  SetState(kEncoding);
-}
-
-void VaapiVideoEncodeAccelerator::RecycleVASurfaceID(
-    VASurfaceID va_surface_id) {
-  DVLOGF(4) << "va_surface_id: " << va_surface_id;
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-
-  available_va_surface_ids_.push_back(va_surface_id);
-  EncodeFrameTask();
-}
-
-void VaapiVideoEncodeAccelerator::BeginFrame(bool force_keyframe) {
-  current_pic_ = new H264Picture();
-
-  // If the current picture is an IDR picture, frame_num shall be equal to 0.
-  if (force_keyframe)
-    frame_num_ = 0;
-
-  current_pic_->frame_num = frame_num_++;
-  frame_num_ %= idr_period_;
-
-  if (current_pic_->frame_num == 0) {
-    current_pic_->idr = true;
-    // H264 spec mandates idr_pic_id to differ between two consecutive IDRs.
-    idr_pic_id_ ^= 1;
-    ref_pic_list0_.clear();
-  }
-
-  if (current_pic_->frame_num % i_period_ == 0)
-    current_pic_->type = H264SliceHeader::kISlice;
-  else
-    current_pic_->type = H264SliceHeader::kPSlice;
-
-  if (current_pic_->type != H264SliceHeader::kBSlice)
-    current_pic_->ref = true;
-
-  current_pic_->pic_order_cnt = current_pic_->frame_num * 2;
-  current_pic_->top_field_order_cnt = current_pic_->pic_order_cnt;
-  current_pic_->pic_order_cnt_lsb = current_pic_->pic_order_cnt;
-
-  current_encode_job_->keyframe = current_pic_->idr;
-
-  DVLOGF(4) << "Starting a new frame, type: " << current_pic_->type
-            << (force_keyframe ? " (forced keyframe)" : "")
-            << " frame_num: " << current_pic_->frame_num
-            << " POC: " << current_pic_->pic_order_cnt;
-}
-
-void VaapiVideoEncodeAccelerator::EndFrame() {
-  DCHECK(current_pic_);
-  // Store the picture on the list of reference pictures and keep the list
-  // below maximum size, dropping oldest references.
-  if (current_pic_->ref)
-    ref_pic_list0_.push_front(current_encode_job_->recon_surface);
-  size_t max_num_ref_frames =
-      base::checked_cast<size_t>(current_sps_.max_num_ref_frames);
-  while (ref_pic_list0_.size() > max_num_ref_frames)
-    ref_pic_list0_.pop_back();
-
-  submitted_encode_jobs_.push(make_linked_ptr(current_encode_job_.release()));
-}
-
-static void InitVAPicture(VAPictureH264* va_pic) {
-  memset(va_pic, 0, sizeof(*va_pic));
-  va_pic->picture_id = VA_INVALID_ID;
-  va_pic->flags = VA_PICTURE_H264_INVALID;
-}
-
-bool VaapiVideoEncodeAccelerator::SubmitFrameParameters() {
-  DCHECK(current_pic_);
-  VAEncSequenceParameterBufferH264 seq_param;
-  memset(&seq_param, 0, sizeof(seq_param));
-
-#define SPS_TO_SP(a) seq_param.a = current_sps_.a;
-  SPS_TO_SP(seq_parameter_set_id);
-  SPS_TO_SP(level_idc);
-
-  seq_param.intra_period = i_period_;
-  seq_param.intra_idr_period = idr_period_;
-  seq_param.ip_period = ip_period_;
-  seq_param.bits_per_second = bitrate_;
-
-  SPS_TO_SP(max_num_ref_frames);
-  seq_param.picture_width_in_mbs = mb_width_;
-  seq_param.picture_height_in_mbs = mb_height_;
-
-#define SPS_TO_SP_FS(a) seq_param.seq_fields.bits.a = current_sps_.a;
-  SPS_TO_SP_FS(chroma_format_idc);
-  SPS_TO_SP_FS(frame_mbs_only_flag);
-  SPS_TO_SP_FS(log2_max_frame_num_minus4);
-  SPS_TO_SP_FS(pic_order_cnt_type);
-  SPS_TO_SP_FS(log2_max_pic_order_cnt_lsb_minus4);
-#undef SPS_TO_SP_FS
-
-  SPS_TO_SP(bit_depth_luma_minus8);
-  SPS_TO_SP(bit_depth_chroma_minus8);
-
-  SPS_TO_SP(frame_cropping_flag);
-  if (current_sps_.frame_cropping_flag) {
-    SPS_TO_SP(frame_crop_left_offset);
-    SPS_TO_SP(frame_crop_right_offset);
-    SPS_TO_SP(frame_crop_top_offset);
-    SPS_TO_SP(frame_crop_bottom_offset);
-  }
-
-  SPS_TO_SP(vui_parameters_present_flag);
-#define SPS_TO_SP_VF(a) seq_param.vui_fields.bits.a = current_sps_.a;
-  SPS_TO_SP_VF(timing_info_present_flag);
-#undef SPS_TO_SP_VF
-  SPS_TO_SP(num_units_in_tick);
-  SPS_TO_SP(time_scale);
-#undef SPS_TO_SP
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncSequenceParameterBufferType,
-                                    sizeof(seq_param), &seq_param))
-    return false;
-
-  VAEncPictureParameterBufferH264 pic_param;
-  memset(&pic_param, 0, sizeof(pic_param));
-
-  pic_param.CurrPic.picture_id = current_encode_job_->recon_surface->id();
-  pic_param.CurrPic.TopFieldOrderCnt = current_pic_->top_field_order_cnt;
-  pic_param.CurrPic.BottomFieldOrderCnt = current_pic_->bottom_field_order_cnt;
-  pic_param.CurrPic.flags = 0;
-
-  for (size_t i = 0; i < arraysize(pic_param.ReferenceFrames); ++i)
-    InitVAPicture(&pic_param.ReferenceFrames[i]);
-
-  DCHECK_LE(ref_pic_list0_.size(), arraysize(pic_param.ReferenceFrames));
-  RefPicList::const_iterator iter = ref_pic_list0_.begin();
-  for (size_t i = 0;
-       i < arraysize(pic_param.ReferenceFrames) && iter != ref_pic_list0_.end();
-       ++iter, ++i) {
-    pic_param.ReferenceFrames[i].picture_id = (*iter)->id();
-    pic_param.ReferenceFrames[i].flags = 0;
-  }
-
-  pic_param.coded_buf = current_encode_job_->coded_buffer;
-  pic_param.pic_parameter_set_id = current_pps_.pic_parameter_set_id;
-  pic_param.seq_parameter_set_id = current_pps_.seq_parameter_set_id;
-  pic_param.frame_num = current_pic_->frame_num;
-  pic_param.pic_init_qp = qp_;
-  pic_param.num_ref_idx_l0_active_minus1 = max_ref_idx_l0_size_ - 1;
-  pic_param.pic_fields.bits.idr_pic_flag = current_pic_->idr;
-  pic_param.pic_fields.bits.reference_pic_flag = current_pic_->ref;
-#define PPS_TO_PP_PF(a) pic_param.pic_fields.bits.a = current_pps_.a;
-  PPS_TO_PP_PF(entropy_coding_mode_flag);
-  PPS_TO_PP_PF(transform_8x8_mode_flag);
-  PPS_TO_PP_PF(deblocking_filter_control_present_flag);
-#undef PPS_TO_PP_PF
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPictureParameterBufferType,
-                                    sizeof(pic_param), &pic_param))
-    return false;
-
-  VAEncSliceParameterBufferH264 slice_param;
-  memset(&slice_param, 0, sizeof(slice_param));
-
-  slice_param.num_macroblocks = mb_width_ * mb_height_;
-  slice_param.macroblock_info = VA_INVALID_ID;
-  slice_param.slice_type = current_pic_->type;
-  slice_param.pic_parameter_set_id = current_pps_.pic_parameter_set_id;
-  slice_param.idr_pic_id = idr_pic_id_;
-  slice_param.pic_order_cnt_lsb = current_pic_->pic_order_cnt_lsb;
-  slice_param.num_ref_idx_active_override_flag = true;
-
-  for (size_t i = 0; i < arraysize(slice_param.RefPicList0); ++i)
-    InitVAPicture(&slice_param.RefPicList0[i]);
-
-  for (size_t i = 0; i < arraysize(slice_param.RefPicList1); ++i)
-    InitVAPicture(&slice_param.RefPicList1[i]);
-
-  DCHECK_LE(ref_pic_list0_.size(), arraysize(slice_param.RefPicList0));
-  iter = ref_pic_list0_.begin();
-  for (size_t i = 0;
-       i < arraysize(slice_param.RefPicList0) && iter != ref_pic_list0_.end();
-       ++iter, ++i) {
-    InitVAPicture(&slice_param.RefPicList0[i]);
-    slice_param.RefPicList0[i].picture_id = (*iter)->id();
-    slice_param.RefPicList0[i].flags = 0;
-  }
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncSliceParameterBufferType,
-                                    sizeof(slice_param), &slice_param))
-    return false;
-
-  VAEncMiscParameterRateControl rate_control_param;
-  memset(&rate_control_param, 0, sizeof(rate_control_param));
-  rate_control_param.bits_per_second = bitrate_;
-  rate_control_param.target_percentage = 90;
-  rate_control_param.window_size = kCPBWindowSizeMs;
-  rate_control_param.initial_qp = qp_;
-  rate_control_param.rc_flags.bits.disable_frame_skip = true;
-
-  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
-          VAEncMiscParameterTypeRateControl, sizeof(rate_control_param),
-          &rate_control_param))
-    return false;
-
-  VAEncMiscParameterFrameRate framerate_param;
-  memset(&framerate_param, 0, sizeof(framerate_param));
-  framerate_param.framerate = framerate_;
-  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
-          VAEncMiscParameterTypeFrameRate, sizeof(framerate_param),
-          &framerate_param))
-    return false;
-
-  VAEncMiscParameterHRD hrd_param;
-  memset(&hrd_param, 0, sizeof(hrd_param));
-  hrd_param.buffer_size = cpb_size_;
-  hrd_param.initial_buffer_fullness = cpb_size_ / 2;
-  if (!vaapi_wrapper_->SubmitVAEncMiscParamBuffer(
-          VAEncMiscParameterTypeHRD, sizeof(hrd_param), &hrd_param))
-    return false;
-
-  return true;
-}
-
-bool VaapiVideoEncodeAccelerator::SubmitHeadersIfNeeded() {
-  DCHECK(current_pic_);
-  if (current_pic_->type != H264SliceHeader::kISlice)
-    return true;
-
-  // Submit SPS.
-  VAEncPackedHeaderParameterBuffer par_buffer;
-  memset(&par_buffer, 0, sizeof(par_buffer));
-  par_buffer.type = VAEncPackedHeaderSequence;
-  par_buffer.bit_length = packed_sps_.BytesInBuffer() * 8;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
-                                    sizeof(par_buffer), &par_buffer))
-    return false;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
-                                    packed_sps_.BytesInBuffer(),
-                                    packed_sps_.data()))
-    return false;
-
-  // Submit PPS.
-  memset(&par_buffer, 0, sizeof(par_buffer));
-  par_buffer.type = VAEncPackedHeaderPicture;
-  par_buffer.bit_length = packed_pps_.BytesInBuffer() * 8;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderParameterBufferType,
-                                    sizeof(par_buffer), &par_buffer))
-    return false;
-
-  if (!vaapi_wrapper_->SubmitBuffer(VAEncPackedHeaderDataBufferType,
-                                    packed_pps_.BytesInBuffer(),
-                                    packed_pps_.data()))
-    return false;
-
-  return true;
-}
-
-bool VaapiVideoEncodeAccelerator::ExecuteEncode() {
-  DCHECK(current_pic_);
-  DVLOGF(4) << "Encoding frame_num: " << current_pic_->frame_num;
-  return vaapi_wrapper_->ExecuteAndDestroyPendingBuffers(
-      current_encode_job_->input_surface->id());
-}
-
-bool VaapiVideoEncodeAccelerator::UploadFrame(
-    const scoped_refptr<VideoFrame>& frame) {
-  return vaapi_wrapper_->UploadVideoFrameToSurface(
-      frame, current_encode_job_->input_surface->id());
-}
-
-void VaapiVideoEncodeAccelerator::TryToReturnBitstreamBuffer() {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-
-  if (state_ != kEncoding)
-    return;
-
-  while (!submitted_encode_jobs_.empty()) {
-    linked_ptr<EncodeJob> encode_job = submitted_encode_jobs_.front();
-    // An null job indicates a flush command.
-    if (encode_job == nullptr) {
-      submitted_encode_jobs_.pop();
-      DVLOGF(2) << "FlushDone";
-      DCHECK(flush_callback_);
-      child_task_runner_->PostTask(
-          FROM_HERE, base::BindOnce(std::move(flush_callback_), true));
-      continue;
-    }
-
-    if (available_bitstream_buffers_.empty())
-      break;
-    auto buffer = available_bitstream_buffers_.front();
-
-    available_bitstream_buffers_.pop();
-    submitted_encode_jobs_.pop();
-
-    uint8_t* target_data = reinterpret_cast<uint8_t*>(buffer->shm->memory());
-
-    size_t data_size = 0;
-    if (!vaapi_wrapper_->DownloadAndDestroyCodedBuffer(
-            encode_job->coded_buffer, encode_job->input_surface->id(),
-            target_data, buffer->shm->size(), &data_size)) {
-      NOTIFY_ERROR(kPlatformFailureError, "Failed downloading coded buffer");
-      return;
-    }
-
-    DVLOGF(4) << "Returning bitstream buffer "
-              << (encode_job->keyframe ? "(keyframe)" : "")
-              << " id: " << buffer->id << " size: " << data_size;
-
-    child_task_runner_->PostTask(
-        FROM_HERE,
-        base::Bind(&Client::BitstreamBufferReady, client_, buffer->id,
-                   data_size, encode_job->keyframe, encode_job->timestamp));
-    break;
-  }
-}
-
-void VaapiVideoEncodeAccelerator::Encode(const scoped_refptr<VideoFrame>& frame,
-                                         bool force_keyframe) {
-  DVLOGF(4) << "Frame timestamp: " << frame->timestamp().InMilliseconds()
-            << " force_keyframe: " << force_keyframe;
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-
-  encoder_thread_task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::EncodeTask,
-                            base::Unretained(this), frame, force_keyframe));
-}
-
-bool VaapiVideoEncodeAccelerator::PrepareNextJob(base::TimeDelta timestamp) {
-  if (available_va_surface_ids_.size() < kMinSurfacesToEncode)
-    return false;
-
-  DCHECK(!current_encode_job_);
-  current_encode_job_.reset(new EncodeJob());
-
-  if (!vaapi_wrapper_->CreateCodedBuffer(output_buffer_byte_size_,
-                                         &current_encode_job_->coded_buffer)) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed creating coded buffer");
-    return false;
-  }
-
-  current_encode_job_->timestamp = timestamp;
-
-  current_encode_job_->input_surface = new VASurface(
-      available_va_surface_ids_.back(), coded_size_,
-      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_);
-  available_va_surface_ids_.pop_back();
-
-  current_encode_job_->recon_surface = new VASurface(
-      available_va_surface_ids_.back(), coded_size_,
-      vaapi_wrapper_->va_surface_format(), va_surface_release_cb_);
-  available_va_surface_ids_.pop_back();
-
-  // Reference surfaces are needed until the job is done, but they get
-  // removed from ref_pic_list0_ when it's full at the end of job submission.
-  // Keep refs to them along with the job and only release after sync.
-  current_encode_job_->reference_surfaces = ref_pic_list0_;
-
-  return true;
-}
-
-void VaapiVideoEncodeAccelerator::EncodeTask(
-    const scoped_refptr<VideoFrame>& frame,
-    bool force_keyframe) {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK_NE(state_, kUninitialized);
-
-  encoder_input_queue_.push(
-      make_linked_ptr(new InputFrameRef(frame, force_keyframe)));
-  EncodeFrameTask();
-}
-
-void VaapiVideoEncodeAccelerator::EncodeFrameTask() {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-
-  if (state_ != kEncoding || encoder_input_queue_.empty())
-    return;
-
-  if (!PrepareNextJob(encoder_input_queue_.front()->frame->timestamp())) {
-    DVLOGF(4) << "Not ready for next frame yet";
-    return;
-  }
-
-  linked_ptr<InputFrameRef> frame_ref = encoder_input_queue_.front();
-  encoder_input_queue_.pop();
-
-  if (!UploadFrame(frame_ref->frame)) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed uploading source frame to HW.");
-    return;
-  }
-
-  BeginFrame(frame_ref->force_keyframe || encoding_parameters_changed_);
-  encoding_parameters_changed_ = false;
-
-  if (!SubmitFrameParameters()) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting frame parameters.");
-    return;
-  }
-
-  if (!SubmitHeadersIfNeeded()) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting frame headers.");
-    return;
-  }
-
-  if (!ExecuteEncode()) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed submitting encode job to HW.");
-    return;
-  }
-
-  EndFrame();
-  TryToReturnBitstreamBuffer();
-}
-
-void VaapiVideoEncodeAccelerator::UseOutputBitstreamBuffer(
-    const BitstreamBuffer& buffer) {
-  DVLOGF(4) << "id: " << buffer.id();
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-
-  if (buffer.size() < output_buffer_byte_size_) {
-    NOTIFY_ERROR(kInvalidArgumentError, "Provided bitstream buffer too small");
-    return;
-  }
-
-  std::unique_ptr<SharedMemoryRegion> shm(
-      new SharedMemoryRegion(buffer, false));
-  if (!shm->Map()) {
-    NOTIFY_ERROR(kPlatformFailureError, "Failed mapping shared memory.");
-    return;
-  }
-
-  std::unique_ptr<BitstreamBufferRef> buffer_ref(
-      new BitstreamBufferRef(buffer.id(), std::move(shm)));
-
-  encoder_thread_task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(&VaapiVideoEncodeAccelerator::UseOutputBitstreamBufferTask,
-                 base::Unretained(this), base::Passed(&buffer_ref)));
-}
-
-void VaapiVideoEncodeAccelerator::UseOutputBitstreamBufferTask(
-    std::unique_ptr<BitstreamBufferRef> buffer_ref) {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK_NE(state_, kUninitialized);
-
-  available_bitstream_buffers_.push(make_linked_ptr(buffer_ref.release()));
-  TryToReturnBitstreamBuffer();
-}
-
-void VaapiVideoEncodeAccelerator::RequestEncodingParametersChange(
-    uint32_t bitrate,
-    uint32_t framerate) {
-  VLOGF(2) << "bitrate: " << bitrate << " framerate: " << framerate;
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-
-  encoder_thread_task_runner_->PostTask(
-      FROM_HERE,
-      base::Bind(
-          &VaapiVideoEncodeAccelerator::RequestEncodingParametersChangeTask,
-          base::Unretained(this), bitrate, framerate));
-}
-
-void VaapiVideoEncodeAccelerator::UpdateRates(uint32_t bitrate,
-                                              uint32_t framerate) {
-  if (encoder_thread_.IsRunning())
-    DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK_NE(bitrate, 0u);
-  DCHECK_NE(framerate, 0u);
-  bitrate_ = bitrate;
-  framerate_ = framerate;
-  cpb_size_ = bitrate_ * kCPBWindowSizeMs / 1000;
-}
-
-void VaapiVideoEncodeAccelerator::RequestEncodingParametersChangeTask(
-    uint32_t bitrate,
-    uint32_t framerate) {
-  VLOGF(2) << "bitrate: " << bitrate << " framerate: " << framerate;
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  DCHECK_NE(state_, kUninitialized);
-
-  // This is a workaround to zero being temporarily, as part of the initial
-  // setup, provided by the webrtc video encode and a zero bitrate and
-  // framerate not being accepted by VAAPI
-  // TODO: This code is common with v4l2_video_encode_accelerator.cc, perhaps
-  // it could be pulled up to RTCVideoEncoder
-  if (bitrate < 1)
-    bitrate = 1;
-  if (framerate < 1)
-    framerate = 1;
-
-  if (bitrate_ == bitrate && framerate_ == framerate)
-    return;
-
-  UpdateRates(bitrate, framerate);
-
-  UpdateSPS();
-  GeneratePackedSPS();
-
-  // Submit new parameters along with next frame that will be processed.
-  encoding_parameters_changed_ = true;
-}
-
-void VaapiVideoEncodeAccelerator::Flush(FlushCallback flush_callback) {
-  DVLOGF(2);
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-  if (flush_callback_) {
-    NOTIFY_ERROR(kIllegalStateError, "There is a pending flush");
-    std::move(flush_callback).Run(false);
-    return;
-  }
-  flush_callback_ = std::move(flush_callback);
-  encoder_thread_task_runner_->PostTask(
-      FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::FlushTask,
-                            base::Unretained(this)));
-}
-
-void VaapiVideoEncodeAccelerator::FlushTask() {
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-
-  // Insert an null job to indicate a flush command.
-  submitted_encode_jobs_.push(linked_ptr<EncodeJob>(nullptr));
-  TryToReturnBitstreamBuffer();
-}
-
-void VaapiVideoEncodeAccelerator::Destroy() {
-  DCHECK(child_task_runner_->BelongsToCurrentThread());
-
-  // Can't call client anymore after Destroy() returns.
-  client_ptr_factory_.reset();
-  weak_this_ptr_factory_.InvalidateWeakPtrs();
-
-  // Early-exit encoder tasks if they are running and join the thread.
-  if (encoder_thread_.IsRunning()) {
-    encoder_thread_.task_runner()->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::DestroyTask,
-                              base::Unretained(this)));
-    encoder_thread_.Stop();
-  }
-
-  if (flush_callback_)
-    std::move(flush_callback_).Run(false);
-
-  delete this;
-}
-
-void VaapiVideoEncodeAccelerator::DestroyTask() {
-  VLOGF(2);
-  DCHECK(encoder_thread_task_runner_->BelongsToCurrentThread());
-  SetState(kError);
-}
-
-void VaapiVideoEncodeAccelerator::UpdateSPS() {
-  memset(&current_sps_, 0, sizeof(H264SPS));
-
-  // Spec A.2 and A.3.
-  switch (profile_) {
-    case H264PROFILE_BASELINE:
-      // Due to crbug.com/345569, we don't distinguish between constrained
-      // and non-constrained baseline profiles. Since many codecs can't do
-      // non-constrained, and constrained is usually what we mean (and it's a
-      // subset of non-constrained), default to it.
-      current_sps_.profile_idc = H264SPS::kProfileIDCBaseline;
-      current_sps_.constraint_set0_flag = true;
-      break;
-    case H264PROFILE_MAIN:
-      current_sps_.profile_idc = H264SPS::kProfileIDCMain;
-      current_sps_.constraint_set1_flag = true;
-      break;
-    case H264PROFILE_HIGH:
-      current_sps_.profile_idc = H264SPS::kProfileIDCHigh;
-      break;
-    default:
-      NOTIMPLEMENTED();
-      return;
-  }
-
-  current_sps_.level_idc = kDefaultLevelIDC;
-  current_sps_.seq_parameter_set_id = 0;
-  current_sps_.chroma_format_idc = kChromaFormatIDC;
-
-  DCHECK_GE(idr_period_, 1u << 4);
-  current_sps_.log2_max_frame_num_minus4 = Log2OfPowerOf2(idr_period_) - 4;
-  current_sps_.pic_order_cnt_type = 0;
-  current_sps_.log2_max_pic_order_cnt_lsb_minus4 =
-      Log2OfPowerOf2(idr_period_ * 2) - 4;
-  current_sps_.max_num_ref_frames = max_ref_idx_l0_size_;
-
-  current_sps_.frame_mbs_only_flag = true;
-
-  DCHECK_GT(mb_width_, 0u);
-  DCHECK_GT(mb_height_, 0u);
-  current_sps_.pic_width_in_mbs_minus1 = mb_width_ - 1;
-  DCHECK(current_sps_.frame_mbs_only_flag);
-  current_sps_.pic_height_in_map_units_minus1 = mb_height_ - 1;
-
-  if (visible_size_ != coded_size_) {
-    // Visible size differs from coded size, fill crop information.
-    current_sps_.frame_cropping_flag = true;
-    DCHECK(!current_sps_.separate_colour_plane_flag);
-    // Spec table 6-1. Only 4:2:0 for now.
-    DCHECK_EQ(current_sps_.chroma_format_idc, 1);
-    // Spec 7.4.2.1.1. Crop is in crop units, which is 2 pixels for 4:2:0.
-    const unsigned int crop_unit_x = 2;
-    const unsigned int crop_unit_y = 2 * (2 - current_sps_.frame_mbs_only_flag);
-    current_sps_.frame_crop_left_offset = 0;
-    current_sps_.frame_crop_right_offset =
-        (coded_size_.width() - visible_size_.width()) / crop_unit_x;
-    current_sps_.frame_crop_top_offset = 0;
-    current_sps_.frame_crop_bottom_offset =
-        (coded_size_.height() - visible_size_.height()) / crop_unit_y;
-  }
-
-  current_sps_.vui_parameters_present_flag = true;
-  current_sps_.timing_info_present_flag = true;
-  current_sps_.num_units_in_tick = 1;
-  current_sps_.time_scale = framerate_ * 2;  // See equation D-2 in spec.
-  current_sps_.fixed_frame_rate_flag = true;
-
-  current_sps_.nal_hrd_parameters_present_flag = true;
-  // H.264 spec ch. E.2.2.
-  current_sps_.cpb_cnt_minus1 = 0;
-  current_sps_.bit_rate_scale = kBitRateScale;
-  current_sps_.cpb_size_scale = kCPBSizeScale;
-  current_sps_.bit_rate_value_minus1[0] =
-      (bitrate_ >> (kBitRateScale + H264SPS::kBitRateScaleConstantTerm)) - 1;
-  current_sps_.cpb_size_value_minus1[0] =
-      (cpb_size_ >> (kCPBSizeScale + H264SPS::kCPBSizeScaleConstantTerm)) - 1;
-  current_sps_.cbr_flag[0] = true;
-  current_sps_.initial_cpb_removal_delay_length_minus_1 =
-      H264SPS::kDefaultInitialCPBRemovalDelayLength - 1;
-  current_sps_.cpb_removal_delay_length_minus1 =
-      H264SPS::kDefaultInitialCPBRemovalDelayLength - 1;
-  current_sps_.dpb_output_delay_length_minus1 =
-      H264SPS::kDefaultDPBOutputDelayLength - 1;
-  current_sps_.time_offset_length = H264SPS::kDefaultTimeOffsetLength;
-  current_sps_.low_delay_hrd_flag = false;
-}
-
-void VaapiVideoEncodeAccelerator::GeneratePackedSPS() {
-  packed_sps_.Reset();
-
-  packed_sps_.BeginNALU(H264NALU::kSPS, 3);
-
-  packed_sps_.AppendBits(8, current_sps_.profile_idc);
-  packed_sps_.AppendBool(current_sps_.constraint_set0_flag);
-  packed_sps_.AppendBool(current_sps_.constraint_set1_flag);
-  packed_sps_.AppendBool(current_sps_.constraint_set2_flag);
-  packed_sps_.AppendBool(current_sps_.constraint_set3_flag);
-  packed_sps_.AppendBool(current_sps_.constraint_set4_flag);
-  packed_sps_.AppendBool(current_sps_.constraint_set5_flag);
-  packed_sps_.AppendBits(2, 0);  // reserved_zero_2bits
-  packed_sps_.AppendBits(8, current_sps_.level_idc);
-  packed_sps_.AppendUE(current_sps_.seq_parameter_set_id);
-
-  if (current_sps_.profile_idc == H264SPS::kProfileIDCHigh) {
-    packed_sps_.AppendUE(current_sps_.chroma_format_idc);
-    if (current_sps_.chroma_format_idc == 3)
-      packed_sps_.AppendBool(current_sps_.separate_colour_plane_flag);
-    packed_sps_.AppendUE(current_sps_.bit_depth_luma_minus8);
-    packed_sps_.AppendUE(current_sps_.bit_depth_chroma_minus8);
-    packed_sps_.AppendBool(current_sps_.qpprime_y_zero_transform_bypass_flag);
-    packed_sps_.AppendBool(current_sps_.seq_scaling_matrix_present_flag);
-    CHECK(!current_sps_.seq_scaling_matrix_present_flag);
-  }
-
-  packed_sps_.AppendUE(current_sps_.log2_max_frame_num_minus4);
-  packed_sps_.AppendUE(current_sps_.pic_order_cnt_type);
-  if (current_sps_.pic_order_cnt_type == 0)
-    packed_sps_.AppendUE(current_sps_.log2_max_pic_order_cnt_lsb_minus4);
-  else if (current_sps_.pic_order_cnt_type == 1) {
-    CHECK(1);
-  }
-
-  packed_sps_.AppendUE(current_sps_.max_num_ref_frames);
-  packed_sps_.AppendBool(current_sps_.gaps_in_frame_num_value_allowed_flag);
-  packed_sps_.AppendUE(current_sps_.pic_width_in_mbs_minus1);
-  packed_sps_.AppendUE(current_sps_.pic_height_in_map_units_minus1);
-
-  packed_sps_.AppendBool(current_sps_.frame_mbs_only_flag);
-  if (!current_sps_.frame_mbs_only_flag)
-    packed_sps_.AppendBool(current_sps_.mb_adaptive_frame_field_flag);
-
-  packed_sps_.AppendBool(current_sps_.direct_8x8_inference_flag);
-
-  packed_sps_.AppendBool(current_sps_.frame_cropping_flag);
-  if (current_sps_.frame_cropping_flag) {
-    packed_sps_.AppendUE(current_sps_.frame_crop_left_offset);
-    packed_sps_.AppendUE(current_sps_.frame_crop_right_offset);
-    packed_sps_.AppendUE(current_sps_.frame_crop_top_offset);
-    packed_sps_.AppendUE(current_sps_.frame_crop_bottom_offset);
-  }
-
-  packed_sps_.AppendBool(current_sps_.vui_parameters_present_flag);
-  if (current_sps_.vui_parameters_present_flag) {
-    packed_sps_.AppendBool(false);  // aspect_ratio_info_present_flag
-    packed_sps_.AppendBool(false);  // overscan_info_present_flag
-    packed_sps_.AppendBool(false);  // video_signal_type_present_flag
-    packed_sps_.AppendBool(false);  // chroma_loc_info_present_flag
-
-    packed_sps_.AppendBool(current_sps_.timing_info_present_flag);
-    if (current_sps_.timing_info_present_flag) {
-      packed_sps_.AppendBits(32, current_sps_.num_units_in_tick);
-      packed_sps_.AppendBits(32, current_sps_.time_scale);
-      packed_sps_.AppendBool(current_sps_.fixed_frame_rate_flag);
-    }
-
-    packed_sps_.AppendBool(current_sps_.nal_hrd_parameters_present_flag);
-    if (current_sps_.nal_hrd_parameters_present_flag) {
-      packed_sps_.AppendUE(current_sps_.cpb_cnt_minus1);
-      packed_sps_.AppendBits(4, current_sps_.bit_rate_scale);
-      packed_sps_.AppendBits(4, current_sps_.cpb_size_scale);
-      CHECK_LT(base::checked_cast<size_t>(current_sps_.cpb_cnt_minus1),
-               arraysize(current_sps_.bit_rate_value_minus1));
-      for (int i = 0; i <= current_sps_.cpb_cnt_minus1; ++i) {
-        packed_sps_.AppendUE(current_sps_.bit_rate_value_minus1[i]);
-        packed_sps_.AppendUE(current_sps_.cpb_size_value_minus1[i]);
-        packed_sps_.AppendBool(current_sps_.cbr_flag[i]);
-      }
-      packed_sps_.AppendBits(
-          5, current_sps_.initial_cpb_removal_delay_length_minus_1);
-      packed_sps_.AppendBits(5, current_sps_.cpb_removal_delay_length_minus1);
-      packed_sps_.AppendBits(5, current_sps_.dpb_output_delay_length_minus1);
-      packed_sps_.AppendBits(5, current_sps_.time_offset_length);
-    }
-
-    packed_sps_.AppendBool(false);  // vcl_hrd_parameters_flag
-    if (current_sps_.nal_hrd_parameters_present_flag)
-      packed_sps_.AppendBool(current_sps_.low_delay_hrd_flag);
-
-    packed_sps_.AppendBool(false);  // pic_struct_present_flag
-    packed_sps_.AppendBool(true);   // bitstream_restriction_flag
-
-    packed_sps_.AppendBool(false);  // motion_vectors_over_pic_boundaries_flag
-    packed_sps_.AppendUE(2);        // max_bytes_per_pic_denom
-    packed_sps_.AppendUE(1);        // max_bits_per_mb_denom
-    packed_sps_.AppendUE(16);       // log2_max_mv_length_horizontal
-    packed_sps_.AppendUE(16);       // log2_max_mv_length_vertical
-
-    // Explicitly set max_num_reorder_frames to 0 to allow the decoder to
-    // output pictures early.
-    packed_sps_.AppendUE(0);  // max_num_reorder_frames
-
-    // The value of max_dec_frame_buffering shall be greater than or equal to
-    // max_num_ref_frames.
-    const unsigned int max_dec_frame_buffering =
-        current_sps_.max_num_ref_frames;
-    packed_sps_.AppendUE(max_dec_frame_buffering);
-  }
-
-  packed_sps_.FinishNALU();
-}
-
-void VaapiVideoEncodeAccelerator::UpdatePPS() {
-  memset(&current_pps_, 0, sizeof(H264PPS));
-
-  current_pps_.seq_parameter_set_id = current_sps_.seq_parameter_set_id;
-  current_pps_.pic_parameter_set_id = 0;
-
-  current_pps_.entropy_coding_mode_flag =
-      current_sps_.profile_idc >= H264SPS::kProfileIDCMain;
-
-  CHECK_GT(max_ref_idx_l0_size_, 0u);
-  current_pps_.num_ref_idx_l0_default_active_minus1 = max_ref_idx_l0_size_ - 1;
-  current_pps_.num_ref_idx_l1_default_active_minus1 = 0;
-  DCHECK_LE(qp_, 51u);
-  current_pps_.pic_init_qp_minus26 = qp_ - 26;
-  current_pps_.deblocking_filter_control_present_flag = true;
-  current_pps_.transform_8x8_mode_flag =
-      (current_sps_.profile_idc == H264SPS::kProfileIDCHigh);
-}
-
-void VaapiVideoEncodeAccelerator::GeneratePackedPPS() {
-  packed_pps_.Reset();
-
-  packed_pps_.BeginNALU(H264NALU::kPPS, 3);
-
-  packed_pps_.AppendUE(current_pps_.pic_parameter_set_id);
-  packed_pps_.AppendUE(current_pps_.seq_parameter_set_id);
-  packed_pps_.AppendBool(current_pps_.entropy_coding_mode_flag);
-  packed_pps_.AppendBool(
-      current_pps_.bottom_field_pic_order_in_frame_present_flag);
-  CHECK_EQ(current_pps_.num_slice_groups_minus1, 0);
-  packed_pps_.AppendUE(current_pps_.num_slice_groups_minus1);
-
-  packed_pps_.AppendUE(current_pps_.num_ref_idx_l0_default_active_minus1);
-  packed_pps_.AppendUE(current_pps_.num_ref_idx_l1_default_active_minus1);
-
-  packed_pps_.AppendBool(current_pps_.weighted_pred_flag);
-  packed_pps_.AppendBits(2, current_pps_.weighted_bipred_idc);
-
-  packed_pps_.AppendSE(current_pps_.pic_init_qp_minus26);
-  packed_pps_.AppendSE(current_pps_.pic_init_qs_minus26);
-  packed_pps_.AppendSE(current_pps_.chroma_qp_index_offset);
-
-  packed_pps_.AppendBool(current_pps_.deblocking_filter_control_present_flag);
-  packed_pps_.AppendBool(current_pps_.constrained_intra_pred_flag);
-  packed_pps_.AppendBool(current_pps_.redundant_pic_cnt_present_flag);
-
-  packed_pps_.AppendBool(current_pps_.transform_8x8_mode_flag);
-  packed_pps_.AppendBool(current_pps_.pic_scaling_matrix_present_flag);
-  DCHECK(!current_pps_.pic_scaling_matrix_present_flag);
-  packed_pps_.AppendSE(current_pps_.second_chroma_qp_index_offset);
-
-  packed_pps_.FinishNALU();
-}
-
-void VaapiVideoEncodeAccelerator::SetState(State state) {
-  // Only touch state on encoder thread, unless it's not running.
-  if (encoder_thread_.IsRunning() &&
-      !encoder_thread_task_runner_->BelongsToCurrentThread()) {
-    encoder_thread_task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::SetState,
-                              base::Unretained(this), state));
-    return;
-  }
-
-  VLOGF(2) << "setting state to: " << state;
-  state_ = state;
-}
-
-void VaapiVideoEncodeAccelerator::NotifyError(Error error) {
-  if (!child_task_runner_->BelongsToCurrentThread()) {
-    child_task_runner_->PostTask(
-        FROM_HERE, base::Bind(&VaapiVideoEncodeAccelerator::NotifyError,
-                              weak_this_, error));
-    return;
-  }
-
-  if (client_) {
-    client_->NotifyError(error);
-    client_ptr_factory_.reset();
-  }
-}
-
-VaapiVideoEncodeAccelerator::EncodeJob::EncodeJob()
-    : coded_buffer(VA_INVALID_ID), keyframe(false) {}
-
-VaapiVideoEncodeAccelerator::EncodeJob::~EncodeJob() {}
-
-}  // namespace media
--- a/media/gpu/vaapi_video_encode_accelerator.h
+++ /dev/null
@@ -1,275 +0,0 @@
-// Copyright 2014 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef MEDIA_GPU_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
-#define MEDIA_GPU_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
-
-#include <stddef.h>
-#include <stdint.h>
-
-#include <list>
-#include <memory>
-
-#include "base/containers/queue.h"
-#include "base/macros.h"
-#include "base/memory/linked_ptr.h"
-#include "base/threading/thread.h"
-#include "media/filters/h264_bitstream_buffer.h"
-#include "media/gpu/h264_dpb.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/va_surface.h"
-#include "media/gpu/vaapi_wrapper.h"
-#include "media/video/video_encode_accelerator.h"
-
-namespace media {
-
-// A VideoEncodeAccelerator implementation that uses VA-API
-// (http://www.freedesktop.org/wiki/Software/vaapi) for HW-accelerated
-// video encode.
-class MEDIA_GPU_EXPORT VaapiVideoEncodeAccelerator
-    : public VideoEncodeAccelerator {
- public:
-  VaapiVideoEncodeAccelerator();
-  ~VaapiVideoEncodeAccelerator() override;
-
-  // VideoEncodeAccelerator implementation.
-  VideoEncodeAccelerator::SupportedProfiles GetSupportedProfiles() override;
-  bool Initialize(VideoPixelFormat format,
-                  const gfx::Size& input_visible_size,
-                  VideoCodecProfile output_profile,
-                  uint32_t initial_bitrate,
-                  Client* client) override;
-  void Encode(const scoped_refptr<VideoFrame>& frame,
-              bool force_keyframe) override;
-  void UseOutputBitstreamBuffer(const BitstreamBuffer& buffer) override;
-  void RequestEncodingParametersChange(uint32_t bitrate,
-                                       uint32_t framerate) override;
-  void Destroy() override;
-  void Flush(FlushCallback flush_callback) override;
-
- private:
-  // Reference picture list.
-  typedef std::list<scoped_refptr<VASurface>> RefPicList;
-
-  // Encode job for one frame. Created when an input frame is awaiting and
-  // enough resources are available to proceed. Once the job is prepared and
-  // submitted to the hardware, it awaits on the submitted_encode_jobs_ queue
-  // for an output bitstream buffer to become available. Once one is ready,
-  // the encoded bytes are downloaded to it and job resources are released
-  // and become available for reuse.
-  struct EncodeJob {
-    // Input surface for video frame data.
-    scoped_refptr<VASurface> input_surface;
-    // Surface for a reconstructed picture, which is used for reference
-    // for subsequent frames.
-    scoped_refptr<VASurface> recon_surface;
-    // Buffer that will contain output bitstream for this frame.
-    VABufferID coded_buffer;
-    // Reference surfaces required to encode this picture. We keep references
-    // to them here, because we may discard some of them from ref_pic_list*
-    // before the HW job is done.
-    RefPicList reference_surfaces;
-    // True if this job will produce a keyframe. Used to report
-    // to BitstreamBufferReady().
-    bool keyframe;
-    // Source timestamp.
-    base::TimeDelta timestamp;
-
-    EncodeJob();
-    ~EncodeJob();
-  };
-
-  // Encoder state.
-  enum State {
-    kUninitialized,
-    kEncoding,
-    kError,
-  };
-
-  // Holds input frames coming from the client ready to be encoded.
-  struct InputFrameRef;
-  // Holds output buffers coming from the client ready to be filled.
-  struct BitstreamBufferRef;
-
-  // Tasks for each of the VEA interface calls to be executed on the
-  // encoder thread.
-  void InitializeTask();
-  void EncodeTask(const scoped_refptr<VideoFrame>& frame, bool force_keyframe);
-  void UseOutputBitstreamBufferTask(
-      std::unique_ptr<BitstreamBufferRef> buffer_ref);
-  void RequestEncodingParametersChangeTask(uint32_t bitrate,
-                                           uint32_t framerate);
-  void DestroyTask();
-  void FlushTask();
-
-  // Prepare and schedule an encode job if we have an input to encode
-  // and enough resources to proceed.
-  void EncodeFrameTask();
-
-  // Fill current_sps_/current_pps_ with current values.
-  void UpdateSPS();
-  void UpdatePPS();
-  void UpdateRates(uint32_t bitrate, uint32_t framerate);
-
-  // Generate packed SPS and PPS in packed_sps_/packed_pps_, using
-  // values in current_sps_/current_pps_.
-  void GeneratePackedSPS();
-  void GeneratePackedPPS();
-
-  // Check if we have sufficient resources for a new encode job, claim them and
-  // fill current_encode_job_ with them.
-  // Return false if we cannot start a new job yet, true otherwise.
-  bool PrepareNextJob(base::TimeDelta timestamp);
-
-  // Begin a new frame, making it a keyframe if |force_keyframe| is true,
-  // updating current_pic_.
-  void BeginFrame(bool force_keyframe);
-
-  // End current frame, updating reference picture lists and storing current
-  // job in the jobs awaiting completion on submitted_encode_jobs_.
-  void EndFrame();
-
-  // Submit parameters for the current frame to the hardware.
-  bool SubmitFrameParameters();
-  // Submit keyframe headers to the hardware if the current frame is a keyframe.
-  bool SubmitHeadersIfNeeded();
-
-  // Upload image data from |frame| to the input surface for current job.
-  bool UploadFrame(const scoped_refptr<VideoFrame>& frame);
-
-  // Execute encode in hardware. This does not block and will return before
-  // the job is finished.
-  bool ExecuteEncode();
-
-  // Callback that returns a no longer used VASurfaceID to
-  // available_va_surface_ids_ for reuse.
-  void RecycleVASurfaceID(VASurfaceID va_surface_id);
-
-  // Tries to return a bitstream buffer if both a submitted job awaits to
-  // be completed and we have bitstream buffers from the client available
-  // to download the encoded data to.
-  void TryToReturnBitstreamBuffer();
-
-  // Puts the encoder into en error state and notifies client about the error.
-  void NotifyError(Error error);
-
-  // Sets the encoder state on the correct thread.
-  void SetState(State state);
-
-  // VaapiWrapper is the owner of all HW resources (surfaces and buffers)
-  // and will free them on destruction.
-  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
-
-  // Input profile and sizes.
-  VideoCodecProfile profile_;
-  gfx::Size visible_size_;
-  gfx::Size coded_size_;  // Macroblock-aligned.
-  // Width/height in macroblocks.
-  unsigned int mb_width_;
-  unsigned int mb_height_;
-
-  // Maximum size of the reference list 0.
-  unsigned int max_ref_idx_l0_size_;
-
-  // Initial QP.
-  unsigned int qp_;
-
-  // IDR frame period.
-  unsigned int idr_period_;
-  // I frame period.
-  unsigned int i_period_;
-  // IP period, i.e. how often do we need to have either an I or a P frame in
-  // the stream. Period of 1 means we can have no B frames.
-  unsigned int ip_period_;
-
-  // Size in bytes required for input bitstream buffers.
-  size_t output_buffer_byte_size_;
-
-  // All of the members below must be accessed on the encoder_thread_,
-  // while it is running.
-
-  // Encoder state. Encode tasks will only run in kEncoding state.
-  State state_;
-
-  // frame_num to be used for the next frame.
-  unsigned int frame_num_;
-  // idr_pic_id to be used for the next frame.
-  unsigned int idr_pic_id_;
-
-  // Current bitrate in bps.
-  unsigned int bitrate_;
-  // Current fps.
-  unsigned int framerate_;
-  // CPB size in bits, i.e. bitrate in kbps * window size in ms/1000.
-  unsigned int cpb_size_;
-  // True if the parameters have changed and we need to submit a keyframe
-  // with updated parameters.
-  bool encoding_parameters_changed_;
-
-  // Job currently being prepared for encode.
-  std::unique_ptr<EncodeJob> current_encode_job_;
-
-  // Current SPS, PPS and their packed versions. Packed versions are their NALUs
-  // in AnnexB format *without* emulation prevention three-byte sequences
-  // (those will be added by the driver).
-  H264SPS current_sps_;
-  H264BitstreamBuffer packed_sps_;
-  H264PPS current_pps_;
-  H264BitstreamBuffer packed_pps_;
-
-  // Picture currently being prepared for encode.
-  scoped_refptr<H264Picture> current_pic_;
-
-  // VA surfaces available for reuse.
-  std::vector<VASurfaceID> available_va_surface_ids_;
-
-  // VA buffers for coded frames.
-  std::vector<VABufferID> available_va_buffer_ids_;
-
-  // Currently active reference surfaces.
-  RefPicList ref_pic_list0_;
-
-  // Callback via which finished VA surfaces are returned to us.
-  VASurface::ReleaseCB va_surface_release_cb_;
-
-  // VideoFrames passed from the client, waiting to be encoded.
-  base::queue<linked_ptr<InputFrameRef>> encoder_input_queue_;
-
-  // BitstreamBuffers mapped, ready to be filled.
-  base::queue<linked_ptr<BitstreamBufferRef>> available_bitstream_buffers_;
-
-  // Jobs submitted for encode, awaiting bitstream buffers to become available.
-  // A pending flush command, indicated by a null job, will be also put in the
-  // queue.
-  base::queue<linked_ptr<EncodeJob>> submitted_encode_jobs_;
-
-  // Encoder thread. All tasks are executed on it.
-  base::Thread encoder_thread_;
-  scoped_refptr<base::SingleThreadTaskRunner> encoder_thread_task_runner_;
-
-  const scoped_refptr<base::SingleThreadTaskRunner> child_task_runner_;
-
-  // To expose client callbacks from VideoEncodeAccelerator.
-  // NOTE: all calls to these objects *MUST* be executed on
-  // child_task_runner_.
-  std::unique_ptr<base::WeakPtrFactory<Client>> client_ptr_factory_;
-  base::WeakPtr<Client> client_;
-
-  // WeakPtr to post from the encoder thread back to the ChildThread, as it may
-  // outlive this. Posting from the ChildThread using base::Unretained(this)
-  // to the encoder thread is safe, because |this| always outlives the encoder
-  // thread (it's a member of this class).
-  base::WeakPtr<VaapiVideoEncodeAccelerator> weak_this_;
-
-  // The completion callback of the Flush() function.
-  FlushCallback flush_callback_;
-
-  base::WeakPtrFactory<VaapiVideoEncodeAccelerator> weak_this_ptr_factory_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiVideoEncodeAccelerator);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_VIDEO_ENCODE_ACCELERATOR_H_
--- a/media/gpu/vaapi_wrapper.cc
+++ /dev/null
@@ -1,1372 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "media/gpu/vaapi_wrapper.h"
-
-#include <dlfcn.h>
-#include <string.h>
-
-#include <va/va.h>
-#include <va/va_drm.h>
-#include <va/va_drmcommon.h>
-#include <va/va_version.h>
-
-#include "base/bind.h"
-#include "base/callback_helpers.h"
-#include "base/environment.h"
-#include "base/logging.h"
-#include "base/macros.h"
-#include "base/numerics/safe_conversions.h"
-#include "base/stl_util.h"
-#include "base/sys_info.h"
-#include "build/build_config.h"
-
-// Auto-generated for dlopen libva libraries
-#include "media/gpu/vaapi/va_stubs.h"
-
-#include "media/gpu/vaapi/vaapi_picture.h"
-#include "third_party/libyuv/include/libyuv.h"
-#include "ui/gfx/buffer_format_util.h"
-#include "ui/gfx/native_pixmap.h"
-#include "ui/gl/gl_bindings.h"
-#include "ui/gl/gl_implementation.h"
-
-#if defined(USE_X11)
-#include <va/va_x11.h>
-#include "ui/gfx/x/x11_types.h"  // nogncheck
-#endif
-
-#if defined(USE_OZONE)
-#include "ui/ozone/public/ozone_platform.h"
-#include "ui/ozone/public/surface_factory_ozone.h"
-#endif
-
-using media_gpu_vaapi::kModuleVa;
-using media_gpu_vaapi::kModuleVa_drm;
-#if defined(USE_X11)
-using media_gpu_vaapi::kModuleVa_x11;
-#endif
-using media_gpu_vaapi::InitializeStubs;
-using media_gpu_vaapi::StubPathMap;
-
-#define LOG_VA_ERROR_AND_REPORT(va_error, err_msg)                  \
-  do {                                                              \
-    LOG(ERROR) << err_msg << " VA error: " << vaErrorStr(va_error); \
-    report_error_to_uma_cb_.Run();                                  \
-  } while (0)
-
-#define VA_LOG_ON_ERROR(va_error, err_msg)        \
-  do {                                            \
-    if ((va_error) != VA_STATUS_SUCCESS)          \
-      LOG_VA_ERROR_AND_REPORT(va_error, err_msg); \
-  } while (0)
-
-#define VA_SUCCESS_OR_RETURN(va_error, err_msg, ret) \
-  do {                                               \
-    if ((va_error) != VA_STATUS_SUCCESS) {           \
-      LOG_VA_ERROR_AND_REPORT(va_error, err_msg);    \
-      return (ret);                                  \
-    }                                                \
-  } while (0)
-
-namespace {
-
-uint32_t BufferFormatToVAFourCC(gfx::BufferFormat fmt) {
-  switch (fmt) {
-    case gfx::BufferFormat::BGRX_8888:
-      return VA_FOURCC_BGRX;
-    case gfx::BufferFormat::BGRA_8888:
-      return VA_FOURCC_BGRA;
-    case gfx::BufferFormat::RGBX_8888:
-      return VA_FOURCC_RGBX;
-    case gfx::BufferFormat::UYVY_422:
-      return VA_FOURCC_UYVY;
-    case gfx::BufferFormat::YVU_420:
-      return VA_FOURCC_YV12;
-    default:
-      NOTREACHED();
-      return 0;
-  }
-}
-
-uint32_t BufferFormatToVARTFormat(gfx::BufferFormat fmt) {
-  switch (fmt) {
-    case gfx::BufferFormat::UYVY_422:
-      return VA_RT_FORMAT_YUV422;
-    case gfx::BufferFormat::BGRX_8888:
-    case gfx::BufferFormat::BGRA_8888:
-    case gfx::BufferFormat::RGBX_8888:
-      return VA_RT_FORMAT_RGB32;
-    case gfx::BufferFormat::YVU_420:
-      return VA_RT_FORMAT_YUV420;
-    default:
-      NOTREACHED();
-      return 0;
-  }
-}
-
-}  // namespace
-
-namespace media {
-
-namespace {
-
-// Maximum framerate of encoded profile. This value is an arbitary limit
-// and not taken from HW documentation.
-const int kMaxEncoderFramerate = 30;
-
-// Attributes required for encode. This only applies to video encode, not JPEG
-// encode.
-static const VAConfigAttrib kVideoEncodeVAConfigAttribs[] = {
-    {VAConfigAttribRateControl, VA_RC_CBR},
-    {VAConfigAttribEncPackedHeaders,
-     VA_ENC_PACKED_HEADER_SEQUENCE | VA_ENC_PACKED_HEADER_PICTURE},
-};
-
-// A map between VideoCodecProfile and VAProfile.
-static const struct {
-  VideoCodecProfile profile;
-  VAProfile va_profile;
-} kProfileMap[] = {
-    {H264PROFILE_BASELINE, VAProfileH264Baseline},
-    {H264PROFILE_MAIN, VAProfileH264Main},
-    // TODO(posciak): See if we can/want to support other variants of
-    // H264PROFILE_HIGH*.
-    {H264PROFILE_HIGH, VAProfileH264High},
-    {VP8PROFILE_ANY, VAProfileVP8Version0_3},
-    {VP9PROFILE_PROFILE0, VAProfileVP9Profile0},
-    {VP9PROFILE_PROFILE1, VAProfileVP9Profile1},
-    {VP9PROFILE_PROFILE2, VAProfileVP9Profile2},
-    {VP9PROFILE_PROFILE3, VAProfileVP9Profile3},
-};
-
-// This class is a wrapper around its |va_display_| (and its associated
-// |va_lock_|) to guarantee mutual exclusion and singleton behaviour.
-class VADisplayState {
- public:
-  static VADisplayState* Get();
-
-  // Initialize static data before sandbox is enabled.
-  static void PreSandboxInitialization();
-
-  VADisplayState();
-  ~VADisplayState() = delete;
-
-  // |va_lock_| must be held on entry.
-  bool Initialize();
-  void Deinitialize(VAStatus* status);
-
-  base::Lock* va_lock() { return &va_lock_; }
-  VADisplay va_display() const { return va_display_; }
-
-  void SetDrmFd(base::PlatformFile fd) { drm_fd_.reset(HANDLE_EINTR(dup(fd))); }
-
- private:
-  // Returns false on init failure.
-  static bool PostSandboxInitialization();
-
-  // Protected by |va_lock_|.
-  int refcount_;
-
-  // Libva is not thread safe, so we have to do locking for it ourselves.
-  // This lock is to be taken for the duration of all VA-API calls and for
-  // the entire job submission sequence in ExecuteAndDestroyPendingBuffers().
-  base::Lock va_lock_;
-
-  // Drm fd used to obtain access to the driver interface by VA.
-  base::ScopedFD drm_fd_;
-
-  // The VADisplay handle.
-  VADisplay va_display_;
-
-  // True if vaInitialize() has been called successfully.
-  bool va_initialized_;
-};
-
-// static
-VADisplayState* VADisplayState::Get() {
-  static VADisplayState* display_state = new VADisplayState();
-  return display_state;
-}
-
-// static
-void VADisplayState::PreSandboxInitialization() {
-  const char kDriRenderNode0Path[] = "/dev/dri/renderD128";
-  base::File drm_file = base::File(
-      base::FilePath::FromUTF8Unsafe(kDriRenderNode0Path),
-      base::File::FLAG_OPEN | base::File::FLAG_READ | base::File::FLAG_WRITE);
-  if (drm_file.IsValid())
-    VADisplayState::Get()->SetDrmFd(drm_file.GetPlatformFile());
-}
-
-// static
-bool VADisplayState::PostSandboxInitialization() {
-  const std::string va_suffix(std::to_string(VA_MAJOR_VERSION + 1));
-  StubPathMap paths;
-
-  paths[kModuleVa].push_back(std::string("libva.so.") + va_suffix);
-  paths[kModuleVa_drm].push_back(std::string("libva-drm.so.") + va_suffix);
-#if defined(USE_X11)
-  // libva-x11 does not exist on libva >= 2
-  if (VA_MAJOR_VERSION == 0)
-    paths[kModuleVa_x11].push_back("libva-x11.so.1");
-#endif
-
-  const bool success = InitializeStubs(paths);
-  if (!success) {
-    static const char kErrorMsg[] = "Failed to initialize VAAPI libs";
-#if defined(OS_CHROMEOS)
-    // When Chrome runs on Linux with target_os="chromeos", do not log error
-    // message without VAAPI libraries.
-    LOG_IF(ERROR, base::SysInfo::IsRunningOnChromeOS()) << kErrorMsg;
-#else
-    DVLOG(1) << kErrorMsg;
-#endif
-  }
-  return success;
-}
-
-VADisplayState::VADisplayState()
-    : refcount_(0), va_display_(nullptr), va_initialized_(false) {}
-
-bool VADisplayState::Initialize() {
-  va_lock_.AssertAcquired();
-
-  static bool result = PostSandboxInitialization();
-  if (!result)
-    return false;
-
-  if (refcount_++ > 0)
-    return true;
-
-  switch (gl::GetGLImplementation()) {
-    case gl::kGLImplementationEGLGLES2:
-      va_display_ = vaGetDisplayDRM(drm_fd_.get());
-      break;
-    case gl::kGLImplementationDesktopGL:
-#if defined(USE_X11)
-      va_display_ = vaGetDisplay(gfx::GetXDisplay());
-#else
-      LOG(WARNING) << "HW video decode acceleration not available without "
-                      "DesktopGL (GLX).";
-#endif  // USE_X11
-      break;
-    // Cannot infer platform from GL, try all available displays
-    case gl::kGLImplementationNone:
-#if defined(USE_X11)
-      va_display_ = vaGetDisplay(gfx::GetXDisplay());
-      if (vaDisplayIsValid(va_display_))
-        break;
-#endif  // USE_X11
-      va_display_ = vaGetDisplayDRM(drm_fd_.get());
-      break;
-
-    default:
-      LOG(WARNING) << "HW video decode acceleration not available for "
-                   << gl::GetGLImplementationName(gl::GetGLImplementation());
-      return false;
-  }
-
-  if (!vaDisplayIsValid(va_display_)) {
-    LOG(ERROR) << "Could not get a valid VA display";
-    return false;
-  }
-
-  // Set VA logging level to enable error messages, unless already set
-  constexpr char libva_log_level_env[] = "LIBVA_MESSAGING_LEVEL";
-  std::unique_ptr<base::Environment> env(base::Environment::Create());
-  if (!env->HasVar(libva_log_level_env))
-    env->SetVar(libva_log_level_env, "1");
-
-  // The VAAPI version.
-  int major_version, minor_version;
-  VAStatus va_res = vaInitialize(va_display_, &major_version, &minor_version);
-  if (va_res != VA_STATUS_SUCCESS) {
-    LOG(ERROR) << "vaInitialize failed: " << vaErrorStr(va_res);
-    return false;
-  }
-
-  va_initialized_ = true;
-  DVLOG(1) << "VAAPI version: " << major_version << "." << minor_version;
-
-  if (major_version != VA_MAJOR_VERSION || minor_version != VA_MINOR_VERSION) {
-    LOG(ERROR) << "This build of Chromium requires VA-API version "
-               << VA_MAJOR_VERSION << "." << VA_MINOR_VERSION
-               << ", system version: " << major_version << "." << minor_version;
-    return false;
-  }
-  return true;
-}
-
-void VADisplayState::Deinitialize(VAStatus* status) {
-  va_lock_.AssertAcquired();
-  if (--refcount_ > 0)
-    return;
-
-  // Must check if vaInitialize completed successfully, to work around a bug in
-  // libva. The bug was fixed upstream:
-  // http://lists.freedesktop.org/archives/libva/2013-July/001807.html
-  // TODO(mgiuca): Remove this check, and the |va_initialized_| variable, once
-  // the fix has rolled out sufficiently.
-  if (va_initialized_ && va_display_)
-    *status = vaTerminate(va_display_);
-  va_initialized_ = false;
-  va_display_ = nullptr;
-}
-
-static std::vector<VAConfigAttrib> GetRequiredAttribs(
-    VaapiWrapper::CodecMode mode,
-    VAProfile profile) {
-  std::vector<VAConfigAttrib> required_attribs;
-  // VAConfigAttribRTFormat is common to both encode and decode |mode|s.
-  if (profile == VAProfileVP9Profile2 || profile == VAProfileVP9Profile3) {
-    required_attribs.push_back(
-        {VAConfigAttribRTFormat, VA_RT_FORMAT_YUV420_10BPP});
-  } else {
-    required_attribs.push_back({VAConfigAttribRTFormat, VA_RT_FORMAT_YUV420});
-  }
-  if (mode == VaapiWrapper::kEncode && profile != VAProfileJPEGBaseline) {
-    required_attribs.insert(
-        required_attribs.end(), kVideoEncodeVAConfigAttribs,
-        kVideoEncodeVAConfigAttribs + arraysize(kVideoEncodeVAConfigAttribs));
-  }
-  return required_attribs;
-}
-
-static VAEntrypoint GetVaEntryPoint(VaapiWrapper::CodecMode mode,
-                                    VAProfile profile) {
-  switch (mode) {
-    case VaapiWrapper::kDecode:
-      return VAEntrypointVLD;
-    case VaapiWrapper::kEncode:
-      if (profile == VAProfileJPEGBaseline)
-        return VAEntrypointEncPicture;
-      else
-        return VAEntrypointEncSlice;
-    case VaapiWrapper::kCodecModeMax:
-      NOTREACHED();
-      return VAEntrypointVLD;
-  }
-}
-
-// This class encapsulates reading and giving access to the list of supported
-// ProfileInfo entries, in a singleton way.
-class VASupportedProfiles {
- public:
-  struct ProfileInfo {
-    VAProfile va_profile;
-    gfx::Size max_resolution;
-  };
-  static VASupportedProfiles* Get();
-
-  std::vector<ProfileInfo> GetSupportedProfileInfosForCodecMode(
-      VaapiWrapper::CodecMode mode);
-
-  bool IsProfileSupported(VaapiWrapper::CodecMode mode, VAProfile va_profile);
-
- private:
-  VASupportedProfiles();
-  ~VASupportedProfiles() = default;
-
-  bool GetSupportedVAProfiles(std::vector<VAProfile>* profiles);
-
-  // Gets supported profile infos for |mode|.
-  std::vector<ProfileInfo> GetSupportedProfileInfosForCodecModeInternal(
-      VaapiWrapper::CodecMode mode);
-
-  // |va_lock_| must be held on entry in the following _Locked methods.
-
-  // Checks if |va_profile| supports |entrypoint| or not.
-  bool IsEntrypointSupported_Locked(VAProfile va_profile,
-                                    VAEntrypoint entrypoint);
-  // Returns true if |va_profile| for |entrypoint| with |required_attribs| is
-  // supported.
-  bool AreAttribsSupported_Locked(
-      VAProfile va_profile,
-      VAEntrypoint entrypoint,
-      const std::vector<VAConfigAttrib>& required_attribs);
-  // Gets maximum resolution for |va_profile| and |entrypoint| with
-  // |required_attribs|. If return value is true, |resolution| is the maximum
-  // resolution.
-  bool GetMaxResolution_Locked(VAProfile va_profile,
-                               VAEntrypoint entrypoint,
-                               std::vector<VAConfigAttrib>& required_attribs,
-                               gfx::Size* resolution);
-
-  std::vector<ProfileInfo> supported_profiles_[VaapiWrapper::kCodecModeMax];
-
-  // Pointer to VADisplayState's members |va_lock_| and its |va_display_|.
-  base::Lock* va_lock_;
-  VADisplay va_display_;
-
-  const base::Closure report_error_to_uma_cb_;
-};
-
-// static
-VASupportedProfiles* VASupportedProfiles::Get() {
-  static VASupportedProfiles* profile_infos = new VASupportedProfiles();
-  return profile_infos;
-}
-
-std::vector<VASupportedProfiles::ProfileInfo>
-VASupportedProfiles::GetSupportedProfileInfosForCodecMode(
-    VaapiWrapper::CodecMode mode) {
-  return supported_profiles_[mode];
-}
-
-bool VASupportedProfiles::IsProfileSupported(VaapiWrapper::CodecMode mode,
-                                             VAProfile va_profile) {
-  for (const auto& profile : supported_profiles_[mode]) {
-    if (profile.va_profile == va_profile)
-      return true;
-  }
-  return false;
-}
-
-VASupportedProfiles::VASupportedProfiles()
-    : va_lock_(VADisplayState::Get()->va_lock()),
-      va_display_(nullptr),
-      report_error_to_uma_cb_(base::Bind(&base::DoNothing)) {
-  static_assert(arraysize(supported_profiles_) == VaapiWrapper::kCodecModeMax,
-                "The array size of supported profile is incorrect.");
-  {
-    base::AutoLock auto_lock(*va_lock_);
-    if (!VADisplayState::Get()->Initialize())
-      return;
-  }
-
-  va_display_ = VADisplayState::Get()->va_display();
-  DCHECK(va_display_) << "VADisplayState hasn't been properly Initialize()d";
-
-  for (size_t i = 0; i < VaapiWrapper::kCodecModeMax; ++i) {
-    supported_profiles_[i] = GetSupportedProfileInfosForCodecModeInternal(
-        static_cast<VaapiWrapper::CodecMode>(i));
-  }
-
-  {
-    base::AutoLock auto_lock(*va_lock_);
-    VAStatus va_res = VA_STATUS_SUCCESS;
-    VADisplayState::Get()->Deinitialize(&va_res);
-    VA_LOG_ON_ERROR(va_res, "vaTerminate failed");
-    va_display_ = nullptr;
-  }
-}
-
-std::vector<VASupportedProfiles::ProfileInfo>
-VASupportedProfiles::GetSupportedProfileInfosForCodecModeInternal(
-    VaapiWrapper::CodecMode mode) {
-  std::vector<ProfileInfo> supported_profile_infos;
-  std::vector<VAProfile> va_profiles;
-  if (!GetSupportedVAProfiles(&va_profiles))
-    return supported_profile_infos;
-
-  base::AutoLock auto_lock(*va_lock_);
-  for (const auto& va_profile : va_profiles) {
-    VAEntrypoint entrypoint = GetVaEntryPoint(mode, va_profile);
-    std::vector<VAConfigAttrib> required_attribs =
-        GetRequiredAttribs(mode, va_profile);
-    if (!IsEntrypointSupported_Locked(va_profile, entrypoint))
-      continue;
-    if (!AreAttribsSupported_Locked(va_profile, entrypoint, required_attribs))
-      continue;
-    ProfileInfo profile_info;
-    if (!GetMaxResolution_Locked(va_profile, entrypoint, required_attribs,
-                                 &profile_info.max_resolution)) {
-      LOG(ERROR) << "GetMaxResolution failed for va_profile " << va_profile
-                 << " and entrypoint " << entrypoint;
-      continue;
-    }
-    profile_info.va_profile = va_profile;
-    supported_profile_infos.push_back(profile_info);
-  }
-  return supported_profile_infos;
-}
-
-bool VASupportedProfiles::GetSupportedVAProfiles(
-    std::vector<VAProfile>* profiles) {
-  base::AutoLock auto_lock(*va_lock_);
-  // Query the driver for supported profiles.
-  const int max_profiles = vaMaxNumProfiles(va_display_);
-  std::vector<VAProfile> supported_profiles(
-      base::checked_cast<size_t>(max_profiles));
-
-  int num_supported_profiles;
-  VAStatus va_res = vaQueryConfigProfiles(va_display_, &supported_profiles[0],
-                                          &num_supported_profiles);
-  VA_SUCCESS_OR_RETURN(va_res, "vaQueryConfigProfiles failed", false);
-  if (num_supported_profiles < 0 || num_supported_profiles > max_profiles) {
-    LOG(ERROR) << "vaQueryConfigProfiles returned: " << num_supported_profiles;
-    return false;
-  }
-
-  supported_profiles.resize(base::checked_cast<size_t>(num_supported_profiles));
-  *profiles = supported_profiles;
-  return true;
-}
-
-bool VASupportedProfiles::IsEntrypointSupported_Locked(
-    VAProfile va_profile,
-    VAEntrypoint entrypoint) {
-  va_lock_->AssertAcquired();
-  // Query the driver for supported entrypoints.
-  int max_entrypoints = vaMaxNumEntrypoints(va_display_);
-  std::vector<VAEntrypoint> supported_entrypoints(
-      base::checked_cast<size_t>(max_entrypoints));
-
-  int num_supported_entrypoints;
-  VAStatus va_res = vaQueryConfigEntrypoints(va_display_, va_profile,
-                                             &supported_entrypoints[0],
-                                             &num_supported_entrypoints);
-  VA_SUCCESS_OR_RETURN(va_res, "vaQueryConfigEntrypoints failed", false);
-  if (num_supported_entrypoints < 0 ||
-      num_supported_entrypoints > max_entrypoints) {
-    LOG(ERROR) << "vaQueryConfigEntrypoints returned: "
-               << num_supported_entrypoints;
-    return false;
-  }
-
-  return base::ContainsValue(supported_entrypoints, entrypoint);
-}
-
-bool VASupportedProfiles::AreAttribsSupported_Locked(
-    VAProfile va_profile,
-    VAEntrypoint entrypoint,
-    const std::vector<VAConfigAttrib>& required_attribs) {
-  va_lock_->AssertAcquired();
-  // Query the driver for required attributes.
-  std::vector<VAConfigAttrib> attribs = required_attribs;
-  for (size_t i = 0; i < required_attribs.size(); ++i)
-    attribs[i].value = 0;
-
-  VAStatus va_res = vaGetConfigAttributes(va_display_, va_profile, entrypoint,
-                                          &attribs[0], attribs.size());
-  VA_SUCCESS_OR_RETURN(va_res, "vaGetConfigAttributes failed", false);
-
-  for (size_t i = 0; i < required_attribs.size(); ++i) {
-    if (attribs[i].type != required_attribs[i].type ||
-        (attribs[i].value & required_attribs[i].value) !=
-            required_attribs[i].value) {
-      DVLOG(1) << "Unsupported value " << required_attribs[i].value
-               << " for attribute type " << required_attribs[i].type;
-      return false;
-    }
-  }
-  return true;
-}
-
-bool VASupportedProfiles::GetMaxResolution_Locked(
-    VAProfile va_profile,
-    VAEntrypoint entrypoint,
-    std::vector<VAConfigAttrib>& required_attribs,
-    gfx::Size* resolution) {
-  va_lock_->AssertAcquired();
-  VAConfigID va_config_id;
-  VAStatus va_res =
-      vaCreateConfig(va_display_, va_profile, entrypoint, &required_attribs[0],
-                     required_attribs.size(), &va_config_id);
-  VA_SUCCESS_OR_RETURN(va_res, "vaCreateConfig failed", false);
-
-  // Calls vaQuerySurfaceAttributes twice. The first time is to get the number
-  // of attributes to prepare the space and the second time is to get all
-  // attributes.
-  unsigned int num_attribs;
-  va_res = vaQuerySurfaceAttributes(va_display_, va_config_id, nullptr,
-                                    &num_attribs);
-  VA_SUCCESS_OR_RETURN(va_res, "vaQuerySurfaceAttributes failed", false);
-  if (!num_attribs)
-    return false;
-
-  std::vector<VASurfaceAttrib> attrib_list(
-      base::checked_cast<size_t>(num_attribs));
-
-  va_res = vaQuerySurfaceAttributes(va_display_, va_config_id, &attrib_list[0],
-                                    &num_attribs);
-  VA_SUCCESS_OR_RETURN(va_res, "vaQuerySurfaceAttributes failed", false);
-
-  resolution->SetSize(0, 0);
-  for (const auto& attrib : attrib_list) {
-    if (attrib.type == VASurfaceAttribMaxWidth)
-      resolution->set_width(attrib.value.value.i);
-    else if (attrib.type == VASurfaceAttribMaxHeight)
-      resolution->set_height(attrib.value.value.i);
-  }
-  if (resolution->IsEmpty()) {
-    LOG(ERROR) << "Wrong codec resolution: " << resolution->ToString();
-    return false;
-  }
-  return true;
-}
-
-// Maps VideoCodecProfile enum values to VaProfile values. This function
-// includes a workaround for https://crbug.com/345569: if va_profile is h264
-// baseline and it is not supported, we try constrained baseline.
-VAProfile ProfileToVAProfile(VideoCodecProfile profile,
-                             VaapiWrapper::CodecMode mode) {
-  VAProfile va_profile = VAProfileNone;
-  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
-    if (kProfileMap[i].profile == profile) {
-      va_profile = kProfileMap[i].va_profile;
-      break;
-    }
-  }
-  if (!VASupportedProfiles::Get()->IsProfileSupported(mode, va_profile) &&
-      va_profile == VAProfileH264Baseline) {
-    // https://crbug.com/345569: ProfileIDToVideoCodecProfile() currently strips
-    // the information whether the profile is constrained or not, so we have no
-    // way to know here. Try for baseline first, but if it is not supported,
-    // try constrained baseline and hope this is what it actually is
-    // (which in practice is true for a great majority of cases).
-    if (VASupportedProfiles::Get()->IsProfileSupported(
-            mode, VAProfileH264ConstrainedBaseline)) {
-      va_profile = VAProfileH264ConstrainedBaseline;
-      DVLOG(1) << "Fall back to constrained baseline profile.";
-    }
-  }
-  return va_profile;
-}
-
-void DestroyVAImage(VADisplay va_display, VAImage image) {
-  if (image.image_id != VA_INVALID_ID)
-    vaDestroyImage(va_display, image.image_id);
-}
-
-}  // namespace
-
-VaapiWrapper::VaapiWrapper()
-    : va_surface_format_(0),
-      va_display_(NULL),
-      va_config_id_(VA_INVALID_ID),
-      va_context_id_(VA_INVALID_ID),
-      va_vpp_config_id_(VA_INVALID_ID),
-      va_vpp_context_id_(VA_INVALID_ID),
-      va_vpp_buffer_id_(VA_INVALID_ID) {
-  va_lock_ = VADisplayState::Get()->va_lock();
-}
-
-VaapiWrapper::~VaapiWrapper() {
-  DestroyPendingBuffers();
-  DestroyCodedBuffers();
-  DestroySurfaces();
-  DeinitializeVpp();
-  Deinitialize();
-}
-
-// static
-scoped_refptr<VaapiWrapper> VaapiWrapper::Create(
-    CodecMode mode,
-    VAProfile va_profile,
-    const base::Closure& report_error_to_uma_cb) {
-  if (!VASupportedProfiles::Get()->IsProfileSupported(mode, va_profile)) {
-    DVLOG(1) << "Unsupported va_profile: " << va_profile;
-    return nullptr;
-  }
-
-  scoped_refptr<VaapiWrapper> vaapi_wrapper(new VaapiWrapper());
-  if (vaapi_wrapper->VaInitialize(report_error_to_uma_cb)) {
-    if (vaapi_wrapper->Initialize(mode, va_profile))
-      return vaapi_wrapper;
-  }
-  LOG(ERROR) << "Failed to create VaapiWrapper for va_profile: " << va_profile;
-  return nullptr;
-}
-
-// static
-scoped_refptr<VaapiWrapper> VaapiWrapper::CreateForVideoCodec(
-    CodecMode mode,
-    VideoCodecProfile profile,
-    const base::Closure& report_error_to_uma_cb) {
-  VAProfile va_profile = ProfileToVAProfile(profile, mode);
-  return Create(mode, va_profile, report_error_to_uma_cb);
-}
-
-// static
-VideoEncodeAccelerator::SupportedProfiles
-VaapiWrapper::GetSupportedEncodeProfiles() {
-  VideoEncodeAccelerator::SupportedProfiles profiles;
-  std::vector<VASupportedProfiles::ProfileInfo> encode_profile_infos =
-      VASupportedProfiles::Get()->GetSupportedProfileInfosForCodecMode(kEncode);
-
-  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
-    VAProfile va_profile = ProfileToVAProfile(kProfileMap[i].profile, kEncode);
-    if (va_profile == VAProfileNone)
-      continue;
-    for (const auto& profile_info : encode_profile_infos) {
-      if (profile_info.va_profile == va_profile) {
-        VideoEncodeAccelerator::SupportedProfile profile;
-        profile.profile = kProfileMap[i].profile;
-        profile.max_resolution = profile_info.max_resolution;
-        profile.max_framerate_numerator = kMaxEncoderFramerate;
-        profile.max_framerate_denominator = 1;
-        profiles.push_back(profile);
-        break;
-      }
-    }
-  }
-  return profiles;
-}
-
-// static
-VideoDecodeAccelerator::SupportedProfiles
-VaapiWrapper::GetSupportedDecodeProfiles() {
-  VideoDecodeAccelerator::SupportedProfiles profiles;
-  std::vector<VASupportedProfiles::ProfileInfo> decode_profile_infos =
-      VASupportedProfiles::Get()->GetSupportedProfileInfosForCodecMode(kDecode);
-
-  for (size_t i = 0; i < arraysize(kProfileMap); ++i) {
-    VAProfile va_profile = ProfileToVAProfile(kProfileMap[i].profile, kDecode);
-    if (va_profile == VAProfileNone)
-      continue;
-    for (const auto& profile_info : decode_profile_infos) {
-      if (profile_info.va_profile == va_profile) {
-        VideoDecodeAccelerator::SupportedProfile profile;
-        profile.profile = kProfileMap[i].profile;
-        profile.max_resolution = profile_info.max_resolution;
-        profile.min_resolution.SetSize(16, 16);
-        profiles.push_back(profile);
-        break;
-      }
-    }
-  }
-  return profiles;
-}
-
-// static
-bool VaapiWrapper::IsJpegDecodeSupported() {
-  return VASupportedProfiles::Get()->IsProfileSupported(kDecode,
-                                                        VAProfileJPEGBaseline);
-}
-
-// static
-bool VaapiWrapper::IsJpegEncodeSupported() {
-  return VASupportedProfiles::Get()->IsProfileSupported(kEncode,
-                                                        VAProfileJPEGBaseline);
-}
-
-void VaapiWrapper::TryToSetVADisplayAttributeToLocalGPU() {
-  base::AutoLock auto_lock(*va_lock_);
-  VADisplayAttribute item = {VADisplayAttribRenderMode,
-                             1,   // At least support '_LOCAL_OVERLAY'.
-                             -1,  // The maximum possible support 'ALL'.
-                             VA_RENDER_MODE_LOCAL_GPU,
-                             VA_DISPLAY_ATTRIB_SETTABLE};
-
-  VAStatus va_res = vaSetDisplayAttributes(va_display_, &item, 1);
-  if (va_res != VA_STATUS_SUCCESS)
-    DVLOG(2) << "vaSetDisplayAttributes unsupported, ignoring by default.";
-}
-
-bool VaapiWrapper::VaInitialize(const base::Closure& report_error_to_uma_cb) {
-  report_error_to_uma_cb_ = report_error_to_uma_cb;
-  {
-    base::AutoLock auto_lock(*va_lock_);
-    if (!VADisplayState::Get()->Initialize())
-      return false;
-  }
-
-  va_display_ = VADisplayState::Get()->va_display();
-  DCHECK(va_display_) << "VADisplayState hasn't been properly Initialize()d";
-  return true;
-}
-
-bool VaapiWrapper::Initialize(CodecMode mode, VAProfile va_profile) {
-  TryToSetVADisplayAttributeToLocalGPU();
-
-  VAEntrypoint entrypoint = GetVaEntryPoint(mode, va_profile);
-  std::vector<VAConfigAttrib> required_attribs =
-      GetRequiredAttribs(mode, va_profile);
-  base::AutoLock auto_lock(*va_lock_);
-  VAStatus va_res =
-      vaCreateConfig(va_display_, va_profile, entrypoint, &required_attribs[0],
-                     required_attribs.size(), &va_config_id_);
-  VA_SUCCESS_OR_RETURN(va_res, "vaCreateConfig failed", false);
-
-  return true;
-}
-
-void VaapiWrapper::Deinitialize() {
-  base::AutoLock auto_lock(*va_lock_);
-
-  if (va_config_id_ != VA_INVALID_ID) {
-    VAStatus va_res = vaDestroyConfig(va_display_, va_config_id_);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyConfig failed");
-  }
-
-  VAStatus va_res = VA_STATUS_SUCCESS;
-  VADisplayState::Get()->Deinitialize(&va_res);
-  VA_LOG_ON_ERROR(va_res, "vaTerminate failed");
-
-  va_config_id_ = VA_INVALID_ID;
-  va_display_ = NULL;
-}
-
-bool VaapiWrapper::CreateSurfaces(unsigned int va_format,
-                                  const gfx::Size& size,
-                                  size_t num_surfaces,
-                                  std::vector<VASurfaceID>* va_surfaces) {
-  base::AutoLock auto_lock(*va_lock_);
-  DVLOG(2) << "Creating " << num_surfaces << " surfaces";
-
-  DCHECK(va_surfaces->empty());
-  DCHECK(va_surface_ids_.empty());
-  DCHECK_EQ(va_surface_format_, 0u);
-  va_surface_ids_.resize(num_surfaces);
-
-  // Allocate surfaces in driver.
-  VAStatus va_res =
-      vaCreateSurfaces(va_display_, va_format, size.width(), size.height(),
-                       &va_surface_ids_[0], va_surface_ids_.size(), NULL, 0);
-
-  VA_LOG_ON_ERROR(va_res, "vaCreateSurfaces failed");
-  if (va_res != VA_STATUS_SUCCESS) {
-    va_surface_ids_.clear();
-    return false;
-  }
-
-  // And create a context associated with them.
-  va_res = vaCreateContext(va_display_, va_config_id_, size.width(),
-                           size.height(), VA_PROGRESSIVE, &va_surface_ids_[0],
-                           va_surface_ids_.size(), &va_context_id_);
-
-  VA_LOG_ON_ERROR(va_res, "vaCreateContext failed");
-  if (va_res != VA_STATUS_SUCCESS) {
-    DestroySurfaces_Locked();
-    return false;
-  }
-
-  *va_surfaces = va_surface_ids_;
-  va_surface_format_ = va_format;
-  return true;
-}
-
-void VaapiWrapper::DestroySurfaces() {
-  base::AutoLock auto_lock(*va_lock_);
-  DVLOG(2) << "Destroying " << va_surface_ids_.size() << " surfaces";
-
-  DestroySurfaces_Locked();
-}
-
-void VaapiWrapper::DestroySurfaces_Locked() {
-  va_lock_->AssertAcquired();
-
-  if (va_context_id_ != VA_INVALID_ID) {
-    VAStatus va_res = vaDestroyContext(va_display_, va_context_id_);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyContext failed");
-  }
-
-  if (!va_surface_ids_.empty()) {
-    VAStatus va_res = vaDestroySurfaces(va_display_, &va_surface_ids_[0],
-                                        va_surface_ids_.size());
-    VA_LOG_ON_ERROR(va_res, "vaDestroySurfaces failed");
-  }
-
-  va_surface_ids_.clear();
-  va_context_id_ = VA_INVALID_ID;
-  va_surface_format_ = 0;
-}
-
-scoped_refptr<VASurface> VaapiWrapper::CreateUnownedSurface(
-    unsigned int va_format,
-    const gfx::Size& size,
-    const std::vector<VASurfaceAttrib>& va_attribs) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  std::vector<VASurfaceAttrib> attribs(va_attribs);
-  VASurfaceID va_surface_id;
-  VAStatus va_res =
-      vaCreateSurfaces(va_display_, va_format, size.width(), size.height(),
-                       &va_surface_id, 1, &attribs[0], attribs.size());
-
-  scoped_refptr<VASurface> va_surface;
-  VA_SUCCESS_OR_RETURN(va_res, "Failed to create unowned VASurface",
-                       va_surface);
-
-  // This is safe to use Unretained() here, because the VDA takes care
-  // of the destruction order. All the surfaces will be destroyed
-  // before VaapiWrapper.
-  va_surface = new VASurface(
-      va_surface_id, size, va_format,
-      base::Bind(&VaapiWrapper::DestroyUnownedSurface, base::Unretained(this)));
-
-  return va_surface;
-}
-
-scoped_refptr<VASurface> VaapiWrapper::CreateVASurfaceForPixmap(
-    const scoped_refptr<gfx::NativePixmap>& pixmap) {
-  // Create a VASurface for a NativePixmap by importing the underlying dmabufs.
-  VASurfaceAttribExternalBuffers va_attrib_extbuf;
-  memset(&va_attrib_extbuf, 0, sizeof(va_attrib_extbuf));
-
-  va_attrib_extbuf.pixel_format =
-      BufferFormatToVAFourCC(pixmap->GetBufferFormat());
-  gfx::Size size = pixmap->GetBufferSize();
-  va_attrib_extbuf.width = size.width();
-  va_attrib_extbuf.height = size.height();
-
-  size_t num_fds = pixmap->GetDmaBufFdCount();
-  size_t num_planes =
-      gfx::NumberOfPlanesForBufferFormat(pixmap->GetBufferFormat());
-  if (num_fds == 0 || num_fds > num_planes) {
-    LOG(ERROR) << "Invalid number of dmabuf fds: " << num_fds
-               << " , planes: " << num_planes;
-    return nullptr;
-  }
-
-  for (size_t i = 0; i < num_planes; ++i) {
-    va_attrib_extbuf.pitches[i] = pixmap->GetDmaBufPitch(i);
-    va_attrib_extbuf.offsets[i] = pixmap->GetDmaBufOffset(i);
-    DVLOG(4) << "plane " << i << ": pitch: " << va_attrib_extbuf.pitches[i]
-             << " offset: " << va_attrib_extbuf.offsets[i];
-  }
-  va_attrib_extbuf.num_planes = num_planes;
-
-  std::vector<unsigned long> fds(num_fds);
-  for (size_t i = 0; i < num_fds; ++i) {
-    int dmabuf_fd = pixmap->GetDmaBufFd(i);
-    if (dmabuf_fd < 0) {
-      LOG(ERROR) << "Failed to get dmabuf from an Ozone NativePixmap";
-      return nullptr;
-    }
-    fds[i] = dmabuf_fd;
-  }
-  va_attrib_extbuf.buffers = fds.data();
-  va_attrib_extbuf.num_buffers = fds.size();
-
-  va_attrib_extbuf.flags = 0;
-  va_attrib_extbuf.private_data = NULL;
-
-  std::vector<VASurfaceAttrib> va_attribs(2);
-
-  va_attribs[0].type = VASurfaceAttribMemoryType;
-  va_attribs[0].flags = VA_SURFACE_ATTRIB_SETTABLE;
-  va_attribs[0].value.type = VAGenericValueTypeInteger;
-  va_attribs[0].value.value.i = VA_SURFACE_ATTRIB_MEM_TYPE_DRM_PRIME;
-
-  va_attribs[1].type = VASurfaceAttribExternalBufferDescriptor;
-  va_attribs[1].flags = VA_SURFACE_ATTRIB_SETTABLE;
-  va_attribs[1].value.type = VAGenericValueTypePointer;
-  va_attribs[1].value.value.p = &va_attrib_extbuf;
-
-  scoped_refptr<VASurface> va_surface = CreateUnownedSurface(
-      BufferFormatToVARTFormat(pixmap->GetBufferFormat()), size, va_attribs);
-  if (!va_surface) {
-    LOG(ERROR) << "Failed to create VASurface for an Ozone NativePixmap";
-    return nullptr;
-  }
-
-  return va_surface;
-}
-
-void VaapiWrapper::DestroyUnownedSurface(VASurfaceID va_surface_id) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAStatus va_res = vaDestroySurfaces(va_display_, &va_surface_id, 1);
-  VA_LOG_ON_ERROR(va_res, "vaDestroySurfaces on surface failed");
-}
-
-bool VaapiWrapper::SubmitBuffer(VABufferType va_buffer_type,
-                                size_t size,
-                                void* buffer) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VABufferID buffer_id;
-  VAStatus va_res = vaCreateBuffer(va_display_, va_context_id_, va_buffer_type,
-                                   size, 1, buffer, &buffer_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a VA buffer", false);
-
-  switch (va_buffer_type) {
-    case VASliceParameterBufferType:
-    case VASliceDataBufferType:
-    case VAEncSliceParameterBufferType:
-      pending_slice_bufs_.push_back(buffer_id);
-      break;
-
-    default:
-      pending_va_bufs_.push_back(buffer_id);
-      break;
-  }
-
-  return true;
-}
-
-bool VaapiWrapper::SubmitVAEncMiscParamBuffer(
-    VAEncMiscParameterType misc_param_type,
-    size_t size,
-    void* buffer) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VABufferID buffer_id;
-  VAStatus va_res = vaCreateBuffer(
-      va_display_, va_context_id_, VAEncMiscParameterBufferType,
-      sizeof(VAEncMiscParameterBuffer) + size, 1, NULL, &buffer_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a VA buffer", false);
-
-  void* data_ptr = NULL;
-  va_res = vaMapBuffer(va_display_, buffer_id, &data_ptr);
-  VA_LOG_ON_ERROR(va_res, "vaMapBuffer failed");
-  if (va_res != VA_STATUS_SUCCESS) {
-    vaDestroyBuffer(va_display_, buffer_id);
-    return false;
-  }
-
-  DCHECK(data_ptr);
-
-  VAEncMiscParameterBuffer* misc_param =
-      reinterpret_cast<VAEncMiscParameterBuffer*>(data_ptr);
-  misc_param->type = misc_param_type;
-  memcpy(misc_param->data, buffer, size);
-  va_res = vaUnmapBuffer(va_display_, buffer_id);
-  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
-
-  pending_va_bufs_.push_back(buffer_id);
-  return true;
-}
-
-void VaapiWrapper::DestroyPendingBuffers() {
-  base::AutoLock auto_lock(*va_lock_);
-
-  for (const auto& pending_va_buf : pending_va_bufs_) {
-    VAStatus va_res = vaDestroyBuffer(va_display_, pending_va_buf);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
-  }
-
-  for (const auto& pending_slice_buf : pending_slice_bufs_) {
-    VAStatus va_res = vaDestroyBuffer(va_display_, pending_slice_buf);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
-  }
-
-  pending_va_bufs_.clear();
-  pending_slice_bufs_.clear();
-}
-
-bool VaapiWrapper::CreateCodedBuffer(size_t size, VABufferID* buffer_id) {
-  base::AutoLock auto_lock(*va_lock_);
-  VAStatus va_res =
-      vaCreateBuffer(va_display_, va_context_id_, VAEncCodedBufferType, size, 1,
-                     NULL, buffer_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed to create a coded buffer", false);
-
-  const auto is_new_entry = coded_buffers_.insert(*buffer_id).second;
-  DCHECK(is_new_entry);
-  return true;
-}
-
-void VaapiWrapper::DestroyCodedBuffers() {
-  base::AutoLock auto_lock(*va_lock_);
-
-  for (std::set<VABufferID>::const_iterator iter = coded_buffers_.begin();
-       iter != coded_buffers_.end(); ++iter) {
-    VAStatus va_res = vaDestroyBuffer(va_display_, *iter);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
-  }
-
-  coded_buffers_.clear();
-}
-
-bool VaapiWrapper::Execute(VASurfaceID va_surface_id) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  DVLOG(4) << "Pending VA bufs to commit: " << pending_va_bufs_.size();
-  DVLOG(4) << "Pending slice bufs to commit: " << pending_slice_bufs_.size();
-  DVLOG(4) << "Target VA surface " << va_surface_id;
-
-  // Get ready to execute for given surface.
-  VAStatus va_res = vaBeginPicture(va_display_, va_context_id_, va_surface_id);
-  VA_SUCCESS_OR_RETURN(va_res, "vaBeginPicture failed", false);
-
-  if (pending_va_bufs_.size() > 0) {
-    // Commit parameter and slice buffers.
-    va_res = vaRenderPicture(va_display_, va_context_id_, &pending_va_bufs_[0],
-                             pending_va_bufs_.size());
-    VA_SUCCESS_OR_RETURN(va_res, "vaRenderPicture for va_bufs failed", false);
-  }
-
-  if (pending_slice_bufs_.size() > 0) {
-    va_res =
-        vaRenderPicture(va_display_, va_context_id_, &pending_slice_bufs_[0],
-                        pending_slice_bufs_.size());
-    VA_SUCCESS_OR_RETURN(va_res, "vaRenderPicture for slices failed", false);
-  }
-
-  // Instruct HW codec to start processing committed buffers.
-  // Does not block and the job is not finished after this returns.
-  va_res = vaEndPicture(va_display_, va_context_id_);
-  VA_SUCCESS_OR_RETURN(va_res, "vaEndPicture failed", false);
-
-  return true;
-}
-
-bool VaapiWrapper::ExecuteAndDestroyPendingBuffers(VASurfaceID va_surface_id) {
-  bool result = Execute(va_surface_id);
-  DestroyPendingBuffers();
-  return result;
-}
-
-#if defined(USE_X11)
-bool VaapiWrapper::PutSurfaceIntoPixmap(VASurfaceID va_surface_id,
-                                        Pixmap x_pixmap,
-                                        gfx::Size dest_size) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAStatus va_res = vaSyncSurface(va_display_, va_surface_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
-
-  // Put the data into an X Pixmap.
-  va_res = vaPutSurface(va_display_,
-                        va_surface_id,
-                        x_pixmap,
-                        0, 0, dest_size.width(), dest_size.height(),
-                        0, 0, dest_size.width(), dest_size.height(),
-                        NULL, 0, 0);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed putting surface to pixmap", false);
-  return true;
-}
-#endif  // USE_X11
-
-bool VaapiWrapper::GetVaImage(VASurfaceID va_surface_id,
-                              VAImageFormat* format,
-                              const gfx::Size& size,
-                              VAImage* image,
-                              void** mem) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAStatus va_res = vaSyncSurface(va_display_, va_surface_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
-
-  va_res =
-      vaCreateImage(va_display_, format, size.width(), size.height(), image);
-  VA_SUCCESS_OR_RETURN(va_res, "vaCreateImage failed", false);
-
-  va_res = vaGetImage(va_display_, va_surface_id, 0, 0, size.width(),
-                      size.height(), image->image_id);
-  VA_LOG_ON_ERROR(va_res, "vaGetImage failed");
-
-  if (va_res == VA_STATUS_SUCCESS) {
-    // Map the VAImage into memory
-    va_res = vaMapBuffer(va_display_, image->buf, mem);
-    VA_LOG_ON_ERROR(va_res, "vaMapBuffer failed");
-  }
-
-  if (va_res != VA_STATUS_SUCCESS) {
-    va_res = vaDestroyImage(va_display_, image->image_id);
-    VA_LOG_ON_ERROR(va_res, "vaDestroyImage failed");
-    return false;
-  }
-
-  return true;
-}
-
-void VaapiWrapper::ReturnVaImage(VAImage* image) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAStatus va_res = vaUnmapBuffer(va_display_, image->buf);
-  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
-
-  va_res = vaDestroyImage(va_display_, image->image_id);
-  VA_LOG_ON_ERROR(va_res, "vaDestroyImage failed");
-}
-
-bool VaapiWrapper::UploadVideoFrameToSurface(
-    const scoped_refptr<VideoFrame>& frame,
-    VASurfaceID va_surface_id) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAImage image;
-  VAStatus va_res = vaDeriveImage(va_display_, va_surface_id, &image);
-  VA_SUCCESS_OR_RETURN(va_res, "vaDeriveImage failed", false);
-  base::ScopedClosureRunner vaimage_deleter(
-      base::Bind(&DestroyVAImage, va_display_, image));
-
-  if (image.format.fourcc != VA_FOURCC_NV12) {
-    LOG(ERROR) << "Unsupported image format: " << image.format.fourcc;
-    return false;
-  }
-
-  if (gfx::Rect(image.width, image.height) < gfx::Rect(frame->coded_size())) {
-    LOG(ERROR) << "Buffer too small to fit the frame.";
-    return false;
-  }
-
-  void* image_ptr = NULL;
-  va_res = vaMapBuffer(va_display_, image.buf, &image_ptr);
-  VA_SUCCESS_OR_RETURN(va_res, "vaMapBuffer failed", false);
-  DCHECK(image_ptr);
-
-  int ret = 0;
-  {
-    base::AutoUnlock auto_unlock(*va_lock_);
-    ret = libyuv::I420ToNV12(
-        frame->data(VideoFrame::kYPlane), frame->stride(VideoFrame::kYPlane),
-        frame->data(VideoFrame::kUPlane), frame->stride(VideoFrame::kUPlane),
-        frame->data(VideoFrame::kVPlane), frame->stride(VideoFrame::kVPlane),
-        static_cast<uint8_t*>(image_ptr) + image.offsets[0], image.pitches[0],
-        static_cast<uint8_t*>(image_ptr) + image.offsets[1], image.pitches[1],
-        image.width, image.height);
-  }
-
-  va_res = vaUnmapBuffer(va_display_, image.buf);
-  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
-
-  return ret == 0;
-}
-
-bool VaapiWrapper::DownloadFromCodedBuffer(VABufferID buffer_id,
-                                           VASurfaceID sync_surface_id,
-                                           uint8_t* target_ptr,
-                                           size_t target_size,
-                                           size_t* coded_data_size) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  VAStatus va_res = vaSyncSurface(va_display_, sync_surface_id);
-  VA_SUCCESS_OR_RETURN(va_res, "Failed syncing surface", false);
-
-  VACodedBufferSegment* buffer_segment = NULL;
-  va_res = vaMapBuffer(va_display_, buffer_id,
-                       reinterpret_cast<void**>(&buffer_segment));
-  VA_SUCCESS_OR_RETURN(va_res, "vaMapBuffer failed", false);
-  DCHECK(target_ptr);
-
-  {
-    base::AutoUnlock auto_unlock(*va_lock_);
-    *coded_data_size = 0;
-
-    while (buffer_segment) {
-      DCHECK(buffer_segment->buf);
-
-      if (buffer_segment->size > target_size) {
-        LOG(ERROR) << "Insufficient output buffer size";
-        break;
-      }
-
-      memcpy(target_ptr, buffer_segment->buf, buffer_segment->size);
-
-      target_ptr += buffer_segment->size;
-      *coded_data_size += buffer_segment->size;
-      target_size -= buffer_segment->size;
-
-      buffer_segment =
-          reinterpret_cast<VACodedBufferSegment*>(buffer_segment->next);
-    }
-  }
-
-  va_res = vaUnmapBuffer(va_display_, buffer_id);
-  VA_LOG_ON_ERROR(va_res, "vaUnmapBuffer failed");
-  return buffer_segment == NULL;
-}
-
-bool VaapiWrapper::DownloadAndDestroyCodedBuffer(VABufferID buffer_id,
-                                                 VASurfaceID sync_surface_id,
-                                                 uint8_t* target_ptr,
-                                                 size_t target_size,
-                                                 size_t* coded_data_size) {
-  bool result = DownloadFromCodedBuffer(buffer_id, sync_surface_id, target_ptr,
-                                        target_size, coded_data_size);
-
-  VAStatus va_res = vaDestroyBuffer(va_display_, buffer_id);
-  VA_LOG_ON_ERROR(va_res, "vaDestroyBuffer failed");
-  const auto was_found = coded_buffers_.erase(buffer_id);
-  DCHECK(was_found);
-
-  return result;
-}
-
-bool VaapiWrapper::BlitSurface(
-    const scoped_refptr<VASurface>& va_surface_src,
-    const scoped_refptr<VASurface>& va_surface_dest) {
-  base::AutoLock auto_lock(*va_lock_);
-
-  // Initialize the post processing engine if not already done.
-  if (va_vpp_buffer_id_ == VA_INVALID_ID) {
-    if (!InitializeVpp_Locked())
-      return false;
-  }
-
-  VAProcPipelineParameterBuffer* pipeline_param;
-  VA_SUCCESS_OR_RETURN(vaMapBuffer(va_display_, va_vpp_buffer_id_,
-                                   reinterpret_cast<void**>(&pipeline_param)),
-                       "Couldn't map vpp buffer", false);
-
-  memset(pipeline_param, 0, sizeof *pipeline_param);
-  const gfx::Size src_size = va_surface_src->size();
-  const gfx::Size dest_size = va_surface_dest->size();
-
-  VARectangle input_region;
-  input_region.x = input_region.y = 0;
-  input_region.width = src_size.width();
-  input_region.height = src_size.height();
-  pipeline_param->surface_region = &input_region;
-  pipeline_param->surface = va_surface_src->id();
-  pipeline_param->surface_color_standard = VAProcColorStandardNone;
-
-  VARectangle output_region;
-  output_region.x = output_region.y = 0;
-  output_region.width = dest_size.width();
-  output_region.height = dest_size.height();
-  pipeline_param->output_region = &output_region;
-  pipeline_param->output_background_color = 0xff000000;
-  pipeline_param->output_color_standard = VAProcColorStandardNone;
-  pipeline_param->filter_flags = VA_FILTER_SCALING_DEFAULT;
-
-  VA_SUCCESS_OR_RETURN(vaUnmapBuffer(va_display_, va_vpp_buffer_id_),
-                       "Couldn't unmap vpp buffer", false);
-
-  VA_SUCCESS_OR_RETURN(
-      vaBeginPicture(va_display_, va_vpp_context_id_, va_surface_dest->id()),
-      "Couldn't begin picture", false);
-
-  VA_SUCCESS_OR_RETURN(
-      vaRenderPicture(va_display_, va_vpp_context_id_, &va_vpp_buffer_id_, 1),
-      "Couldn't render picture", false);
-
-  VA_SUCCESS_OR_RETURN(vaEndPicture(va_display_, va_vpp_context_id_),
-                       "Couldn't end picture", false);
-
-  return true;
-}
-
-bool VaapiWrapper::InitializeVpp_Locked() {
-  va_lock_->AssertAcquired();
-
-  VA_SUCCESS_OR_RETURN(
-      vaCreateConfig(va_display_, VAProfileNone, VAEntrypointVideoProc, NULL, 0,
-                     &va_vpp_config_id_),
-      "Couldn't create config", false);
-
-  // The size of the picture for the context is irrelevant in the case
-  // of the VPP, just passing 1x1.
-  VA_SUCCESS_OR_RETURN(vaCreateContext(va_display_, va_vpp_config_id_, 1, 1, 0,
-                                       NULL, 0, &va_vpp_context_id_),
-                       "Couldn't create context", false);
-
-  VA_SUCCESS_OR_RETURN(vaCreateBuffer(va_display_, va_vpp_context_id_,
-                                      VAProcPipelineParameterBufferType,
-                                      sizeof(VAProcPipelineParameterBuffer), 1,
-                                      NULL, &va_vpp_buffer_id_),
-                       "Couldn't create buffer", false);
-
-  return true;
-}
-
-void VaapiWrapper::DeinitializeVpp() {
-  base::AutoLock auto_lock(*va_lock_);
-
-  if (va_vpp_buffer_id_ != VA_INVALID_ID) {
-    vaDestroyBuffer(va_display_, va_vpp_buffer_id_);
-    va_vpp_buffer_id_ = VA_INVALID_ID;
-  }
-  if (va_vpp_context_id_ != VA_INVALID_ID) {
-    vaDestroyContext(va_display_, va_vpp_context_id_);
-    va_vpp_context_id_ = VA_INVALID_ID;
-  }
-  if (va_vpp_config_id_ != VA_INVALID_ID) {
-    vaDestroyConfig(va_display_, va_vpp_config_id_);
-    va_vpp_config_id_ = VA_INVALID_ID;
-  }
-}
-
-// static
-void VaapiWrapper::PreSandboxInitialization() {
-  VADisplayState::PreSandboxInitialization();
-}
-
-}  // namespace media
--- a/media/gpu/vaapi_wrapper.h
+++ /dev/null
@@ -1,288 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// This file contains an implementation of VaapiWrapper, used by
-// VaapiVideoDecodeAccelerator and VaapiH264Decoder for decode,
-// and VaapiVideoEncodeAccelerator for encode, to interface
-// with libva (VA-API library for hardware video codec).
-
-#ifndef MEDIA_GPU_VAAPI_WRAPPER_H_
-#define MEDIA_GPU_VAAPI_WRAPPER_H_
-
-#include <stddef.h>
-#include <stdint.h>
-
-#include <set>
-#include <vector>
-
-#include <va/va.h>
-
-#include "base/files/file.h"
-#include "base/macros.h"
-#include "base/memory/ref_counted.h"
-#include "base/synchronization/lock.h"
-#include "media/base/video_decoder_config.h"
-#include "media/base/video_frame.h"
-#include "media/gpu/media_gpu_export.h"
-#include "media/gpu/va_surface.h"
-#include "media/video/jpeg_decode_accelerator.h"
-#include "media/video/video_decode_accelerator.h"
-#include "media/video/video_encode_accelerator.h"
-#include "ui/gfx/geometry/size.h"
-
-#if defined(USE_X11)
-#include "ui/gfx/x/x11.h"
-#endif  // USE_X11
-
-namespace gfx {
-class NativePixmap;
-}
-
-namespace media {
-
-// This class handles VA-API calls and ensures proper locking of VA-API calls
-// to libva, the userspace shim to the HW codec driver. libva is not
-// thread-safe, so we have to perform locking ourselves. This class is fully
-// synchronous and its methods can be called from any thread and may wait on
-// the va_lock_ while other, concurrent calls run.
-//
-// This class is responsible for managing VAAPI connection, contexts and state.
-// It is also responsible for managing and freeing VABuffers (not VASurfaces),
-// which are used to queue parameters and slice data to the HW codec,
-// as well as underlying memory for VASurfaces themselves.
-class MEDIA_GPU_EXPORT VaapiWrapper
-    : public base::RefCountedThreadSafe<VaapiWrapper> {
- public:
-  enum CodecMode {
-    kDecode,
-    kEncode,
-    kCodecModeMax,
-  };
-
-  // Return an instance of VaapiWrapper initialized for |va_profile| and
-  // |mode|. |report_error_to_uma_cb| will be called independently from
-  // reporting errors to clients via method return values.
-  static scoped_refptr<VaapiWrapper> Create(
-      CodecMode mode,
-      VAProfile va_profile,
-      const base::Closure& report_error_to_uma_cb);
-
-  // Create VaapiWrapper for VideoCodecProfile. It maps VideoCodecProfile
-  // |profile| to VAProfile.
-  // |report_error_to_uma_cb| will be called independently from reporting
-  // errors to clients via method return values.
-  static scoped_refptr<VaapiWrapper> CreateForVideoCodec(
-      CodecMode mode,
-      VideoCodecProfile profile,
-      const base::Closure& report_error_to_uma_cb);
-
-  // Return the supported video encode profiles.
-  static VideoEncodeAccelerator::SupportedProfiles GetSupportedEncodeProfiles();
-
-  // Return the supported video decode profiles.
-  static VideoDecodeAccelerator::SupportedProfiles GetSupportedDecodeProfiles();
-
-  // Return true when JPEG decode is supported.
-  static bool IsJpegDecodeSupported();
-
-  // Return true when JPEG encode is supported.
-  static bool IsJpegEncodeSupported();
-
-  // Create |num_surfaces| backing surfaces in driver for VASurfaces of
-  // |va_format|, each of size |size|. Returns true when successful, with the
-  // created IDs in |va_surfaces| to be managed and later wrapped in
-  // VASurfaces.
-  // The client must DestroySurfaces() each time before calling this method
-  // again to free the allocated surfaces first, but is not required to do so
-  // at destruction time, as this will be done automatically from
-  // the destructor.
-  virtual bool CreateSurfaces(unsigned int va_format,
-                              const gfx::Size& size,
-                              size_t num_surfaces,
-                              std::vector<VASurfaceID>* va_surfaces);
-
-  // Free all memory allocated in CreateSurfaces.
-  virtual void DestroySurfaces();
-
-  // Create a VASurface of |va_format|, |size| and using |va_attribs|
-  // attributes. The ownership of the surface is transferred to the
-  // caller. It differs from surfaces created using CreateSurfaces(),
-  // where VaapiWrapper is the owner of the surfaces.
-  scoped_refptr<VASurface> CreateUnownedSurface(
-      unsigned int va_format,
-      const gfx::Size& size,
-      const std::vector<VASurfaceAttrib>& va_attribs);
-
-  // Create a VASurface for |pixmap|. The ownership of the surface is
-  // transferred to the caller. It differs from surfaces created using
-  // CreateSurfaces(), where VaapiWrapper is the owner of the surfaces.
-  scoped_refptr<VASurface> CreateVASurfaceForPixmap(
-      const scoped_refptr<gfx::NativePixmap>& pixmap);
-
-  // Submit parameters or slice data of |va_buffer_type|, copying them from
-  // |buffer| of size |size|, into HW codec. The data in |buffer| is no
-  // longer needed and can be freed after this method returns.
-  // Data submitted via this method awaits in the HW codec until
-  // ExecuteAndDestroyPendingBuffers() is called to execute or
-  // DestroyPendingBuffers() is used to cancel a pending job.
-  bool SubmitBuffer(VABufferType va_buffer_type, size_t size, void* buffer);
-
-  // Submit a VAEncMiscParameterBuffer of given |misc_param_type|, copying its
-  // data from |buffer| of size |size|, into HW codec. The data in |buffer| is
-  // no longer needed and can be freed after this method returns.
-  // Data submitted via this method awaits in the HW codec until
-  // ExecuteAndDestroyPendingBuffers() is called to execute or
-  // DestroyPendingBuffers() is used to cancel a pending job.
-  bool SubmitVAEncMiscParamBuffer(VAEncMiscParameterType misc_param_type,
-                                  size_t size,
-                                  void* buffer);
-
-  // Cancel and destroy all buffers queued to the HW codec via SubmitBuffer().
-  // Useful when a pending job is to be cancelled (on reset or error).
-  void DestroyPendingBuffers();
-
-  // Execute job in hardware on target |va_surface_id| and destroy pending
-  // buffers. Return false if Execute() fails.
-  bool ExecuteAndDestroyPendingBuffers(VASurfaceID va_surface_id);
-
-#if defined(USE_X11)
-  // Put data from |va_surface_id| into |x_pixmap| of size
-  // |dest_size|, converting/scaling to it.
-  bool PutSurfaceIntoPixmap(VASurfaceID va_surface_id,
-                            Pixmap x_pixmap,
-                            gfx::Size dest_size);
-#endif  // USE_X11
-
-  // Get a VAImage from a VASurface |va_surface_id| and map it into memory with
-  // given |format| and |size|. The output is |image| and the mapped memory is
-  // |mem|. If |format| doesn't equal to the internal format, the underlying
-  // implementation will do format conversion if supported. |size| should be
-  // smaller than or equal to the surface. If |size| is smaller, the image will
-  // be cropped. The VAImage should be released using the ReturnVaImage
-  // function. Returns true when successful.
-  bool GetVaImage(VASurfaceID va_surface_id,
-                  VAImageFormat* format,
-                  const gfx::Size& size,
-                  VAImage* image,
-                  void** mem);
-
-  // Release the VAImage (and the associated memory mapping) obtained from
-  // GetVaImage().
-  void ReturnVaImage(VAImage* image);
-
-  // Upload contents of |frame| into |va_surface_id| for encode.
-  bool UploadVideoFrameToSurface(const scoped_refptr<VideoFrame>& frame,
-                                 VASurfaceID va_surface_id);
-
-  // Create a buffer of |size| bytes to be used as encode output.
-  bool CreateCodedBuffer(size_t size, VABufferID* buffer_id);
-
-  // Download the contents of the buffer with given |buffer_id| into a buffer of
-  // size |target_size|, pointed to by |target_ptr|. The number of bytes
-  // downloaded will be returned in |coded_data_size|. |sync_surface_id| will
-  // be used as a sync point, i.e. it will have to become idle before starting
-  // the download. |sync_surface_id| should be the source surface passed
-  // to the encode job.
-  bool DownloadFromCodedBuffer(VABufferID buffer_id,
-                               VASurfaceID sync_surface_id,
-                               uint8_t* target_ptr,
-                               size_t target_size,
-                               size_t* coded_data_size);
-
-  // See DownloadFromCodedBuffer() for details. After downloading, it deletes
-  // the VA buffer with |buffer_id|.
-  bool DownloadAndDestroyCodedBuffer(VABufferID buffer_id,
-                                     VASurfaceID sync_surface_id,
-                                     uint8_t* target_ptr,
-                                     size_t target_size,
-                                     size_t* coded_data_size);
-
-  // Destroy all previously-allocated (and not yet destroyed) coded buffers.
-  void DestroyCodedBuffers();
-
-  // Blits a VASurface |va_surface_src| into another VASurface
-  // |va_surface_dest| applying pixel format conversion and scaling
-  // if needed.
-  bool BlitSurface(const scoped_refptr<VASurface>& va_surface_src,
-                   const scoped_refptr<VASurface>& va_surface_dest);
-
-  // Initialize static data before sandbox is enabled.
-  static void PreSandboxInitialization();
-
-  // Get the created surfaces format.
-  unsigned int va_surface_format() const { return va_surface_format_; }
-
- protected:
-  VaapiWrapper();
-  virtual ~VaapiWrapper();
-
- private:
-  friend class base::RefCountedThreadSafe<VaapiWrapper>;
-
-  bool Initialize(CodecMode mode, VAProfile va_profile);
-  void Deinitialize();
-  bool VaInitialize(const base::Closure& report_error_to_uma_cb);
-
-  // Free all memory allocated in CreateSurfaces.
-  void DestroySurfaces_Locked();
-  // Destroys a |va_surface| created using CreateUnownedSurface.
-  void DestroyUnownedSurface(VASurfaceID va_surface_id);
-
-  // Initialize the video post processing context with the |size| of
-  // the input pictures to be processed.
-  bool InitializeVpp_Locked();
-
-  // Deinitialize the video post processing context.
-  void DeinitializeVpp();
-
-  // Execute pending job in hardware and destroy pending buffers. Return false
-  // if vaapi driver refuses to accept parameter or slice buffers submitted
-  // by client, or if execution fails in hardware.
-  bool Execute(VASurfaceID va_surface_id);
-
-  // Attempt to set render mode to "render to texture.". Failure is non-fatal.
-  void TryToSetVADisplayAttributeToLocalGPU();
-
-  // Pointer to VADisplayState's member |va_lock_|. Guaranteed to be valid for
-  // the lifetime of VaapiWrapper.
-  base::Lock* va_lock_;
-
-  // Allocated ids for VASurfaces.
-  std::vector<VASurfaceID> va_surface_ids_;
-
-  // VA format of surfaces with va_surface_ids_.
-  unsigned int va_surface_format_;
-
-  // VA handles.
-  // All valid after successful Initialize() and until Deinitialize().
-  VADisplay va_display_;
-  VAConfigID va_config_id_;
-  // Created for the current set of va_surface_ids_ in CreateSurfaces() and
-  // valid until DestroySurfaces().
-  VAContextID va_context_id_;
-
-  // Data queued up for HW codec, to be committed on next execution.
-  std::vector<VABufferID> pending_slice_bufs_;
-  std::vector<VABufferID> pending_va_bufs_;
-
-  // Bitstream buffers for encode.
-  std::set<VABufferID> coded_buffers_;
-
-  // Called to report codec errors to UMA. Errors to clients are reported via
-  // return values from public methods.
-  base::Closure report_error_to_uma_cb_;
-
-  // VPP (Video Post Processing) context, this is used to convert
-  // pictures used by the decoder to RGBA pictures usable by GL or the
-  // display hardware.
-  VAConfigID va_vpp_config_id_;
-  VAContextID va_vpp_context_id_;
-  VABufferID va_vpp_buffer_id_;
-
-  DISALLOW_COPY_AND_ASSIGN(VaapiWrapper);
-};
-
-}  // namespace media
-
-#endif  // MEDIA_GPU_VAAPI_WRAPPER_H_
--- a/media/gpu/video_decode_accelerator_unittest.cc
+++ b/media/gpu/video_decode_accelerator_unittest.cc
@@ -75,7 +75,7 @@
 #include "media/gpu/dxva_video_decode_accelerator_win.h"
 #endif  // defined(OS_WIN)
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #endif  // BUILDFLAG(USE_VAAPI)
 
 #if defined(OS_CHROMEOS)
--- a/media/gpu/video_encode_accelerator_unittest.cc
+++ b/media/gpu/video_encode_accelerator_unittest.cc
@@ -56,7 +56,7 @@
 #include "testing/gtest/include/gtest/gtest.h"
 
 #if BUILDFLAG(USE_VAAPI)
-#include "media/gpu/vaapi_wrapper.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
 #elif defined(OS_WIN)
 #include "media/gpu/media_foundation_video_encode_accelerator_win.h"
 #endif
